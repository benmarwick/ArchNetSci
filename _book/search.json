[{"path":"index.html","id":"Welcome","chapter":"Welcome","heading":"Welcome","text":"project serves companion Cambridge Manuals Archaeology book Network Science Archaeology Tom Brughmans Matthew . Peeples (2023).document contains series tutorials outline methods managing, analyzing, visualizing network data, primarily using R programming language. provide code examples replicate analyses presented book well many useful tools. bulk Online Companion designed used book hand expand topics covered published version. Part document (see Table Contents) focused helping get started R R-Studio. Part II includes sections 2 7 corresponds topics information covered Chapters 2 7 Brughmans Peeples book. Part III (Going Beyond Book) includes tutorials beyond scope published book including “advanced” topics require additional detailed description knowledge methods presented Parts II. plan continue add expand Part III future. can use table contents left-hand side screen jump directly particular section table contents right navigate within section. also created quick TOC reference seeking something particular.information book authors check project website : archnetworks.net.Cite document :Peeples, Matthew . Tom Brughmans (2023). Online Companion Network Science Archaeology. https://archnetworks.net, Accessed 2024-02-15.associated book can cited asBrughmans, Tom Matthew . Peeples (2023). Network Science Archaeology. Cambridge Manuals Archaeology. Cambridge University Press, Cambridge, UK.","code":""},{"path":"index.html","id":"HowTo","chapter":"Welcome","heading":"How Should I Use This Online Companion?","text":"tutorials designed complement text associated book (Brughmans Peeples 2023) can also stand alone guide implementation network analyses R basic background network methods terminology. Although section guide builds upon previous sections terms network concepts R methods, sections independent terms data, examples, code can run order choose.suggestions start:new network analysis R, suggest going section document, starting Part : Getting Started R going Part II order following along corresponding chapters book.already familiar R new network analysis, can start Section 2 Part II set data work space, follow along remaining numbered sections associated book chapters read.already confident network analyst R user just looking code chunks implement something particular, feel free skip around. tried make section independent possible can pick choose want work . Use Table Contents find topics quickly.real pro designing network analyses visualizations, love contributed project help document grow.Throughout document use icons call-special information concerns. Keep eye symbols :\nuse icon highlight discussions R packages, Python\npackages, software used project. Check brief\noverviews instructions use configure \npackages.\n\nuse icon highlight particular areas concern \ndiscussion network methods R code. particular, use \nicon warn common errors pitfalls particular functions\nnetwork methods.\n\nuse icon highlight helpful tips use particular\nnetwork methods tools.\n","code":""},{"path":"index.html","id":"Repro","chapter":"Welcome","heading":"Reproducibility","text":"recent version document built R version 4.2.2 (2022-10-31 ucrt). suggest use recent version R attempting use code document (version 4.2 recommended).   \ncontent document designed accessible reproducible possible. source code used produce document along data used analyses available GitHub. GitHub repository allows users open issues, contribute document, help fix typos errors (see information contributing ). also opened GitHub discussion board repository users can ask questions data code repository without making edits issue requests directly.easiest way reproduce document launch project directly browser using Binder. click link open browser based instance R studio required packages files. can test evaluate code directly.open Binder see window Binder logo spinning progress wheel. typically take minute get running see screen . Click “R-Studio” link “Notebook” open new window R-Studio instance can use just like computer. click Binder link taking long time, click “show” build logs. “lucky” enough first initialize Binder new build GitHub project take quite bit longer get started. Grab coffee, tea, Dr. Pepper, beverage choice may approximately 30+ minutes R-Studio loads.can also install repository R package directly GitHub using following code:package installation includes dependencies required run code document create folders called “data” “scripts” package installation directory required files replicate analyses document.Finally, can run code generate documents locally using R R Studio downloading entire R repository : main.zip. Unzip files :Open “ArchNetSci.Rproj” file R studio.Use renv::restore() command console install required packages dependencies. Note large document uses many packages may take time.able browse files execute code repository computer.online bookdown document deployed using Netlify platform badge shows current status build hosted https://book.archnetworks.net.","code":"\nif (!require(\"devtools\")) install.packages(\"devtools\")\ndevtools::install_github(\"mpeeples2008/ArchNetSci\")"},{"path":"index.html","id":"Discord","chapter":"Welcome","heading":"Computational Archaeology Discord Community","text":"created Archaeological Network Science Channel Computational Archaeology Discord Server, hope provide additional venue archaeological network practitioners collaborate, interact, ask help document archaeological networks (computational methods) general. invite use place ask questions authors, community large, just chat like-minded researchers. Note Discord subject code conduct use GitHub repository must abide agreement participate. require Discord account verified email address.Join Computational Archaeology Discord       ","code":""},{"path":"index.html","id":"NewToR","chapter":"Welcome","heading":"New to R and R Studio?","text":"network tutorials document built users basic familiarity R R-studio ’re just getting started, don’t worry. created detailed guide Getting started R. document covers installation required software provides basic introduction R programming environment hope enough get started.already basic familiarity R want go , numerous additional resources (completely free) help learn. resources recommend include R Data Science (Wickham Grolemund 2017), Advanced R (Wickham 2019), R Cookbook, 2nd edition (Long Teetor 2019), R Action associated Quick-R website (Kabacoff 2015). addition Ben Marwick created excellent repository resources using R archaeology well ever-growing list archaeological publications include R code. website associated book (archnetworks.net) includes list archaeological articles focused network research include data code. Reproducing published results , experience, one best ways learn advanced techniques data management R suggest give try.","code":""},{"path":"index.html","id":"Contributing","chapter":"Welcome","heading":"Contribute To the Project","text":"welcome contributions project community GitHub platform helps us facilitate . first need sign GitHub account log . find something needs updating changing (typos errors) can simply click “Edit source” link right sidebar relevant page click edit icon found near top code block make proposed changes. changes saved new “fork” document review implement relevant happily add name list contributors. Note generally use tidyverse style guide formatting code comments.detect larger error code running like request new feature update, can create issue using issue tracker page associated project repository.contributors must agree adhere code conduct.","code":""},{"path":"index.html","id":"Community","chapter":"Welcome","heading":"Help Build the Community","text":"devoted seeing community archaeological network practitioners grow hope book online resources help make happen. can support growth community !Spread word friends colleaguesShare links online resources social media using #archnetworks hashtagPlease cite book Online Companion use methods code document. Citation InfoStar GitHub project repository contribute projectJoin Computational Archaeology Discord invite interested peopleShare articles, teaching resources, data, archaeological network materials posting associated website (archnetworks.net)","code":""},{"path":"index.html","id":"project-license","chapter":"Welcome","heading":"Project License","text":"Online Companion Archaeological Network Science licensed Creative Commons Attribution-NonCommercial-NoDerivitives 4.0 International License.","code":""},{"path":"index.html","id":"Acknowledgements","chapter":"Welcome","heading":"Acknowledgements","text":"online bookdown project associated book made possible thanks support several generous funding sources including: Carlsberg Foundation, context Past Social Networks Project (CF21-0382); National Science Foundation Archaeology Measurement, Methodology, Statistics programs (grant #1758690 #1758606); School Human Evolution Social Change Arizona State University. Thank Jens Emil Bødstrup Christoffersen providing detailed comments testing initial version online bookdown document. errors remain .          ","code":""},{"path":"GettingStarted.html","id":"GettingStarted","chapter":"Section 1 Getting Started with R","heading":"Section 1 Getting Started with R","text":"order follow along code examples document, need recent installations R R-Studio computer. R R-studio available Windows, MacOS, Linux. section provides brief overview get running. Following , introduce basics R R-Studio get ready tutorials remainder document. follow tutorial confident able engage examples code Online Companion.","code":""},{"path":"GettingStarted.html","id":"InstallR","chapter":"Section 1 Getting Started with R","heading":"1.1 Download and Install R","text":"first step install recent version R (recommend 4.2 later document originally created version 4.2). Follow instructions appropriate operating system.first step go R project website www.r-project.org click CRAN link “Downloads” left hand side.Choose mirror download selecting one country “Cloud” option.Next, click Windows, MacOS, Linux distribution follow instructions .","code":""},{"path":"GettingStarted.html","id":"Windows","chapter":"Section 1 Getting Started with R","heading":"1.1.1 Windows","text":"Click “base” sub-directory left hand side screen click “Download R-4.2.0 Windows” (version number 4.2 later) download recent version executable.download complete, run *.exe file answer questions prompted complete installation.","code":""},{"path":"GettingStarted.html","id":"MacOS","chapter":"Section 1 Getting Started with R","heading":"1.1.2 MacOS","text":"install R MacOS, first need know chip manufacturer Mac . order determine chip go Apple menu select “Mac” look information “Processor” “Chip” window pops . either Intel M1.Next, click link “Latest release” *.pkg file appropriate Mac processor computer. separate notarized signed .pkg file Macs Intel processors Macs Apple M1 processors (mostly produced 2020 later). Note, .pkg files interchangeable confirm one need attempting install.downloaded appropriate .pkg, run answer questions install required.","code":""},{"path":"GettingStarted.html","id":"Linux","chapter":"Section 1 Getting Started with R","heading":"1.1.3 Linux","text":"Linux installations R primarily done console instructions slightly different depending distribution using.Click link appropriate Linux distribution follow detailed instructions provided.“R-core” “R-base” builds ones want choose.Follow instructions build install recommended dependencies.","code":""},{"path":"GettingStarted.html","id":"InstallRStudio","chapter":"Section 1 Getting Started with R","heading":"1.2 Download and Install R-Studio","text":"R-studio integrated development environment (IDE) R, Python, related programming tools provides additional features running debugging code data management. see IDE essential working large complex R projects.order install R-Studio:Go R-Studio website www.rstudio.com click “Download” top screen.Select “RStudio Desktop” option.Download run latest “installer” file appropriate operating system.Run downloaded file answer questions prompts appropriate. R-Studio automatically detect installation R.","code":""},{"path":"GettingStarted.html","id":"RunRStudio","chapter":"Section 1 Getting Started with R","heading":"1.3 Run R-Studio","text":"’ve installed R R-Studio, open R-studio look Console window (typically left hand side screen). tell version R associated installation R-Studio. goes well, recent version R just installed.","code":""},{"path":"GettingStarted.html","id":"RBasics","chapter":"Section 1 Getting Started with R","heading":"1.4 R and R-Studio Basics","text":"R powerful statistical analysis platform can used conduct quite complex analyses. learning curve bit steep first getting started payoff HUGE ecosystem existing R scripts packages large diverse. hope cover everything R R-Studio can short intro . tutorial version “Introduction R programming” Peeples used first week Quantitative Formal Methods Archaeology class number years. Hopefully get started.Although R seems complicated first, many quite complex statistical analyses run just lines code. learn basics, complex features R really just combinations basic procedures. won’t become R expert overnight, ’ve seen many students pick basics quite quickly begin take first independent analyses R matter hours.","code":""},{"path":"GettingStarted.html","id":"Org","chapter":"Section 1 Getting Started with R","heading":"1.4.1 Organization of R-Studio","text":"First , let’s take look R-Studio setup. first open R-Studio first time, see screen divided 3 panes. getting started click “File” top screen go “New File > R Script” open 4th pane. see something like screen .\nNote color screen may different using \nparticular “dark mode” color setting find easier eyes. \nchange color scheme, go top R-Studio window click\n“Tools > Global Options > Appearance” select color\nmode works .\nOrganization R-Studio Windows:Workspace - pane top left contains Workspace tabs can write code documents prior executing code.Console - pane bottom left console can type run commands directly. execute code workspace, also appear .Environment/History - pane upper right includes tabs Environment (list objects functions currently initialized) History (list previous commands run console).Files/Plots/Packages - lower right pane tabs Files (shows files current directory), Plots (plots created console displayed), Packages (list additional packages installed initialized R), Help (can get information particular functions packages).Note locations visibility panes can changed going “View > Panes” selecting different options. set tutorials follow going focus Console first introduce panels provide along way.","code":""},{"path":"GettingStarted.html","id":"Math","chapter":"Section 1 Getting Started with R","heading":"1.4.2 Mathematical Operations","text":"Getting started R simple typing directly Console. can use R console like calculator conduct mathematical operations. Simply type numbers operators console hit enter calculate. answer output directly console default. Try typing following console:R uses ( ) bracketing groups operations. can nested complex mathematical operations determine order operations. example compare two equations :R uses typical mathematical operators including + - * / addition, subtraction, multiplication, division ^ raise number exponent.Anything placed # block code treated comment evaluated:","code":"\n3 + 3## [1] 6\n4 * 10## [1] 40\n50 / 5## [1] 10\n((4 * 5 + 3) / 2) * 12## [1] 138\n(((4 * 5)) + 3 / 2) * 12## [1] 258\n5^2## [1] 25\n5^(2 + 1)## [1] 125\n4 * 20 # comment here## [1] 80\n3 * 4 # 4 + 4 will not be evaluated as it is after the ### [1] 12"},{"path":"GettingStarted.html","id":"Variables","chapter":"Section 1 Getting Started with R","heading":"1.4.3 Creating Variables/Objects","text":"R can also assign numbers, characters, complex operations variables (also known objects context) can used mathematical operations. Typically, assign values object using <- assign command = also works. example:Object names R case sensitive include spaces. Object names can include numbers letters must start letter. good idea use descriptive object names object used repeatably.formatting object names common styles :snake_case_style - see little snakes (underscores) place spacesCamalCaseStyle - see capitalized humps denoting wordkebab-case-style - skewered right middleIn general styles fine, suggest try remain consistent. Also, avoid using . separate words used particular R functions calls ways can cause confusion.Many mathematical constants built right R sure overwrite (function) giving object name.","code":"\ntest_var <- 50\ntest_var## [1] 50\ntest2 = 10 + test_var\ntest2## [1] 60\nchar1 <- \"hello world\"\nchar1## [1] \"hello world\"\npi## [1] 3.141593\nLETTERS##  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n## [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\nletters##  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n## [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\nmonth.name##  [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n##  [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\""},{"path":"GettingStarted.html","id":"Logical","chapter":"Section 1 Getting Started with R","heading":"1.4.4 Logical Operators","text":"R can also use logical operators (see list ). operators can used conjunction operations return value indicating TRUE FALSE. can used complex functions conditional statements see .Logical operators can also include statements & symbol statements |. example:","code":"\nv <- 50\nv > 20## [1] TRUE\nv < 20## [1] FALSE\nv * 2 == 100## [1] TRUE\nv <- 40\nv > 20 & v < 30 # and statement## [1] FALSE\nv > 20 | v < 30 # or statement## [1] TRUE"},{"path":"GettingStarted.html","id":"Vectors","chapter":"Section 1 Getting Started with R","heading":"1.4.5 Vectors","text":"R can also assign vector numbers characters variable preform operations using vector. example following use c() (c combine) command create vector subject mathematical operation.want call particular value selection values vector can use [] square brackets indicate item(s) interested .can also search vectors objects specific values:see particular value given object can use %% operator get logical value return.","code":"\nz <- c(2, 4, 6, 8, 10, 12)\nz / 2## [1] 1 2 3 4 5 6\nz[3] # item 3 in object z## [1] 6\nz[4:6] # items 4 through 6 in object z## [1]  8 10 12\nz[c(3, 2, 1)] # items 3, 2, 1, in that order from object z## [1] 6 4 2\nvec_obj <-\n  c(\"Ohtani\",\n    \"Wheeler\",\n    \"Correa\",\n    \"Semien\",\n    \"Soto\",\n    \"Guerrero Jr.\",\n    \"Correa\")\n\nvec_obj[vec_obj == \"Correa\"]## [1] \"Correa\" \"Correa\"\n\"Ohtani\" %in% vec_obj## [1] TRUE\n\"Judge\" %in% vec_obj## [1] FALSE"},{"path":"GettingStarted.html","id":"Functions","chapter":"Section 1 Getting Started with R","heading":"1.4.6 Using Basic R Functions","text":"R number built-functions perform many common operations statistical analyses. already used one c() fast easy might missed . Functions typically used typing name function followed set parenthesis contain arguments function expects. example:list frequently used built-functions see Quick-R page.","code":"\nv <- c(5, 10, 15, 20, 25, 30, 2000)\nmax(v)## [1] 2000\nmin(v)## [1] 5\nmean(v)## [1] 300.7143\nmedian(v)## [1] 20\nlog(v, base = exp(1)) # argument setting the base## [1] 1.609438 2.302585 2.708050 2.995732 3.218876 3.401197 7.600902\nlog10(v)## [1] 0.698970 1.000000 1.176091 1.301030 1.397940 1.477121 3.301030\nround(pi, digits = 2) # argument setting the number of digits to retain## [1] 3.14"},{"path":"GettingStarted.html","id":"Tabular","chapter":"Section 1 Getting Started with R","heading":"1.4.7 Tabular Data","text":"R can used work tabular data well. Typically convenient read data file large tabular data (see working files ), can also generate simple numeric tabular data directly R using matrix() function. following example create two-row, two-column matrix converting vector numbers matrix specifying number rows nrow number columns ncol. assignments make inside matrix() function called arguments.Note matrix() function reads numbers first column row. want want change can first investigate options function using help() function. order see documentation given function simply type help(\"NameOfFunction\") console ?NameOfFunction.let’s zoom one piece particular:can see help materials matrix, additional argument use called byrow set FALSE default. Let’s change TRUE check results. Note can use capital F T place FALSE TRUE functions generally good form write context sharing code publicaly. Note also function call can span multiple rows automatically end close parentheses. multi-line formatting essential making longer function calls readable.\nR-Studio nice built-command formatting code, especially\nlong lines code, multiple lines easier read.\ncommand also creates proper spacing operators objects.\ngive try, simply highlight chunk code workspace area\nhit “Ctrl+Shift+” (“Cmd+Shift+” Mac) reformat code\nwithin selection. many nifty R-Studio keyboard\nshortcuts. Check\ninfo.\nJust like vectors, can also use matrices many mathematical statistical functions built directly R. example, let’s run Fisher’s Exact Test using fisher.test function assess independence rows columns table.output includes information data used run test, p-value, alternative hypothesis, confidence intervals, odds ratio. output get given function vary depending application. See help() documents function interest get info output.","code":"\ndat <- c(3, 4, 2, 20)\nmat1 <- matrix(data = dat, nrow = 2, ncol = 2)\nmat1##      [,1] [,2]\n## [1,]    3    2\n## [2,]    4   20\n?matrix\nmat2 <- matrix(\n  data = dat,\n  nrow = 2,\n  ncol = 2,\n  byrow = TRUE\n)\nmat2##      [,1] [,2]\n## [1,]    3    4\n## [2,]    2   20\nfisher.test(mat2)## \n##  Fisher's Exact Test for Count Data\n## \n## data:  mat2\n## p-value = 0.07474\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##    0.5875228 107.8450263\n## sample estimates:\n## odds ratio \n##   6.815654"},{"path":"GettingStarted.html","id":"DataTypes","chapter":"Section 1 Getting Started with R","heading":"1.4.8 Data Types in R","text":"many different types data R understands focus common categories. includes numeric data, integer data, character data, logical data, factors.numeric data - designation used real numbers can include decimal point.integer data - designation whole numbers without decimal. designate number integer type, can add L number (see example ). Note R automatically converts numeric integer data necessary mathematical operations.character data - designation string characters exclusively consist numbers. Character data can single character \"\" long string \"string character data\". general R displays character data inside \" \".logical data - designation evaluations logical statements takes form TRUE FALSE.factors - Factors nominal variables stored vectors R objects distinct “levels” value must . Factors useful many statistical procedures visualizations unique values can treated “groups” rather simply unique character data. designate data factor, use .factor() function. Note factors can numbers treated nominal characters evaluated.possible determine type data R object contains using str() function. Let’s look examples type :","code":"\nnum <- c(12.3, 32.4, 53, 4.2, 4, 22.3)\nstr(num)##  num [1:6] 12.3 32.4 53 4.2 4 22.3\nint <- c(1L, 2L, 5L, 6L)\nstr(int)##  int [1:4] 1 2 5 6\nchar <- c(\"string1\", \"string2\", \"This too is a string\")\nstr(char)##  chr [1:3] \"string1\" \"string2\" \"This too is a string\"\ntf <- c(TRUE, FALSE, FALSE, TRUE) # note the lack of \" \"\nstr(tf)##  logi [1:4] TRUE FALSE FALSE TRUE\nfac <- as.factor(c(\"type1\", \"type2\", \"type2\", \"type3\"))\nstr(fac)##  Factor w/ 3 levels \"type1\",\"type2\",..: 1 2 2 3"},{"path":"GettingStarted.html","id":"ObjectTypes","chapter":"Section 1 Getting Started with R","heading":"1.4.9 Object Types in R","text":"four common object types R vectors, matrices, lists, data frames. already explored vectors matrices can define classes detail .vector - combined set values type (character, numeric, etc.). Note mix numbers character data, R assume every entry represents character data.matrix - set values rectangular two-way table type (character, numeric, etc.)data frame - set values rectangular two-way table different columns can different data typeslist - list collection R objects can vectors, matrices, data frames others format combined single object.","code":""},{"path":"GettingStarted.html","id":"Vec","chapter":"Section 1 Getting Started with R","heading":"1.4.9.1 Vectors","text":"already introduced vectors can point one feature often useful assessing vectors. length() function tells many elements vector.","code":"\nv <- c(1, 6, 4, 8, 7, 5, 3, 8, 10, 44)\nlength(v)## [1] 10"},{"path":"GettingStarted.html","id":"Mat","chapter":"Section 1 Getting Started with R","heading":"1.4.9.2 Matrices","text":", already introduced matrices details worth addressing . , want call specific value matrix can use [ , ] square brackets row number listed followed comma column number. example:want know size matrix, can use dim() dimensions function:","code":"\nmat1##      [,1] [,2]\n## [1,]    3    2\n## [2,]    4   20\nmat1[2, 1] # row 2 column 1## [1] 4\ndim(mat1)## [1] 2 2"},{"path":"GettingStarted.html","id":"DF","chapter":"Section 1 Getting Started with R","heading":"1.4.9.3 Data Frame","text":"brief definitions suggest, data frames similar matrices can include mixed data types rectangular table. row column must, however, number entries. data frame can created combining set vectors. example:want look kind data R understands column , can use str() structure function.Note dim() function also works data frames [,] call specific items:","code":"\ncol1 <- c(\"mammoth\", \"mastodon\", \"bison\")\ncol2 <- c(50L, 52L, 14L)\ncol3 <- c(11.14, 22.23, 656.34)\ncol4 <- as.factor(c(\"type1\", \"type1\", \"type2\"))\ncol5 <- c(TRUE, FALSE, TRUE)\n\ndat <- data.frame(col1, col2, col3, col4, col5)\ndat##       col1 col2   col3  col4  col5\n## 1  mammoth   50  11.14 type1  TRUE\n## 2 mastodon   52  22.23 type1 FALSE\n## 3    bison   14 656.34 type2  TRUE\nstr(dat)## 'data.frame':    3 obs. of  5 variables:\n##  $ col1: chr  \"mammoth\" \"mastodon\" \"bison\"\n##  $ col2: int  50 52 14\n##  $ col3: num  11.1 22.2 656.3\n##  $ col4: Factor w/ 2 levels \"type1\",\"type2\": 1 1 2\n##  $ col5: logi  TRUE FALSE TRUE\ndat##       col1 col2   col3  col4  col5\n## 1  mammoth   50  11.14 type1  TRUE\n## 2 mastodon   52  22.23 type1 FALSE\n## 3    bison   14 656.34 type2  TRUE\ndim(dat)## [1] 3 5\ndat[2, 1]## [1] \"mastodon\""},{"path":"GettingStarted.html","id":"List","chapter":"Section 1 Getting Started with R","heading":"1.4.9.4 Lists","text":"list simply convenient way combining multiple objects single object. doesn’t matter type objects . Lists can defined using list() function. example:want call specific element list use double square brackets [[]] along numeric index middle:can even stack sets double single brackets call specific items within list elements:","code":"\nout1 <- list(mat1, dat, c(1, 2, 4)) # create a list containing 3 objects\nout1## [[1]]\n##      [,1] [,2]\n## [1,]    3    2\n## [2,]    4   20\n## \n## [[2]]\n##       col1 col2   col3  col4  col5\n## 1  mammoth   50  11.14 type1  TRUE\n## 2 mastodon   52  22.23 type1 FALSE\n## 3    bison   14 656.34 type2  TRUE\n## \n## [[3]]\n## [1] 1 2 4\nout1[[3]]## [1] 1 2 4\nout1[[3]][2] # item 2 in list object 3## [1] 2\nout1[[2]][2, 1] # row 2 column 1 in list object 2## [1] \"mastodon\""},{"path":"GettingStarted.html","id":"WorkspaceTab","chapter":"Section 1 Getting Started with R","heading":"1.5 The Workspace Tab","text":"Now starting get complex calls functions, useful write edit code executing rather typing directly Console. , can work Workspace tab R script document created beginning tutorial (Go File > New File > R Script open new document). .R documents can edited saved computer can return later. Let’s take look works.Think R script document draft plan type Console.","code":""},{"path":"GettingStarted.html","id":"Directory","chapter":"Section 1 Getting Started with R","heading":"1.5.1 Setting the Working Directory","text":"get started, let’s save blank R file just created. First, want define “Working Directory” files associated project go. go menu top screen click “Session > Set Working Directory > Choose Working Directory” navigate location like save file. Next, click “File > Save ” define name R script. end .R extension R R studio recognize R Scripts.","code":""},{"path":"GettingStarted.html","id":"FirstScript","chapter":"Section 1 Getting Started with R","heading":"1.5.2 Working with your first R script","text":"Now saved script, can type mathematical operations, functions, code just directly Console . main advantage make mistake can go back fix easily. Go ahead copy code next code chunk paste R script int Workspace window save document.saved, highlight code Workspace window click “Run” button top right side pane (see yellow arrow ).execute code Console print results. Let’s say ran code, realized actually wanted raise mat3 3rd power typed one number data incorrectly. can make changes select code click run . true power scripts allow us make changes modify code easily go without retyping commands. Anything can console can first set Workspace pane.","code":"\nmat3 <- matrix(\n  data = c(4, 5, 1, 5, 1, 5),\n  nrow = 2,\n  ncol = 3,\n  byrow = T\n)\n\nmat3^2"},{"path":"GettingStarted.html","id":"InstallPackages","chapter":"Section 1 Getting Started with R","heading":"1.6 Installing and Using Packages","text":"far, everything done involved packages included “base” R internal built-functions. One best things R ecosystem packages created peer reviewed others manner statistical analyses can imagine. package just everything always good idea check start write complex script .order install external packages, need know name package want simply type install.packages(\"NameOfPackage\") console. Let’s try installing vegan package first includes lots useful functions community ecology research.package installs, can “call” initialize using libaray() function. Notice load package also loads permute lattice two additional packages used within vegan. dependencies automatically installed installed vegan package.Now can use just base R functions, also functions within vegan package. Within package one particularly useful function called diversity() allows us calculate manner common diversity measures. Remember check ?diversity want learn package arguments. Let’s give try creating vector calculating two different diversity indices vector:\nexample shows, package loaded using \nlibrary() function, nothing special using\nexternal functions. called Console just like built-\nfunctions. , however, one additional consideration. Since \nmany packages created many people, sometimes\ntwo packages use function name. example, \nigraph sna packages use function\nname degree() degree centrality. packages \ninitialized R, R know one use? solution \nuse package name directly function call like \ncode :\nwriting code others use, may good idea include package names function calls avoid ambiguity.\ntons useful packages can sometimes \nbit overwhelming trying find . Searching search engine \nsimple letter “R” can also yield unexpected results. One helpful tip\nsearching packages include “CRAN” “package” \nsearch terms. CRAN stands Comprehensive R Archive Network \narchive contains peer reviewed \nestablished packages R.\n","code":"\ninstall.packages(\"vegan\")\nlibrary(vegan)## Warning: package 'vegan' was built under R version 4.2.3## Loading required package: permute## Warning: package 'permute' was built under R version 4.2.3## Loading required package: lattice## Warning: package 'lattice' was built under R version 4.2.3## This is vegan 2.6-4\nvec1 <- c(1, 6, 2, 7, 45, 3, 6, 2, 4, 6, 7, 2)\n\ndiversity(vec1, index = \"shannon\")## [1] 1.831803\ndiversity(vec1, index = \"simpson\")## [1] 0.7259993\nigraph::degree(data) # igraph degree function\nsna::degree(data) # sna degree function"},{"path":"GettingStarted.html","id":"WorkingWithFiles","chapter":"Section 1 Getting Started with R","heading":"1.7 Working with External Files","text":"many cases may wish either write read external files R. Frequently files take shape spreadsheets Excel documents csv (comma separated value) documents. R many functions reading data built-base R. Let’s try first writing .csv (comma separated value) file matrix generate reading back . Note files write console go directly R working directory unless otherwise specify.write csv file use write.csv() function. First create simple matrix, add row names column names, export . Note write file sub-folder working directory called “data” . change something else R return error attempt read write folders haven’t first created outside R-Studio.export file, see appear File pane bottom right R-Studio within working directory.want read file back , can simply use read.csv() function. Let’s give try create new object called, read_mat results function. use argument header = T indicate first row represents column names row.names = 1 indicate first column includes row names.\nimportant note , however, \nread.csv()function doesn’t know difference \ndata frame matrix unless specify. Indeed, check, R sees\nread_mat data frame. purposes doesn’t\nmatter , can convert matrix using \n.matrix() function.\nlots different functions reading files different formats introduce later subsequent sections tutorial relevant. overview common file types see Quick-R tutorial.","code":"\nvec2 <- c(4, 2, 65, 4, 2, 4, 6, 4, 2)\n\n# Notice in the matrix call below we don't enter 'nrow'\n# and other argument names as R automatically expects\n# them to occur in the order mentioned in the documentation\nmat4 <- matrix(vec2, 3, 3) # 3 row 3 column matrix\nrow.names(mat4) <- c(\"row 1\", \"row 2\", \"row 3\") # assign row names\ncolnames(mat4) <- c(\"A\", \"B\", \"C\") #assign col names\nmat4 # view matrix##        A B C\n## row 1  4 4 6\n## row 2  2 2 4\n## row 3 65 4 2\n# Export the matrix as a csv file\nwrite.csv(mat4, file = \"data/output_mat.csv\")\nread_mat <-\n  read.csv(file = \"data/output_mat.csv\",\n           header = T,\n           row.names = 1)\nread_mat##        A B C\n## row 1  4 4 6\n## row 2  2 2 4\n## row 3 65 4 2\nstr(read_mat)## 'data.frame':    3 obs. of  3 variables:\n##  $ A: int  4 2 65\n##  $ B: int  4 2 4\n##  $ C: int  6 4 2\nread_mat2 <- as.matrix(read_mat)\nis.matrix(read_mat2)## [1] TRUE"},{"path":"GettingStarted.html","id":"Plotting","chapter":"Section 1 Getting Started with R","heading":"1.8 Plotting Data","text":"One great features R ability make kinds amazing data visualizations. Making simple graphics easy see, defining specific details often requires number different packages considerable care. Indeed, vast majority functions used Online Companion used visualizations.Let’s start something simple creating two vectors creating bi-plot comparing . use plot() function plot automatically appear bottom right pane R-Studio window. use rnorm() function generate random numbers normal distribution.\nchunk code , many places document,\nuse set.seed() function. function expects \ninteger uses number initialize random number generator\nbuilt R. use seed computer, \nget results . entered different number \nset.seed() get different results. helps us\nensure code reproducible.\ncan also easily create histogram single variable additional argument breaks determines many bars histogram :boxplots:lots data visualizations built base R suggest exploring R Gallery Book outlines many options.\nremainder Online Companion go detail \nmodify configure visualizations worth mentioning one\ncommon visualization tool almost eclipsed base R graphics\npopularity. package ggplot2. package\ncan used sorts visualizations uses format \nsomewhat different base R.\nLet’s take look example plot using ggplot2 format:code chunk , created data frame (ggplot2 requires) combining random x y variables. Next, made generic call ggplot2 using ggplot(data = df) line. creates ggplot object set df data considered. Notice line followed +. package continue read lines line end symbol ggplot calls can often quite long.next line geom_point() function. package designates different kinds visualizations geom_ many options (geom_histogram, geom_bar, geom_polygon, etc.). geom_point function refers simple point plot. argument inside function defined aes(x = x, y = y). package aes stands aesthetics. case, using aesthetics call designate variable x y axis, easy named variable appropriately.ggplot2 includes seemingly endless customization options. way many options us cover good place start R Graph Gallery website.cover many examples visualization section tutorial particular leans heavily ggplot2 format now, let’s just see couple additional examples.","code":"\nset.seed(465)\n# Create a random normal variable with 5000 entries and\n# a mean of 40 and standard deviation of 3\nx <- rnorm(5000, mean = 40, sd = 3)\n# Create a random normal variable with 5000 entries and\n# a mean of 5 and standard deviation of 0.5\ny <- rnorm(5000, mean = 5, sd = 0.5)\n# plot the results\nplot(x, y)\nhist(x, breaks = 20) # breaks defines the number of bars\nboxplot(x, y)\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)## Warning: package 'ggplot2' was built under R version 4.2.3\ndf <- data.frame(x, y)\n\nggplot(data = df) +\n  geom_point(aes(x = x, y = y))\n# Histogram example\nggplot(data = df) +\n  geom_histogram(aes(x = y), col = \"blue\", fill = \"darkorchid4\") +\n  xlab(\"Numbers!!\") +\n  ylab(\"REALLY BIG NUMBERS\") +\n  theme_minimal()\n# Bined biplot example\nggplot(data = df) +\n  geom_bin2d(aes(x = x, y = y)) +\n  scale_fill_continuous(type = \"viridis\") +\n  theme_bw()\n# Create data frame for bar plot example\ndf2 <- data.frame(d1 = rpois(50, lambda = 4),\n                  gp = sample(size = 50, letters[1:4], replace = T))\nggplot(data = df2) +\n  geom_bar(aes(x = d1, fill = factor(gp))) +\n  theme_dark()"},{"path":"GettingStarted.html","id":"Warnings","chapter":"Section 1 Getting Started with R","heading":"1.9 Warnings and Messages in R","text":"run code sections documents, may seen additional “warnings” “messages” appear screen. example something like:stat_bin()` using `bins = 30`. Pick better value `binwidthThis output console simply letting us know might want select different binwidth better suits data. Warnings messages like often relatively benign like , may also indicate bigger problem. example, may get warning particular method appropriate data (perhaps missing data) even though results provided. Keep careful eye warnings heed necessary. Often looking help() documentation given function help interpret messages.purposes online companion, however, “muted” warnings messages output except couple places pointing something specific. messages generate innocuous feel free ask questions concerns.","code":""},{"path":"GettingStarted.html","id":"AdvancedR","chapter":"Section 1 Getting Started with R","heading":"1.10 More Advanced R Features","text":"examples far covered basic features R R-Studio. just things implemented online document need bit additional explanation. can follow along examples , able replicate work document. features section help expand skills better understand complicated code document.","code":""},{"path":"GettingStarted.html","id":"Conditionals","chapter":"Section 1 Getting Started with R","heading":"1.10.1 Conditional Statements","text":"Another common need programming R conduct action conditioned another action variable state. example, TRUE B. statements like formally R using following format:Example 1 statement called test evaluated TRUE event1 executed. test evaluated FALSE nothing happens.Example 2 …else statement. example statement called test evaluated TRUE event1 executed. test evaluated FALSE event2 executed.Let’s take look worked example print output screen depending outcome test expression.first example , evaluation x > 50 FALSE statement brackets else evaluated. second example, evaluation x*2 > 50 TRUE first statement evaluated. Finally, third example, x > 50 FALSE since else statement nothing happened.want apply ...else statement vector values rather one time, can use useful function ifelse(). ifelse() function expects first item parenthesis test expression, followed event execute statement true event execute expression false.Another useful frequently used conditional function () function. function allows evaluate items object meet given condition. Let’s take look example see works:first example , created sequence numbers 1 10 evaluated greater 5. results indicated items 6, 7, 8, 9, 10 vector greater 5. Note results referring values instead numeric indexes values. second example illustrates . much like first example create sequence numbers 2 20 counting 2s. evaluate numbers vector greater 10, results tell us 6th, 7th, 8th, 9th, 10th numbers greater 10.","code":"\n# Example 1\nif (test) {\n  event1\n}\n\n# Example 2\nif (test) {\n  event1\n} else {\n  event2\n}\nx <- 40\n\nif (x > 50) {\n  cat(\"Greater Than 50\")\n} else {\n  cat(\"Less Than 50\")\n}## Less Than 50\nif (x * 2 > 50) {\n  cat(\"Greater Than 50\")\n} else {\n  cat(\"Less Than 50\")\n}## Greater Than 50\nif (x > 50) {\n  cat(\"Greater Than 50\")\n}\nx <- seq(5, 100, by = 5)\nx##  [1]   5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95\n## [20] 100\nifelse(x > 50, \"Greater Than 50\", \"Less Than 50\")##  [1] \"Less Than 50\"    \"Less Than 50\"    \"Less Than 50\"    \"Less Than 50\"   \n##  [5] \"Less Than 50\"    \"Less Than 50\"    \"Less Than 50\"    \"Less Than 50\"   \n##  [9] \"Less Than 50\"    \"Less Than 50\"    \"Greater Than 50\" \"Greater Than 50\"\n## [13] \"Greater Than 50\" \"Greater Than 50\" \"Greater Than 50\" \"Greater Than 50\"\n## [17] \"Greater Than 50\" \"Greater Than 50\" \"Greater Than 50\" \"Greater Than 50\"\nx <- seq(1, 10) # sequence of numbers 1 to 10\nx##  [1]  1  2  3  4  5  6  7  8  9 10\nwhich(x > 5)## [1]  6  7  8  9 10\ny <- seq(2, 20, by = 2) # sequence of numbers 2 to 20 by 2s\ny##  [1]  2  4  6  8 10 12 14 16 18 20\nwhich(y > 10)## [1]  6  7  8  9 10"},{"path":"GettingStarted.html","id":"Loops","chapter":"Section 1 Getting Started with R","heading":"1.10.2 Loops","text":"loop provides set instructions R repeat code block number times based rules supply. typical syntax :means every value sequence values, evaluate expression event chunk. Let’s take look worked example help clarify .example helps illustrate, (1:5) statement defines = 1 evaluates statement print(* 2), defines = 2 evaluates print(* 2), completes chunk = 5. key feature loops can use value assigned iterator statement inside curly brackets {} evaluate statement range values. sequence values assigned iterator arbitrary can occur order:can also assign results expressions curly brackets new object. want retain results results rewritten, need first define output object start.second example, statement within brackets tells R assign value z position [z] therefore results retained rather rewritten sequence loop.lot can done loops basic description need know understand code document.","code":"\nfor (value in sequence) {\n  event\n}\nfor (i in 1:5) { # for every value in the sequence from 1:5\n  print(i * 2)\n}## [1] 2\n## [1] 4\n## [1] 6\n## [1] 8\n## [1] 10\nval_seq <- c(5, 1, 8, 4, 1, 5, 7)\n\nfor (m in val_seq) {\n  print(m)\n}## [1] 5\n## [1] 1\n## [1] 8\n## [1] 4\n## [1] 1\n## [1] 5\n## [1] 7\n# Compare these two chunks of code\nfor (z in 1:10) {\n  out <- z\n}\nout## [1] 10\nout <- NULL\nfor (z in 1:10) {\n  out[z] <- z\n}\nout##  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"GettingStarted.html","id":"CustomFunctions","chapter":"Section 1 Getting Started with R","heading":"1.10.3 Custom Functions","text":"Finally, going end discussion R can used create custom functions. operation , doesn’t make sense keep copying pasting code every time. makes sense define function just call . defined, custom function works just like built-package functions ’ve seen . basic syntax function R:format fairly simple example. functions can quite complex, complexity usually product combining loops conditional statements processes discussed within function rather anything new beyond ’ve shown far. Let’s take look simple worked example see custom functions work:shows, named argument function call can used expression evaluated within brackets. Functions can contain many lines code many arguments features format simple examples . Let’s look somewhat complex function see works:Let’s break happening chunk code . First, defined function one argument x. Inside function expression initialized new variable output called z simply setting NULL empty. enter loop iterates values sequence numbers 1 length vector x using seq_len() call.. value z position defined value x position times divided 5. loop finishes, function returns vector z results. example shows, arguments need limited single values can include vectors, data.frames, matrices, lists, type R object.clarify iterator works, function seq_len() creates sequence numbers 1 number indicated. setting number runs loop based length object good practice use function.","code":"\nfunction_name <- function(arguments) {\n  result <- expression_to_evaluate\n  return(result)\n}\n\n# Once defined function can be run as\nfunction_name(arguments)\ndo_something <- function(x, y) {\n  result <- (x * y) + (x - y)^2\n  return(result)\n}\n\ndo_something(4, 5)## [1] 21\ndo_something(10, 5)## [1] 75\nmyfunct <- function(x) {\n  z <- NULL\n  for (i in seq_len(length(x))) {\n    z[i] <- (x[i] * i) / 5\n  }\n  return(z)\n}\n\nval_seq <- seq(1:10)\nmyfunct(val_seq)##  [1]  0.2  0.8  1.8  3.2  5.0  7.2  9.8 12.8 16.2 20.0\nseq_len(10)##  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"GettingStarted.html","id":"TestYourSkills","chapter":"Section 1 Getting Started with R","heading":"1.11 Test Your Skills","text":"’ve followed along tutorial far, able many basic operations R R-Studio. Let’s now put skills test. Use learned create function converts Fahrenheit temperatures Celsius. formula conversion (F_temp - 32) * 5 / 9. Create function reads F temperature outputs C run sequence values .Hints: Remember can’t use F object name designation R uses FALSE. Also, think trying accomplish . want create function iterates across vector. ’s much previous example can use code inspiration.working function, use round() function convert results integers (check ?round() need hints ) output results object called res. Finally run chunk code surprise:provided answer give try first peeking answer.peeking try!!solution :","code":"\nf_temp <- c(44, 59, 59, 39, 50, 59, 35)\npaste(c(LETTERS[res]), collapse = \"\")\nconvert_temp <- function(f) {\n  results <- NULL\n  for (i in seq_len(length(f))) {\n    results[i] <- ((f[i] - 32) * 5 / 9)\n  }\n  return(results)\n}\n\nf_temp <- c(44, 59, 59, 39, 50, 59, 35)\nout <- convert_temp(f_temp)\nout## [1]  6.666667 15.000000 15.000000  3.888889 10.000000 15.000000  1.666667\nres <- round(out, digits = 0)\nres## [1]  7 15 15  4 10 15  2\npaste(c(LETTERS[res]), collapse = \"\")## [1] \"GOODJOB\""},{"path":"DataAndWorkspace.html","id":"DataAndWorkspace","chapter":"Section 2 Data and Workspace Setup","heading":"Section 2 Data and Workspace Setup","text":"section provides downloadable files network data sets used online companion book well information primary R packages used analysis visualization throughout tutorials document. provide brief instructions importing data R using R-studio guidance setting R-studio working environment. additional guidance see Getting Started R.","code":""},{"path":"DataAndWorkspace.html","id":"DataSets","chapter":"Section 2 Data and Workspace Setup","heading":"2.1 Data Sets","text":"analyses illustrated document use number real simulated archaeological data sets serve examples particular data types techniques. data sets used provided .csv (comma separated value) .RData formats can downloaded can follow along analyses computer. encourage explore files see formatted guide setting data sets.data used include range different network data formats types. primary data sets described detail Brughmans Peeples (2023) Chapter 2.8. Note spatial locations archaeological sites provided locations randomly jittered 10 kilometers actual locations maintain data security.files can right click “save ” save use locally. Note many additional data sets relating replication particular figures book provided code particular figure occurs. ’d like just download everything see next section","code":""},{"path":"DataAndWorkspace.html","id":"Everything","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.1 Just Give Me Everything","text":"Hey, get . ’re busy just want data one convenient package. provide data used appendix single .zip file download. follow along examples appendix need choose R working directory place contents *.zip folder within individual files contained within folder called “data”. Note includes additional files required reproducing particular figures well.All_data.zip - single compressed file containing data files used appendix.","code":""},{"path":"DataAndWorkspace.html","id":"RomanRoad","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.2 Roman Road Networks","text":"development elaborate road system one enduring legacies Roman Republic Empire. Areas came Roman control connected Rome important provincial centers entirely new roads well redeveloped existing roads. roughly second century AD onward resulted integrated terrestrial transport network connecting North-Africa, Middle East, western southern Europe. Much subsequent development transport systems regions built Roman system.primary source roads entire Roman world Barrington Atlas Greek Roman World (Talbert 2000) digitization Ancient World Mapping Center (2012). many examples focus particular roads Iberian Peninsula, digitized great detail Pau de Soto (de Soto Carreras 2021). analyses Roman road network ancient settlements represented nodes existence road two settlements represented edge. also include length road edge attribute.Hispania_nodes - NodeIDs names Roman era settlements Iberian Peninsula along names latitude longitude locations decimal degrees.Hispania_roads - Edge list road connections using NodeIDs Hispania_nodes file. file contains “weight” variable defined edge denotes length road segment.Stanford ORBIS project provides additional data across Roman World including settlements, roads, characterizations travel time. data wrapped convenient R compendium Sebastian Heath data available GitHub :","code":"\nif (!require(\"devtools\")) install.packages(\"devtools\")\ndevtools::install_github(\"sfsheath/cawd\")"},{"path":"DataAndWorkspace.html","id":"SWSN","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.3 Southwest Social Networks Project Ceramic Similarity Networks","text":"Southwest Social Networks (SWSN) Project (subsequent cyberSW project) large collaborative effort focused exploring methods models network analysis archaeological data better understand patterns interaction, population movement, demographic change across U.S. Southwest Mexican Northwest time (ca. .D. 800-1800; Borck et al. 2015; Giomi et al. 2021; Mills et al. 2013a; 2013b; 2015; 2018; Peeples Haas 2013; Peeples et al. 2016; Peeples Roberts 2013). interval considered project region inhabited largely sedentary agricultural populations (though mobile populations also present throughout period) communities large several thousand people peak. region blessed excellent archaeological preservation, fine grained chronology anchored dendrochronological dates, nearly 150 years focused archaeological research.SWSN/cyberSW project team gathered massive database information location size tens thousands archaeological sites ceramic material cultural typological frequency data consisting millions objects explore patterns material similarity, exchange, technology change across time space study area. data well tools needed analyze available online platform called cyberSW (cyberSW.org). online platform even allows explore data directly internet browser. size complexity SWSN/cyberSW data make particularly good example discussing decision processes involved visualizing analyzing large networks.several sections book also use subsets larger data set: San Pedro Valley, Chaco World. San Pedro Valley southern Arizona well-studied portion SWSN study area (see Clark Lyons 2012; Gerald 2019) early focus network methodological exploration team (Mills et al. 2013b). data subset includes detailed ceramic typological frequency known major settlements across region late pre-Hispanic period (ca. .D. 1200-1450). Chaco World large-scale social political system spanned much Colorado Plateau ca. .D. 800-1150. settlement system marked construction massive public architectural features known great houses great kivas. subset database includes information architecture ceramic typological data large portion known Chacoan architectural complexes throughout U.S. Southwest. Chaco World major focus SWSN/cyberSW project (Giomi et al. 2021; Giomi Peeples 2019; Mills et al. 2018).networks, individual settlements treated nodes edges defined weighted based similarities ceramic wares recovered settlements. Ceramic data used generate networks apportioned sequence 50-year chronological intervals using methods described detail Roberts colleagues (2012) Ortman (2016; see discussion Mills et al. 2018) able explore change time. Site locations site attribute data also considered examples. R implementations chronological apportioning methods available GitHub well (R implementation Roberts et al. 2012, R implementation Ortman 2016).SWSN Attribute Data AD 1300-1350 - Attribute data SWSN sites dating AD 1300 1350 including site name, site sub-region (Macro), jittered easting northing UTM coordinates (Zone 12N).SWSN Similarity Data AD 1300-1350 - Symmetric similarity matrix based Brainerd-Robinson similarities SWSN sites dating AD 1300 1350.Chaco World Attribute Data AD 1050-1100 - Attribute data sites Chacoan architectural features dating AD 1050 1100 including site IDs, site names, site sub-regions, counts different kinds public architectural features, jittered easting northing UTM site locations (Zone 12N).Chaco World Ceramic Data AD 1050-1100 - Ceramic count data ware sites Chacoan architectural features dating AD 1050 1100.Chaco World Network AD 1050-1100 - Adjacency matrix binarized network ceramic similarity sites Chacoan architectural features dating AD 1050 1100.San Pedro Networks Time - .RData file contains igraph network objects San Pedro region ceramic similarity networks AD1250-1300, AD1300-1350, AD1350-1400.","code":""},{"path":"DataAndWorkspace.html","id":"Cibola","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.4 Cibola Region Technological Similarity Networks","text":"Cibola region along Arizona New Mexico border U.S. Southwest large diverse physiographic region spanning southern edge Colorado Plateau ancestral homeland contemporary Zuni (:shiwi) people. Peeples colleagues (Peeples 2011, 2018; Peeples et al. 2021) explored patterns technological similarity communities practice region series sites dating ca. .D. 1100-1350 explorations corrugated ceramic cooking pots. Corrugated pots, produced across much U.S. Southwest least 9th 14th centuries, coiled ceramic vessels coils used make vessel never fully smoothed. Thus, ceramics retain substantial amounts evidence specific techniques used produce .book use data ceramic technological production techniques generate similarity networks originally published Peeples (2011; 2018). networks settlement treated node similarity metrics defining weights edges pairs sites based analysis number metric coded attributes individual ceramic vessels. addition material cultural data, also additional site attributes location types frequency public architectural features.Ceramic technological data Peeples (2018): Additional data documentation project available tDAR collection. Nodes defined individual settlements edges defined based similarities technological attributes cooking pots recovered settlements. details methods assumptions used define networks see Peeples (2018, pg. 100-104).Cibola Ceramic Technological Clusters - Counts ceramic technological clusters sites Cibola region sample.Cibola Site Attributes - Site location, public architectural feature types, sub-region designations sites Cibola region sample.Cibola Binary Network Edge List - Binary edge list Cibola technological similarity network.Cibola Binary Network Adjacency Matrix - Binary adjacency matrix Cibola technological similarity network.Peeples2018.Rdata - file contains number objects R format including site attributes (site_info), symmetric Brainerd-Robinson similarity matrix (ceramic_br), binary network object statnet/network format (brnet), weighted network object network format (brnet_w)","code":""},{"path":"DataAndWorkspace.html","id":"Himalaya","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.5 Himalayan Visibility Networks","text":"Hundreds forts small fortified structures located mountain tops ridges central Himalayan region Garhwal Uttarakhand (India). Despite prominent feature history region interwoven local folklore (Garhwal derived ‘land forts’), fortification phenomenon received little research attention. might origins downfall Katyuri dynasty 11th century continued 15th century region consolidated Parmar dynasty possibly even later attested Mughal, Tibetan, British aggression.book use research context example spatial networks specifically visibility networks.made possible thanks survey forts region performed context PhD project Dr Nagendra Singh Rawat (2017). use catalog 193 sites (Rawat et al. 2020, Appendix S1), use case Chaundkot fort surroundings particular case study. Chaundkot fort theorized one key strongholds region also one partly excavated (Rawat Nautiyal 2020). case studies represent strongholds nodes, ability line--sight exist observers located pair strongholds represented directed edge. length line--sight represented edge attribute.Himalayan Node data - Node attribute data Himalayan sites including locations lat/long, elevation, site name/type, descriptions landscape features.Himalayan Edge List - Edge list data information connections among nodes within 25kms information distance whether target site visible source. Note edges Visible = TRUE included activated edges.","code":""},{"path":"DataAndWorkspace.html","id":"ArchPubs","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.6 Archaeological Publication Networks","text":"knowledge stories past human behavior much shaped material remains excavate, actions interactions archaeologists study . Aspects actions interactions formally represented publications. papers can co-authored, reflecting scientific collaboration networks communities practice. Authors cite authors’ works indicate explicitly influenced related paper’s subject matter.previous work, turned tools archaeological network science archaeological network researchers (Brughmans 2013; Brughmans Peeples 2017). studied co-authorship citation practices 250 publications applied formal network methods archaeological research topics 1968 present. list publications, undirected co-authorship network can made representing individual authors nodes, connecting pair authors edge co-authors one papers, edge values representing number papers co-authored. Moreover, directed citation network can made bibliographies list publications. citation network, node represents individual publication connected publications bibliography directed edge. edge goes citing publication cited publication, represents source direction academic influence explicitly expressed publication. use networks archaeological network research publications throughout volume illustrate concepts like acyclic structure citation networks.Publication Networks Attribute Data - Attribute data table including information publications including unique key identifier, publication type, publication title, publication date, author list separated semi-colons.Publication Networks Co-Authorship Incidence Matrix - incidence matrix unique publications rows authors columns.","code":""},{"path":"DataAndWorkspace.html","id":"Guadalquivir","chapter":"Section 2 Data and Workspace Setup","heading":"2.1.7 Iron Age Sites in Southern Spain","text":"Guadalquivir river valley south Spain present-day Seville Córdoba densely urbanized late Iron Age (early 5th c. B.C. late 3rd c. B.C.). Many settlements dotted along rivers southern part valley (Fig. 2.6), settlement pattern focused nuclear settlements sometimes referred oppida. reveal defensive architecture many located elevations. Previous studies Iron Age settlements region explored possible explanations locations (Keay Earl 2011; Brughmans et al. 2014, 2015). Given elevated locations, one theory received considerable attention intervisibility. small settlements surrounding oppida seen , oppida located partly allow visual control surrounding settlements? groups Iron Age settlements tend intervisible, forming communities visible daily basis? chains intervisibility allowed passing information one site another via visual smoke fire signals, chains follow key communication medium area: navigable rivers?questions explored previous research using GIS network methods, using data set 86 sites lines--sight connecting pairs Iron Age settlements distances 20km large fire smoke signals visible (data set research topic: Keay Earl 2011; Brughmans et al. 2014, 2015). account errors Digital Elevation Model (DEM), probabilistic line--sight analysis performed introduces random errors DEM can blocking enhancing effect lines--sight. locations 86 sites network displayed figure 2.9 also available Appendix Brughmans et al. 2014. locations used Chapter 7 book illustrate spatial network models explore different geographical structures might underlie settlement pattern.Guadalquivir settlement data - Site number locations decimal degrees sites Guadalquivir survey area.","code":""},{"path":"DataAndWorkspace.html","id":"Importing","chapter":"Section 2 Data and Workspace Setup","heading":"2.2 Importing Data in R","text":"section briefly describes data provided (data) can imported R analyses (see Working Files info). running code , however, need ensure R session set correct working directory (location placed .csv files just downloaded). , go menu bar top click Session > Set Working Directory > Choose Directory navigate place hard drive files reside.example read Cibola_edgelist.csv file define object called el1 includes data file using read.csv() command. Note case file want read sub-folder working directory called “data” need use data/ prefix file name correctly call file. chose use sub-folder call folder something else, need modify data/ section code.addition .csv files, several examples book several data sets provide .RData files can read directly R can contain multiple R objects. can read directly R environment using load() function. See example . note must specify specific directory within working directory file located.","code":"\n# read in data with first row representing column names (header=TRUE)\nel1 <- read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\n# look at the first few rows\nhead(el1)##           FROM                   TO\n## 1 Apache Creek         Casa Malpais\n## 2 Apache Creek         Coyote Creek\n## 3 Apache Creek         Hooper Ranch\n## 4 Apache Creek      Horse Camp Mill\n## 5 Apache Creek        Hubble Corner\n## 6 Apache Creek Mineral Creek Pueblo\nload(\"data/map.RData\")"},{"path":"DataAndWorkspace.html","id":"PrimaryPackages","chapter":"Section 2 Data and Workspace Setup","heading":"2.3 Required/Suggested R Packages","text":"\nappendix rely number pre-existing R packages. \norder use packages new installation R R-studio, \nfirst need install . Note need \nnew installation R. install packages, can click \n“Packages” tab window bottom right R studio, click\n“Install” button top type names packages\nseparated commas. Alternatively can install packages \nconsole simply typing\ninstall.packages(“nameofpackagehere”).\ninstall.packages(c(\"statnet\", \"igraph\"))use number R packages modules book manipulating analyzing network data general analyses procedures. frequently used network packages include:igraph (Csardi Nepusz 2006) - analytical routines simple graphs graph analysisstatnet (Krivitsky et al. 2020) - suite packages designed management statistical analysis networks including network, sna, ergm, others.intergraph (Bojanowski 2015) - set routines coercing objects common network formats Rggraph (Pederson 2021) - powerful graph visualization package based ggplot2 plotting formatThroughout Online Companion, consistently rely igraph statnet (statnet actually suite packages includes sna, network, ergm, others). part two packages many things. can use calculate centrality metrics, define groups, evaluate network structures. general igraph bit centered complex networks mathematical models statnet affiliated packages focused social network analysis though considerable overlap.Although igraph statnet suite packages many features, directly compatible use different network formats store data R. Adding potential confusion, function call names often two packages. example degree centrality calculated using degree() function . simply use degree() call R use function whichever package initialized recently. wrong package data format, get error. order avoid errors clear ambiguity use package name followed :: function call (.e., igraph::function_name sna::function_name) R knows package intend use. can R function want specify package (package::function_name).general Online Companion use igraph package wherever possible find data format especially functions converting network data types useful intuitive kinds analyses. use statnet affiliated packages specific cases igraph lacks specific functionality important features. Luckily package called intergraph lets us easily convert network objects one format another see examples ahead.Finally, recommend installing ggraph useful intuitive package allows diverse network visualizations customization. four packages account bulk examples book. discuss use package detail visualization section guide.","code":""},{"path":"DataAndWorkspace.html","id":"ShouldIInstall","chapter":"Section 2 Data and Workspace Setup","heading":"2.3.1 Should I Just Install Everything?","text":"matter plan working documents, install packages following chunk minimum running code . packages get everything Sections 1 4 much Sections 5 6.plenty disk space time don’t wont worry installing packages piecemeal, can install everything time using code . Note large number packages dependencies many used one two places Online Companion. packages used network visualization section making plots specific features. generally recommend install packages need work document .choose install everything, however, can simply run chunk code . Note code re-install packages already installed current version R. Note familiar Git R Environments, much faster just use renv::restore() function build environment repository. See Reproducibility section introduction information.\naddition R packages listed , couple \nprocedures used Online Companion (especially “Going\nBeyond Book” section) require installation \nPython 3.8 particular packages associated . order \nimplement sections code, need also run \nfollowing lines code. Note large install takes\n1.4 GB hard drive space \nspace REALLY want explore edge bundling (see Edge Bundling Visualizations) network comparison methods. \nable reproduce everything document except two chunks \ncode main section procedures Comparing Networks\nsection without feel free sit one .\ninstall Python required libraries, run following chunk code. Keep mind take several minutes 1.4 GB disk space:","code":"\npackages <- c(\"igraph\", \"statnet\", \"intergraph\", \"ggraph\",\n              \"reshape2\", \"ggmap\", \"vegan\", \"sf\")\n\ninstall.packages(setdiff(packages, rownames(installed.packages())))\npackages <- c(\"tidyverse\", \"ape\", \"devtools\", \"igraph\", \"statnet\", \"intergraph\",\n  \"tnet\", \"ggplot2\", \"rjson\", \"d3r\", \"cccd\", \"networkD3\", \"visNetwork\",\n  \"GISTools\", \"rgeos\", \"maptools\", \"sf\", \"igraphdata\", \"ggrepel\",\n  \"ggsn\", \"tidyverse\", \"superheat\", \"ggplotify\", \"ggforce\", \"colorspace\",\n  \"ggmap\", \"dplyr\", \"ggpubr\", \"ggraph\", \"reshape2\", \"multinet\",\n  \"RColorBrewer\", \"Rcpp\", \"deldir\", \"vegan\", \"geosphere\", \"networkDynamic\",\n  \"scatterplot3d\", \"patchwork\", \"concaveman\", \"latticeExtra\",\n  \"orca\", \"pracma\", \"netdiffuseR\", \"graphkernels\")\n\ninstall.packages(setdiff(packages, rownames(installed.packages())))\n\ndevtools::install_github(\"liamgilbey/ggwaffle\")\ndevtools::install_github(\"QiliShi/NetworkSim\")\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\nBiocManager::install(\"RBGL\")\ninstall.packages(\"edgebundle\", \"reticulate\")\nlibrary(edgebundle)\nlibrary(reticulate)\ninstall_bundle_py(method = \"auto\", conda = \"auto\")"},{"path":"DataAndWorkspace.html","id":"Environment","chapter":"Section 2 Data and Workspace Setup","heading":"2.3.2 R Environment","text":"version book built R version 4.2.2 (2022-10-31 ucrt) following packages:","code":""},{"path":"DataAndWorkspace.html","id":"WorkspaceSetup","chapter":"Section 2 Data and Workspace Setup","heading":"2.4 Suggested Workspace Setup","text":"order follow along examples Online Companion easiest set R working directory similar format used creating . Specifically, suggest create new working directory create R studio project tied specific directory.order , open R-Studio go “File > New Project” click “New Directory > New Project” dialog give appropriate name location computer. Next, navigate location computer create two sub-folders: one called “data” one called “scripts” (directory names case sensitive). Place data files downloaded section Online Companion “data” folder R script files download “scripts” folder.\nNote chose “Just Give Everything” download \n.zip file already contains sub-folder called “data”\nsure ’re double nesting folders (want\n“working_directory/data” “working_directory/data/data”).\nclose R see dialog asks want save work space image. provide name, can reopen .RData file later time pick exactly previous session left .new R environment file structures, suggest review Getting Started R section information.","code":""},{"path":"NetworkData.html","id":"NetworkData","chapter":"Section 3 Network Data in R","heading":"Section 3 Network Data in R","text":"network simply set entities formally defined relationships among . , however, many different ways networks can encoded displayed. section provides examples many common network formats data types discussed Chapter 3 Brughmans Peeples 2023. examples use Cibola technological similarity network data set (described Chapter 2.8.3 ) relatively small easy display variety formats.Throughout document, refer unique bounded entities connected formal network nodes connections edges note many terms used literature documentation R packages used . Nodes often referred vertices actors edges often referred ties links. Note use network refer formal system interdependent pairwise relationships (edges) among set entities (nodes) term graph often used equivalently mathematics fields.","code":""},{"path":"NetworkData.html","id":"NetworkDataFormats","chapter":"Section 3 Network Data in R","heading":"3.1 Network Data Formats","text":"section follows Chapter 3.2 Brughmans Peeples (2023) provide examples network attribute data variety different data formats well code converting among formats R.network data formats discuss section include:Edge list - network data format consisting list connected node pairs. E=((n1,n2),(n1,n3),(n1,n4),…,(ni,nj)). can also represented matrix two columns source target nodes respectively one edge per row.Adjacency list - network data format consisting set rows, first node row connected subsequent nodes row.Adjacency matrix - network data format consisting matrix size n x n, set rows equal number nodes, set columns equal number nodes. pair nodes connected edge (.e., adjacent), corresponding cell entry.Incidence matrix - network data format consisting matrix size n x e, set rows equal number nodes, set columns equal number edges. entry made cell corresponding node edge connected. column incidence matrix two entries.Let’s first get started initializing packages use section.\nprimary packages used Section (igraph,\nstatnet, intergraph) already described\nlast section. also use \nvegan package includes many functions focused \ncommunity ecology. document, rely package \ncalculate several distance/similarity metrics useful \ngenerating similarity networks.\nFinally, provide brief example end section using\nmultinet package focused conducting multilayer network analyses.\n","code":"\n# initialize packages\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(vegan)\nlibrary(multinet)"},{"path":"NetworkData.html","id":"NetworkDataFunctions","chapter":"Section 3 Network Data in R","heading":"3.1.1 Defining Network Objects in R","text":"general examples network data formats remainder section converted R network objects two basic steps.First, read external data file contains network data, usually generated sort spreadsheet program, create R data frame matrix object.Next, call function expects given data format (edge list, adjacency matrix, incidence matrix, etc.) converts R network object.see , mostly rely igraph functions take following basic format:igraph::graph_from_**DataType****DataType** replaced appropriate format edgelist, adjacency_matrix, . examples plot network just confirm everything works, certainly optional.","code":""},{"path":"NetworkData.html","id":"Edgelist","chapter":"Section 3 Network Data in R","heading":"3.1.2 Edge List","text":"edge list quick easy way capture network data. simply lists edges network one one node id: E=((n1,n2),(n1,n3),(n1,n4),…,(ni,nj)). purposes data management usually easiest create edge list data frame matrix row represents pair nodes connections going node one column node second column (additional columns can used edge weight edge attributes).example, import Cibola data set format data frame convert igraph network object analysis. can download edge list file follow along . Since edges network undirected simple binary network, use directed = FALSE argument igraph::graph_from_edgelist function call. function simply takes edge list tabular format converts network object R recognizes can used analysis visualization.","code":"\n# Read in edge list file as data frame\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\n\n# Examine the first several rows\nhead(cibola_edgelist)##           FROM                   TO\n## 1 Apache Creek         Casa Malpais\n## 2 Apache Creek         Coyote Creek\n## 3 Apache Creek         Hooper Ranch\n## 4 Apache Creek      Horse Camp Mill\n## 5 Apache Creek        Hubble Corner\n## 6 Apache Creek Mineral Creek Pueblo\n# Create graph object. The data frame is converted to a matrix as that\n#is required by this specific function. Since this is an undirected\n# network directed = FALSE.\ncibola_net <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist),\n                              directed = FALSE)\n\n# Display igraph network object and then plot a simple node-link diagram\ncibola_net## IGRAPH a94a035 UN-- 30 167 -- \n## + attr: name (v/c)\n## + edges from a94a035 (vertex names):\n##  [1] Apache Creek--Casa Malpais          Apache Creek--Coyote Creek         \n##  [3] Apache Creek--Hooper Ranch          Apache Creek--Horse Camp Mill      \n##  [5] Apache Creek--Hubble Corner         Apache Creek--Mineral Creek Pueblo \n##  [7] Apache Creek--Rudd Creek Ruin       Apache Creek--Techado Springs      \n##  [9] Apache Creek--Tri-R Pueblo          Apache Creek--UG481                \n## [11] Apache Creek--UG494                 Atsinna     --Cienega              \n## [13] Atsinna     --Los Gigantes          Atsinna     --Mirabal              \n## [15] Atsinna     --Ojo Bonito            Atsinna     --Pueblo de los Muertos\n## + ... omitted several edges\n# Set random seed to ensure graph layout stays the same each time.\nset.seed(3523)\nplot(cibola_net)"},{"path":"NetworkData.html","id":"AdjacencyList","chapter":"Section 3 Network Data in R","heading":"3.1.3 Adjacency List","text":"adjacency list consists set rows, first node row connected subsequent nodes row. therefore concise edge list (relationship row), unlike edge list result rows equal length (row edge list typically two values, representing pair nodes). Adjacency lists relatively rare practice can sometimes useful formats directly gathering network data small networks supported many network analysis software packages.following chunk code, convert network object created adjacency list using igraph::as_adj_edge_list() function examine couple rows.output particular node can called either referencing name using using $ followed site name [[k]] double brackets k row number node question. printed output essentially list edges incident node question identified name sending receiving node.","code":"\n# Convert edge list to adjacency list using igraph function\nadj_list <- igraph::as_adj_edge_list(cibola_net)\n\n# examine adjacency list for the site Apache Creek\nadj_list$`Apache Creek`## + 11/167 edges from a94a035 (vertex names):\n##  [1] Apache Creek--Casa Malpais         Apache Creek--Coyote Creek        \n##  [3] Apache Creek--Hooper Ranch         Apache Creek--Horse Camp Mill     \n##  [5] Apache Creek--Hubble Corner        Apache Creek--Mineral Creek Pueblo\n##  [7] Apache Creek--Rudd Creek Ruin      Apache Creek--Techado Springs     \n##  [9] Apache Creek--Tri-R Pueblo         Apache Creek--UG481               \n## [11] Apache Creek--UG494\n# It is also possible to call specific nodes by number. In this case,\n# site 2 is Casa Malpais\nadj_list[[2]]## + 11/167 edges from a94a035 (vertex names):\n##  [1] Apache Creek--Casa Malpais    Casa Malpais--Coyote Creek   \n##  [3] Casa Malpais--Hooper Ranch    Casa Malpais--Horse Camp Mill\n##  [5] Casa Malpais--Hubble Corner   Casa Malpais--Rudd Creek Ruin\n##  [7] Casa Malpais--Techado Springs Casa Malpais--Tri-R Pueblo   \n##  [9] Casa Malpais--UG481           Casa Malpais--Garcia Ranch   \n## [11] Casa Malpais--Hinkson"},{"path":"NetworkData.html","id":"AdjacencyMatrix","chapter":"Section 3 Network Data in R","heading":"3.1.4 Adjacency Matrix","text":"adjacency matrix perhaps common versatile network data format data analysis network science (sociology sometimes referred sociomatrix). symmetric matrix size n x n, set rows columns denoting nodes network. node names identifiers typically used label rows columns. pair nodes connected edge (.e. adjacent), corresponding cell entry. diagonal matrix represents “self loops” can variously defined connected unconnected depending application.can obtain adjacency matrix object R converting network object created reading file directly rows columns denoting site 0 1 denoting presence absence relation. take data frame object adj_mat square matrix 1s 0s convert network object using igraph::graph_from_adjacency_matrix() function. can download csv file follow along .Note compare network graph one produced based edge list additional unconnected node (WS Ranch) shown previous network. one advantages adjacency matrix provides way easily including unconnected nodes without manually add include self-loops.","code":"\n# Convert to adjacency matrix then display first few rows/columns\nadj_mat <- igraph::as_adjacency_matrix(cibola_net)\nadj_mat[1:5, 1:5]## 5 x 5 sparse Matrix of class \"dgCMatrix\"\n##                 Apache Creek Casa Malpais Coyote Creek Hooper Ranch\n## Apache Creek               .            1            1            1\n## Casa Malpais               1            .            1            1\n## Coyote Creek               1            1            .            1\n## Hooper Ranch               1            1            1            .\n## Horse Camp Mill            1            1            1            1\n##                 Horse Camp Mill\n## Apache Creek                  1\n## Casa Malpais                  1\n## Coyote Creek                  1\n## Hooper Ranch                  1\n## Horse Camp Mill               .\n# Read in adjacency matrix and convert to network object for plotting\nadj_mat2 <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = T,\n           row.names = 1)\n\nadj_mat2[1:4, 1:4]##              Apache.Creek Atsinna Baca.Pueblo Casa.Malpais\n## Apache Creek            0       0           0            1\n## Atsinna                 0       0           0            0\n## Baca Pueblo             0       0           0            0\n## Casa Malpais            1       0           0            0\ncibola_net2 <-\n  igraph::graph_from_adjacency_matrix(as.matrix(adj_mat2),\n                                      mode = \"undirected\")\nset.seed(4352)\nplot(cibola_net2)"},{"path":"NetworkData.html","id":"IncidenceMatrix","chapter":"Section 3 Network Data in R","heading":"3.1.5 Incidence Matrix","text":"incidence matrix frequently used define connections among different sets nodes two-mode bipartite network rows columns represent two different classes nodes presence/absence value edge indicated corresponding cell.way example can read data used generate one-mode networks ceramic technological similarity examining far. corresponding data frame, row represents site column represents specific cluster technological attributes cooking pottery (see Peeples 2018, pg. 100-104 details) number cell representing count technological cluster site.reading rectangular data frame, can create network object using igraph::graph_from_incidence_matrix() function. plot simple two-mode network color representing node class. discuss plotting options greater detail visualization section document. can download csv file follow along .","code":"\n# Read in two-way table of sites and ceramic technological clusters\ncibola_clust <-\n  read.csv(file = \"data/Cibola_clust.csv\",\n           header = TRUE,\n           row.names = 1)\nhead(cibola_clust)##              Clust1 Clust2 Clust3 Clust4 Clust5 Clust6 Clust7 Clust8 Clust9\n## Apache Creek      7      3      6     16      6      1      1      2      0\n## Atsinna           0     12     26      5      0      1      6      0      7\n## Baca Pueblo       0      9      3     12      1      2      5      0     16\n## Casa Malpais      2     15      7     28     17     16      2      5      1\n## Cienega           2     28     34      2      0     10     11      0      5\n## Coyote Creek     10     13      8     30     20      5      1      8      0\n##              Clust10\n## Apache Creek       0\n## Atsinna            0\n## Baca Pueblo        1\n## Casa Malpais       0\n## Cienega            1\n## Coyote Creek       5\n# Convert into a network object using the incidence matrix format. Note that\n# multiple=TRUE as we want this defined as a bipartite network.\ncibola_inc <-\n  igraph::graph_from_incidence_matrix(cibola_clust,\n                                      directed = FALSE,\n                                      multiple = TRUE)\nhead(cibola_inc)## 6 x 41 sparse Matrix of class \"dgCMatrix\"\n##                                                                              \n## Apache Creek . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  7\n## Atsinna      . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .\n## Baca Pueblo  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .\n## Casa Malpais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  2\n## Cienega      . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  2\n## Coyote Creek . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n##                                      \n## Apache Creek  3  6 16  6  1  1 2  . .\n## Atsinna      12 26  5  .  1  6 .  7 .\n## Baca Pueblo   9  3 12  1  2  5 . 16 1\n## Casa Malpais 15  7 28 17 16  2 5  1 .\n## Cienega      28 34  2  . 10 11 .  5 1\n## Coyote Creek 13  8 30 20  5  1 8  . 5\nset.seed(4543)\n# Plot as two-mode network\nplot(cibola_inc, vertex.color = as.numeric(V(cibola_inc)$type) + 1)"},{"path":"NetworkData.html","id":"NodeAttributes","chapter":"Section 3 Network Data in R","heading":"3.1.6 Node and Edge Information","text":"Frequently want use information nodes edges (node location, site type, edge weight, etc.) analyses need track data separate attribute object data column. One common way simply create data frame contains required attribute information call specific data data frame needed. following example shows, also possible directly assign attributes nodes edges igraph network object use subsequent analyses using V() nodes (V standing vertices) E() edges calls within igraph.following example use file includes basic attribute data site (node) sites network ’ve working . file includes x y coordinates sites, information presence/absence shape Great Kiva public architectural features sites, Region assigned. First read data.order assign attribute particular node edge can use V E (vertex edge) calls igraph. example, following example, assign region variable node network created using V function assign vertex attribute. simply type name network object parenthesis V use $ atomic variable symbol assign name attribute associated network object.can used plotting analyses calling variable factor (see resource Getting Started R learn factor data.","code":"\n# Read in attribute data and look at the first few rows.\ncibola_attr <- read.csv(file = \"data/Cibola_attr.csv\", header = TRUE)\nhead(cibola_attr)##           Site      x       y             Great.Kiva                Region\n## 1 Apache Creek 724125 3747310 Rectangular Great Kiva    Mogollon Highlands\n## 2      Atsinna 726741 3895499                   none       El Morro Valley\n## 3  Baca Pueblo 651431 3797143                   none Upper Little Colorado\n## 4 Casa Malpais 659021 3786211 Rectangular Great Kiva Upper Little Colorado\n## 5      Cienega 738699 3887985                   none       El Morro Valley\n## 6 Coyote Creek 671154 3780509 Rectangular Great Kiva Upper Little Colorado\n# Assign a variable called \"region\" to the Cibola_net2 based on the\n# column in the Cibola_attr table called \"Region\"\nV(cibola_net2)$region <- cibola_attr$Region\n\n# If we now call that attribute we get a vector listing each assigned value\nV(cibola_net2)$region##  [1] \"Mogollon Highlands\"    \"El Morro Valley\"       \"Upper Little Colorado\"\n##  [4] \"Upper Little Colorado\" \"El Morro Valley\"       \"Upper Little Colorado\"\n##  [7] \"Mogollon Highlands\"    \"Carrizo Wash\"          \"Pescado Basin\"        \n## [10] \"West Zuni\"             \"Upper Little Colorado\" \"Mariana Mesa\"         \n## [13] \"Mariana Mesa\"          \"West Zuni\"             \"El Morro Valley\"      \n## [16] \"Vernon Area\"           \"El Morro Valley\"       \"West Zuni\"            \n## [19] \"Pescado Basin\"         \"Carrizo Wash\"          \"El Morro Valley\"      \n## [22] \"Upper Little Colorado\" \"El Morro Valley\"       \"West Zuni\"            \n## [25] \"Mariana Mesa\"          \"El Morro Valley\"       \"Mariana Mesa\"         \n## [28] \"Mariana Mesa\"          \"Mariana Mesa\"          \"Mogollon Highlands\"   \n## [31] \"Pescado Basin\"\n# Note that \"region\" is now listed as an attribute when we view\n# the network object\ncibola_net2## IGRAPH a965b56 UN-- 31 167 -- \n## + attr: name (v/c), region (v/c)\n## + edges from a965b56 (vertex names):\n##  [1] Apache.Creek--Casa.Malpais          Apache.Creek--Coyote.Creek         \n##  [3] Apache.Creek--Hooper.Ranch          Apache.Creek--Horse.Camp.Mill      \n##  [5] Apache.Creek--Hubble.Corner         Apache.Creek--Mineral.Creek.Pueblo \n##  [7] Apache.Creek--Rudd.Creek.Ruin       Apache.Creek--Techado.Springs      \n##  [9] Apache.Creek--Tri.R.Pueblo          Apache.Creek--UG481                \n## [11] Apache.Creek--UG494                 Atsinna     --Cienega              \n## [13] Atsinna     --Los.Gigantes          Atsinna     --Mirabal              \n## [15] Atsinna     --Ojo.Bonito            Atsinna     --Pueblo.de.los.Muertos\n## + ... omitted several edges\nset.seed(43534)\nplot(cibola_net2, vertex.color = as.factor(V(cibola_net2)$region))"},{"path":"NetworkData.html","id":"TypesOfNetworks","chapter":"Section 3 Network Data in R","heading":"3.2 Types of Networks","text":"section roughly follows Brughmans Peeples (2023) Chapter 3.3 describe provide examples R format many common types networks. examples use igraph R package also show use statnet network packages applicable.section, cover:Simple Networks - set nodes set edges additional information .Directed Networks - network consisting set nodes edges connecting orientation direction specified. words connected B, B necessarily connected .Signed, Categorized, Weighted Networks - category refers networks edges (relationships) additional nominal, ordinal, metric information encoded . signed network network edges carry positive negative sign indicating opposed property relations network. categorized network network edges classified according nominal category necessarily represent opposition. weighted network one edges carry non-binary value indicates strength given relationship.Two-Mode Networks - network two separate categories nodes defined edges defined categories.Similarity Networks - Networks edges defined weighted based quantitative metric similarity distance based node attributes artifact assemblages.Ego Networks - network including focal node, set nodes ego connected edge edges nodes set.Multilayer Networks - network single set nodes connected two sets edges represent different kind relationship among nodes.","code":""},{"path":"NetworkData.html","id":"SimpleNetworks","chapter":"Section 3 Network Data in R","heading":"3.2.1 Simple Networks","text":"call network simple network (simple graph) set nodes set edges connecting , additional information edges specific rules need follow. Simple networks , words, unweighted undirected one-mode networks. way example use Cibola region adjacency matrix file convert simple network using igraph network. Notice examples specify undirected network (mode = \"undirected\" directed = FALSE).Notice two formats differ way internally store network data R way print output screen show total 31 nodes (vertices) 167 edges (igraph object first row specifies node edge numbers – marks).","code":"\n# Read in raw adjacency matrix file\nadj_mat2 <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = T,\n           row.names = 1)\n\n# Convert to a network object using igraph\nsimple_net_i <-\n  igraph::graph_from_adjacency_matrix(as.matrix(adj_mat2),\n                                      mode = \"undirected\")\nsimple_net_i## IGRAPH a9dfa2c UN-- 31 167 -- \n## + attr: name (v/c)\n## + edges from a9dfa2c (vertex names):\n##  [1] Apache.Creek--Casa.Malpais          Apache.Creek--Coyote.Creek         \n##  [3] Apache.Creek--Hooper.Ranch          Apache.Creek--Horse.Camp.Mill      \n##  [5] Apache.Creek--Hubble.Corner         Apache.Creek--Mineral.Creek.Pueblo \n##  [7] Apache.Creek--Rudd.Creek.Ruin       Apache.Creek--Techado.Springs      \n##  [9] Apache.Creek--Tri.R.Pueblo          Apache.Creek--UG481                \n## [11] Apache.Creek--UG494                 Atsinna     --Cienega              \n## [13] Atsinna     --Los.Gigantes          Atsinna     --Mirabal              \n## [15] Atsinna     --Ojo.Bonito            Atsinna     --Pueblo.de.los.Muertos\n## + ... omitted several edges\n# Covert to a network object using statnet/network\nsimple_net_s <-\n  network::network(as.matrix(adj_mat2), directed = FALSE)\nsimple_net_s##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 167 \n##     missing edges= 0 \n##     non-missing edges= 167 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes"},{"path":"NetworkData.html","id":"DirectedNetworks","chapter":"Section 3 Network Data in R","heading":"3.2.2 Directed Networks","text":"Sometimes relationships directional, meaning orientation. example, flow river directed downstream. cases can incorporate information network data distinguishing source target edge.way example modify Cibola network edge list remove number edges random simulate directed network data. convert data various network matrix formats illustrate directed networks stored used R. first use sample function define sub-sample network nodes create network object random sub-sample. randomly removing edges edge list left directed network edges reciprocated.Notice look igraph network plot arrows indicating direction connection edge list. making directed edge list, sending node default first column receiving node second column. adjacency matrix upper lower triangles longer identical. , generating adjacency matrix, can simply mark edges sent nodes denoted rows edges received nodes columns. Finally, plot, since R recognizes directed igraph object plot network, automatically shows arrows indicating direction edge.","code":"\n# Read in edge list file as data frame\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\n\n# Create a random sub-sample of 125 edges out of the total 167 using\n# the \"sample\" function\nset.seed(45325)\nel2 <- cibola_edgelist[sample(seq(1, nrow(cibola_edgelist)), 125,\n                              replace = FALSE), ]\n\n# Create graph object from the edge list using the directed=TRUE argument\n# to ensure this is treated as a directed network object.\ndirected_net <-\n  igraph::graph_from_edgelist(as.matrix(el2), directed = TRUE)\ndirected_net## IGRAPH a9e644c DN-- 30 125 -- \n## + attr: name (v/c)\n## + edges from a9e644c (vertex names):\n##  [1] Coyote Creek   ->Techado Springs      \n##  [2] Hubble Corner  ->Tri-R Pueblo         \n##  [3] Hubble Corner  ->Techado Springs      \n##  [4] Heshotauthla   ->Pueblo de los Muertos\n##  [5] Rudd Creek Ruin->Techado Springs      \n##  [6] Heshotauthla   ->Hinkson              \n##  [7] Los Gigantes   ->Yellowhouse          \n##  [8] Los Gigantes   ->Pueblo de los Muertos\n## + ... omitted several edges\n# View as adjacency matrix of directed network object\n(as_adjacency_matrix(directed_net))[1:5, 1:5]## 5 x 5 sparse Matrix of class \"dgCMatrix\"\n##                 Coyote Creek Techado Springs Hubble Corner Tri-R Pueblo\n## Coyote Creek               .               1             1            .\n## Techado Springs            .               .             .            1\n## Hubble Corner              .               1             .            1\n## Tri-R Pueblo               .               .             .            .\n## Heshotauthla               .               .             .            .\n##                 Heshotauthla\n## Coyote Creek               .\n## Techado Springs            .\n## Hubble Corner              .\n## Tri-R Pueblo               .\n## Heshotauthla               .\n# Plot network\nset.seed(4353)\nplot(directed_net)"},{"path":"NetworkData.html","id":"WeightedNetworks","chapter":"Section 3 Network Data in R","heading":"3.2.3 Signed, Categorized, and Weighted Networks","text":"many situations want add values specific edges signs (sometimes called valences), nominal categories, weights defining strength nature relationships. variety ways can record assign weights values edges R. simplest way directly include information one formats described edge list adjacency matrix. example, can add third column edge list denotes weight, category, sign edge can fill cells adjacency matrix specific values rather simply 1s 0s.example, randomly generate edge weights Cibola network edge list adjacency matrix illustrate R handles formats. use sample function create random vector values 1 4 every edge network add edge list new variable called $Weight. convert data frame network object.Notice final plot line thickness used indicate edges various weights. explore options visualizations network visualizations section document.","code":"\n# Read in edge list file as data frame\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\n# Add additional column of weights as random integers between 1 and 4\n# for each edge\ncibola_edgelist$weight <-\n  sample(seq(1, 4), nrow(cibola_edgelist), replace = TRUE)\n\n# Create weighted network object calling only the first two columns\nweighted_net <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist[, 1:2]),\n                              directed = FALSE)\n# add edge attribute to indicate weight\nE(weighted_net)$weight <- cibola_edgelist$weight\n\n# Explore the first few rows and columns of network object\nhead(get.data.frame(weighted_net))##           from                   to weight\n## 1 Apache Creek         Casa Malpais      4\n## 2 Apache Creek         Coyote Creek      1\n## 3 Apache Creek         Hooper Ranch      1\n## 4 Apache Creek      Horse Camp Mill      3\n## 5 Apache Creek        Hubble Corner      4\n## 6 Apache Creek Mineral Creek Pueblo      4\n# View network as adjacency matrix. Notice the attr=\"weight\" command that\n# indicates which edge attribute to use for values in the matrix\nhead(as_adjacency_matrix(weighted_net, attr = \"weight\"))[1:5, 1:5]## 5 x 5 sparse Matrix of class \"dgCMatrix\"\n##                 Apache Creek Casa Malpais Coyote Creek Hooper Ranch\n## Apache Creek               .            4            1            1\n## Casa Malpais               4            .            1            1\n## Coyote Creek               1            1            .            1\n## Hooper Ranch               1            1            1            .\n## Horse Camp Mill            3            2            4            4\n##                 Horse Camp Mill\n## Apache Creek                  3\n## Casa Malpais                  2\n## Coyote Creek                  4\n## Hooper Ranch                  4\n## Horse Camp Mill               .\n# Plot the network\nset.seed(574)\nplot(weighted_net, edge.width = E(weighted_net)$weight)"},{"path":"NetworkData.html","id":"TwoMode","chapter":"Section 3 Network Data in R","heading":"3.2.4 Two-mode Networks and Affiliation Networks","text":"Two-mode networks networks two separate categories nodes defined structural variable (edges) categories. sociology, two-mode networks often used studying affiliation individuals organizations, presence professionals boards companies attendance scholars conferences (referred affiliation networks).Two-mode network data typically recorded two-way table rows columns representing two different classes nodes individual cells representing presence/absence weight edges classes nodes. way example return table ceramic technological clusters sites Cibola region data. simplest way create unweighted two-mode network data create network object directly two-way table saw . example create edge site technological cluster present irrespective relative frequency using igraph::graph_from_incidence_matrix function.case since clusters present sites, creates pretty busy network may particularly useful. alternative define threshold (either terms raw count proportion) define edge node one class another. provide example build function modify data. function can set proportion threshold like used define edge two classes nodes. proportion cluster site greater equal threshold edge present. example threshold set 0.25 meaning define edges nodes share common type makes least quarter assemblage sites.Notice now far fewer edges familiar sites question might notice clear regional patterning.also possible create one-mode projections two-mode data using simple matrix algebra. need multiply matrix transpose matrix. results adjacency matrix whichever set nodes represented rows first matrix matrix multiplication. example using mod_clust incidence matrix threshold created . resulting incidence matrix individual cells represent number different edges common nodes question can treated like edge weight. diagonal matrix total number clusters present site assemblage. R operator %*% indicates matrix multiplication function t() transpose given matrix.","code":"\n# Read in two-way table of sites and ceramic technological clusters\ncibola_clust <- read.csv(file = \"data/Cibola_clust.csv\",\n                         header = TRUE,\n                         row.names = 1)\n# Create network from incidence matrix based on presence/absence of\n# a cluster at a site\ncibola_inc <- igraph::graph_from_incidence_matrix(cibola_clust,\n                                                  directed = FALSE,\n                                                  multiple = TRUE)\ncibola_inc## IGRAPH aa0c58a UN-B 41 2214 -- \n## + attr: type (v/l), name (v/c)\n## + edges from aa0c58a (vertex names):\n##  [1] Apache Creek--Clust1 Apache Creek--Clust1 Apache Creek--Clust1\n##  [4] Apache Creek--Clust1 Apache Creek--Clust1 Apache Creek--Clust1\n##  [7] Apache Creek--Clust1 Apache Creek--Clust2 Apache Creek--Clust2\n## [10] Apache Creek--Clust2 Apache Creek--Clust3 Apache Creek--Clust3\n## [13] Apache Creek--Clust3 Apache Creek--Clust3 Apache Creek--Clust3\n## [16] Apache Creek--Clust3 Apache Creek--Clust4 Apache Creek--Clust4\n## [19] Apache Creek--Clust4 Apache Creek--Clust4 Apache Creek--Clust4\n## [22] Apache Creek--Clust4 Apache Creek--Clust4 Apache Creek--Clust4\n## + ... omitted several edges\nset.seed(4537643)\n# Plot as two-mode network\nplot(cibola_inc, vertex.color = as.numeric(V(cibola_inc)$type) + 1)\n# Define function for creating incidence matrix with threshold\ntwo_mode <- function(x, thresh = 0.25) {\n  # Create matrix of proportions from x input into function\n  temp <- prop.table(as.matrix(x), 1)\n  # Define anything with greater than or equal to threshold as\n  # present (1)\n  temp[temp >= thresh] <- 1\n  # Define all other cells as absent (0)\n  temp[temp < 1] <- 0\n  # Return the new binarized table as output of the function\n  return(temp)\n}\n\n# Run the function and create network object\n# thresh is set to 0.25 but could be any values from 0-1\nmod_clust <- two_mode(cibola_clust, thresh = 0.25)\n# Examine the first few rows\nhead(mod_clust)##              Clust1 Clust2 Clust3 Clust4 Clust5 Clust6 Clust7 Clust8 Clust9\n## Apache Creek      0      0      0      1      0      0      0      0      0\n## Atsinna           0      0      1      0      0      0      0      0      0\n## Baca Pueblo       0      0      0      0      0      0      0      0      1\n## Casa Malpais      0      0      0      1      0      0      0      0      0\n## Cienega           0      1      1      0      0      0      0      0      0\n## Coyote Creek      0      0      0      1      0      0      0      0      0\n##              Clust10\n## Apache Creek       0\n## Atsinna            0\n## Baca Pueblo        0\n## Casa Malpais       0\n## Cienega            0\n## Coyote Creek       0\n# Create a graph matrix from the new incidence matrix\ntwo_mode_net <- igraph::graph_from_incidence_matrix(\n                          mod_clust,\n                          directed = FALSE,\n                          multiple = TRUE)\n\n# Plot results\nset.seed(4537)\nplot(two_mode_net,\n     vertex.color = as.numeric(V(cibola_inc)$type) + 1)\n# In R the command \"%*%\" indicates matrix multiplication and \"t()\"\n# gives the transpose of the matrix within the parentheses.\n# Lets first create a one-mode projection focused on sites\nsite_mode <- mod_clust %*% t(mod_clust)\nsite_net <- igraph::graph_from_adjacency_matrix(site_mode,\n                                                mode = \"undirected\",\n                                                diag = FALSE)\nplot(site_net)\n# Now lets create a one-mode projection focused on ceramic\n# technological clusters.\n# Notice that the only change is we switch which side of the\n# matrix multiplication we transpose.\nclust_mode <- t(mod_clust) %*% mod_clust\nhead(clust_mode)##        Clust1 Clust2 Clust3 Clust4 Clust5 Clust6 Clust7 Clust8 Clust9 Clust10\n## Clust1      1      0      0      0      0      0      0      0      0       0\n## Clust2      0     16      9      1      0      2      0      0      0       0\n## Clust3      0      9     10      0      0      1      0      0      0       0\n## Clust4      0      1      0     11      1      0      0      0      0       0\n## Clust5      0      0      0      1      1      0      0      0      0       0\n## Clust6      0      2      1      0      0      2      0      0      0       0\nclust_net <- igraph::graph_from_adjacency_matrix(clust_mode,\n                                                 mode = \"undirected\",\n                                                 diag = FALSE)\nplot(clust_net)"},{"path":"NetworkData.html","id":"SimilarityNetworks","chapter":"Section 3 Network Data in R","heading":"3.2.5 Similarity Networks","text":"Similarity networks simply refer one-mode networks nodes defined entities interest edges defined /weighted based metric similarity (distance) defined based features, attributes, assemblage associated node. approach frequently used archaeology explore material cultural networks nodes contexts interests (e.g., sites, excavation units, houses, etc.) edges defined weighted based similarities relative frequencies artifacts particular classes artifacts recovered contexts.many different ways define track similarity network data use R. example, show several methods using affiliation data used previous example. Specifically, define weight edges based similarities frequencies ceramic technological clusters sites Cibola region sample.examples use statnet package network package object format within rather igraph statnet additional functions useful working similarity data. following examples, first demonstrate several different similarity/distance metrics discuss approaches binarization similarity networks options working weighted data.","code":""},{"path":"NetworkData.html","id":"BrainerdRobinson","chapter":"Section 3 Network Data in R","heading":"Brainerd-Robinson Similarity","text":"first metric explore rescaled version Brainerd-Robinson (BR) similarity metric. BR measure commonly used archaeology including number recent (recent) network studies. measure represents total similarity proportional representation categories defined :\\[S = {\\frac{2-\\sum_{k} \\left|x_{k} - y_{k}\\right|} {2}}\\], categories \\(k\\), \\(x\\) proportion \\(k\\) first assemblage \\(y\\) proportion \\(k\\) second. subtract sum 2 2 maximum proportional difference possible two samples. divide result 2. provides scale similarity 0 1 1 perfect similarity 0 indicates similarity. chunk defines code calculating modified BR similarity measure. Note use distance metric called “Manhattan Distance” built vegan package R. metric identical Brainerd-Robinson metric. rescale results range 0 1 calculation.point simply define weighted network object weights equal similarity scores, define threshold defining edges present absent. discuss options detail presenting similarity/distance metrics.","code":"\n# Read in raw data\ncibola_clust <-\n  read.csv(file = \"data/Cibola_clust.csv\",\n           header = TRUE,\n           row.names = 1)\n\n# First we need to convert the ceramic technological clusters into proportions\nclust_p <- prop.table(as.matrix(cibola_clust), margin = 1)\n\n# The following line uses the vegdist function in the vegan package\n# to calculate the Brainerd-Robinson similarity score. Since vegdist\n# by default defines an unscaled distance we must subtract the results\n# from 2 and then divide by 2 to get a similarity scaled from 0 to 1.\ncibola_br <- ((2 - as.matrix(vegan::vegdist(clust_p,\n                                           method = \"manhattan\"))) / 2)\n\n# Lets look at the first few rows.\ncibola_br[1:4, 1:4]##              Apache Creek   Atsinna Baca Pueblo Casa Malpais\n## Apache Creek    1.0000000 0.3433584   0.4455782    0.7050691\n## Atsinna         0.3433584 1.0000000   0.5750090    0.3740804\n## Baca Pueblo     0.4455782 0.5750090   1.0000000    0.5608953\n## Casa Malpais    0.7050691 0.3740804   0.5608953    1.0000000"},{"path":"NetworkData.html","id":"Morisita","chapter":"Section 3 Network Data in R","heading":"3.2.5.1 Morisita’s Overlap Index","text":"Another measure used defining similarities among assemblages archaeological similarity networks Morisita’s overlap index. measure measure overlap individual assemblages within larger population takes size samples account. Specifically, approach assumes sample size increases diversity likely increase. measure produces results similar Brainerd-Robinson metric practice cases measure may preferred dramatic differences assemblage sizes among observations.Morisita’s index calculated :\\[C_D=\\frac{2 \\Sigma^Sx_iy_i}{(D_x + D_y)XY}\\]\\(x_i\\) number rows category \\(\\) represented total \\(X\\) population.\\(y_i\\) number rows category \\(\\) presented total \\(Y\\) population.\\(D_x\\) \\(D_y\\) Simpson’s diversity index values \\(x\\) \\(y\\) respectively.\\(S\\) total number columns.metric ranges 0 (categories overlap ) 1 categories occur proportions samples. metric works absolute counts can run vegdist function directly Cibola_clust object. want similarity rather distance (default function R) subtract results 1.","code":"\n# Calculate matrix of Morisita similarities based on the\n# Cibola_clust two-way table.\ncibola_mor <- 1 - as.matrix(vegan::vegdist(cibola_clust,\n                                           method = \"morisita\"))\ncibola_mor[1:4, 1:4]##              Apache Creek   Atsinna Baca Pueblo Casa Malpais\n## Apache Creek    1.0000000 0.4885799   0.6014729    0.9060751\n## Atsinna         0.4885799 1.0000000   0.5885682    0.4459998\n## Baca Pueblo     0.6014729 0.5885682   1.0000000    0.6529069\n## Casa Malpais    0.9060751 0.4459998   0.6529069    1.0000000"},{"path":"NetworkData.html","id":"ChiSquare","chapter":"Section 3 Network Data in R","heading":"\\(\\chi^{2}\\) Distance","text":"next measure use \\(\\chi^{2}\\) distance metric basis correspondence analysis related methods commonly used frequency seriation archaeology (note probably really called \\(\\chi\\) distance since typical form use squared, name persists way literature ’s use ). measure defined :\\[\\chi_{jk} = \\sqrt{\\sum \\frac 1{c_{j}}\n({x_{j}-y_{j})^{2}}}\\]\\(c_j\\) denotes \\(j_{th}\\) element average row profile (proportional abundance \\(j\\) across rows) \\(x\\) \\(y\\) represent row profiles two sites comparison. metric therefore takes raw abundance (rather simply proportional representation) account defining distance sites. definition metric rare categories play greater role defining distances among sites common categories (correspondence analysis). measure minimum value 0 theoretical upper limit.code calculating \\(\\chi^{2}\\) distances defined chunk new object called Cibola_X created using measure. sometimes preferable rescale measure bounded 0 1. create second object called Cibola_X01 represents rescaled distances simply dividing matrix maximum observed value (many ways fine demonstration purposes). , subtract results 1 convert distance similarity.","code":"\n# Define function for calculating chi-squared distance\nchi_dist <- function(x) {\n  # calculates the profile for every row\n  rowprof <- x / apply(x, 1, sum)\n  # calculates the average profile\n  avgprof <- apply(x, 2, sum) / sum(x)\n  # creates a distance object of chi-squared distances\n  chid <- dist(as.matrix(rowprof) %*% diag(1 / sqrt(avgprof)))\n  # return the results\n  return(as.matrix(chid))\n}\n\n# Run the script and then create the rescaled 0-1 version\ncibola_x <- chi_dist(cibola_clust)\ncibola_x01 <- 1 - (cibola_x / max(cibola_x))\n\ncibola_x01[1:4, 1:4]##              Apache Creek   Atsinna Baca Pueblo Casa Malpais\n## Apache Creek    1.0000000 0.2904662   0.1010795    0.6166508\n## Atsinna         0.2904662 1.0000000   0.3393173    0.2999925\n## Baca Pueblo     0.1010795 0.3393173   1.0000000    0.1469591\n## Casa Malpais    0.6166508 0.2999925   0.1469591    1.0000000"},{"path":"NetworkData.html","id":"Jaccard","chapter":"Section 3 Network Data in R","heading":"Jaccard Similarity","text":"many situations may either presence/absence data data one categories dominate assemblages sites. former case, measures similarity work. latter case, although measures may work, results may largely product similarities differences common categories. cases, may preferable use similarity metric based presence/absence data. Jaccard similarity coefficient two sets presence/absence values simply intersection values two cases divided union two cases. Formally can written :\\[J(,B) = \\frac{|\\cap B|}{|\\cup B|} = \\frac{|\\cap B|}{|| + |B| - |\\cap B|}\\]\\(|\\cap B|\\) intersection vectors B number categories vectors = present.\\(|\\cup B|\\) union vectors B total number categories either B present.can define simple function R calculate Jaccard similarity coefficients. values always range 0 (categories common) 1 (categories common).order try function , create three simple vectors values compare . Note function compares matches position item vector. vec1[1] = 1 vec2[1] = 1 considered match:want run entire incidence matrix roll another function. Note function automatically takes incidence matrix, converts presence/absence data calculates Jaccard coefficients every pair nodes. output square matrix similarities row row. Let’s try cibola_clust data used :Note created R scripts two functions separate files. like initialize functions without copying pasting code , can use source() function call function straight file. located “scripts” folder add sub-folder file name argument. Click download jaccard.R jaccard_inc.R.","code":"\njaccard <- function(a, b) {\n  intersection <- length(which((a-b) == 0))\n  union <- length(a) + length(b) - intersection\n  return(intersection / union)\n}\nvec1 <- c(0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0)\nvec2 <- c(0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1)\nvec3 <- c(0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1)\n\njaccard(vec1, vec2)## [1] 0.4666667\njaccard(vec2, vec3)## [1] 0.5714286\njaccard(vec1, vec3)## [1] 0.375\njaccard_inc <- function(dat) {\n  dat[dat > 0] <- 1\n  out <- matrix(NA, nrow(dat), nrow(dat))\n  for (i in seq_len(nrow(dat))) {\n    for (j in seq_len(nrow(dat))) {\n      out[i, j] <- jaccard(dat[i, ], dat[j, ])\n    }\n  }\n  return(out)\n}\n\ncibola_j <- jaccard_inc(dat = cibola_clust)\n\ncibola_j[1:4, 1:4]##           [,1]      [,2]      [,3]      [,4]\n## [1,] 1.0000000 0.4285714 0.4285714 0.8181818\n## [2,] 0.4285714 1.0000000 0.6666667 0.5384615\n## [3,] 0.4285714 0.6666667 1.0000000 0.5384615\n## [4,] 0.8181818 0.5384615 0.5384615 1.0000000\nsource(\"scripts/jaccard.R\")\nsource(\"scripts/jaccard_inc.R\")"},{"path":"NetworkData.html","id":"NetFromSim","chapter":"Section 3 Network Data in R","heading":"Creating Network Objects from Similarity Matrices","text":"Now defined measures similarity, next step convert network objects R packages able work . can either creating binary networks (ties either present absent) weighted networks (many cases simply raw similarity/distance matrices calculated ). provide examples approaches, starting simple binary networks. many ways define networks matrices like generated examples seen exhaustive set procedures.","code":""},{"path":"NetworkData.html","id":"creating-binary-network-objects","chapter":"Section 3 Network Data in R","heading":"Creating binary network objects","text":"First, produce network object based BR similarity matrix created . example, define ties present pairs sites share 65% commonality (BR > 0.65) terms proportions ceramics recovered pairs sites.code , event2dichot function (statnet package) takes matrix divides 1s 0s based cut choose. ’re using absolute cut meaning ’re assigning specific value use cut (0.65). send output function network function just .next chunk code use \\(\\chi^2\\) distances create binary networks. time, use absolute value define ties present, instead define similarities greater 80 percent similarities present. plot just .Finally, ’ll use Jaccard coefficients define threshold defining edges present absent grand mean entire similarity matrix using method = \"mean\". options event2dichot function. See help material .","code":"\n# Define our binary network object from BR similarity\nbrnet <-\n  network(event2dichot(cibola_br,\n                       method = \"absolute\",\n                       thresh = 0.65),\n                       directed = FALSE)\n# Now let's add names for our nodes based on the row names\n# of our original matrix\nbrnet %v% \"vertex.names\" <- row.names(cibola_clust)\n# look at the results.\nbrnet##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 167 \n##     missing edges= 0 \n##     non-missing edges= 167 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes\n# plot network using default layout\nset.seed(7564)\nplot(brnet)\n# Note we use 1 minus chacoX01 here so to convert a distance\n# to a similarity\nxnet <-\n  network(event2dichot(cibola_x01,\n                       method = \"quantile\",\n                       thresh = 0.80),\n                       directed = FALSE)\n# Once again add vertex names as row names of data frame\nxnet %v% \"vertex.names\" <- row.names(cibola_clust)\n# look at the results\nxnet##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 80 \n##     missing edges= 0 \n##     non-missing edges= 80 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes\n# plot network using default layout\nset.seed(346)\nplot(xnet)\njnet <-\n  network(event2dichot(cibola_j,\n                       method = \"mean\"),\n                       directed = FALSE)\n\njnet %v% \"vertex.names\" <- row.names(cibola_clust)\n\njnet##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 207 \n##     missing edges= 0 \n##     non-missing edges= 207 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes\n# plot network using default layout\nset.seed(343546)\nplot(jnet)"},{"path":"NetworkData.html","id":"creating-weighted-network-objects","chapter":"Section 3 Network Data in R","heading":"Creating Weighted Network Objects","text":"also possible use R create weighted networks individual edges valued. found works reasonably well networks co-presence something similar (counts mentions texts monuments example) perform well applied large similarity distance matrices (every possible link value, network gets unwieldy fast). latter case, found often better just work directly underlying similarity/distance matrix., however, chose create weighted network object similarity matrix requires slight modification procedure . chunk code , simply add arguments ignore.eval = FALSE names.eval = \"weight\" let network function know like weights retained like attribute called ‘weight’. apply matrix Morisita similarities defined plot result.resulting network nearly complete bit unwieldy plotting calculating network statistics weighted network can often still useful see exploratory analysis section.","code":"\n# create weighted network object from co-occurrence matrix by\n# adding the ignore.eval=F argument\nmor_wt <- network(\n  cibola_mor,\n  directed = FALSE,\n  ignore.eval = FALSE,\n  names.eval = \"weight\"\n)\n\nmor_wt %v% \"vertex.names\" <- row.names(cibola_mor)\nmor_wt##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 465 \n##     missing edges= 0 \n##     non-missing edges= 465 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n##  Edge attribute names: \n##     weight\n# plot weighted network using default layout\nset.seed(4634)\nplot(mor_wt)"},{"path":"NetworkData.html","id":"EgoNetworks","chapter":"Section 3 Network Data in R","heading":"3.2.6 Ego Networks","text":"aim understand relational environment within entity embedded, relevant research questions data collection challenges dictate focus, archaeological network research can make use -called ego-networks: type network includes focal node (-called ego), set nodes ego connected edge (-called alters) edges set nodes.Extracting ego-network existing igraph network object R easy. extract plot ego-network Apache Creek, first site network files created . First read data create network object apply igraph::make_ego_graph function network object created.ego-networks, nodes connected target nodes (Apache Creek first example Platt Ranch second) shown edges among included nodes shown.also possible determine size ego-networks entire one-mode network using ego_size function. output function vector can assigned network node attribute.","code":"\n# Read in edge list file as data frame\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\n\n# Create graph object. The data frame is converted to a matrix as\n# that is required by this specific function. Since this is an\n# undirected network, directed = FALSE.\ncibola_net <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist),\n                              directed = FALSE)\n\n# Extract ego-networks\nego_nets <- make_ego_graph(cibola_net)\n\n# Examine the first ego-network\nego_nets[[1]]## IGRAPH ab22b85 UN-- 12 59 -- \n## + attr: name (v/c)\n## + edges from ab22b85 (vertex names):\n##  [1] Apache Creek   --Casa Malpais         Apache Creek   --Coyote Creek        \n##  [3] Casa Malpais   --Coyote Creek         Apache Creek   --Hooper Ranch        \n##  [5] Casa Malpais   --Hooper Ranch         Coyote Creek   --Hooper Ranch        \n##  [7] Apache Creek   --Horse Camp Mill      Casa Malpais   --Horse Camp Mill     \n##  [9] Coyote Creek   --Horse Camp Mill      Hooper Ranch   --Horse Camp Mill     \n## [11] Apache Creek   --Hubble Corner        Casa Malpais   --Hubble Corner       \n## [13] Coyote Creek   --Hubble Corner        Hooper Ranch   --Hubble Corner       \n## [15] Horse Camp Mill--Hubble Corner        Apache Creek   --Mineral Creek Pueblo\n## + ... omitted several edges\n# Plot Apache Creek ego-network\nset.seed(754)\nplot(ego_nets[[1]])\n# Plot Platt Ranch ego-network for comparison\nset.seed(45367)\nplot(ego_nets[[30]])\nego_size(cibola_net)##  [1] 12 12 12 12 13 14 13 13 10 14 15  7  9 14 13 14 15 11 14 14 15  2 14 19 15\n## [26] 12 12 11  7  6"},{"path":"NetworkData.html","id":"Multinet","chapter":"Section 3 Network Data in R","heading":"3.2.7 Multilayer Network","text":"simplest terms, multilayer networks networks single set nodes connected two sets edges represent different kind relationship among nodes. relatively new area network science archaeological network research expect likely change coming years. now new R packages help manage analyze multilayer network data.multinet package (Rossi Vega 2021) designed facilitate analysis multilayer networks. order explore possibilities use example data analyses included package. Specifically, look famous network data Florentine families 14th century connections defined terms business marriage.multinet network objects compatible igraph individual layers can analyzed just like igraph network objects. multinet approach likely greater utility conducting comparisons among layers conducting analyses take several layers account simultaneously. detailed exploration approach beyond scope document (provide simple example ) suggest interested readers read package information tutorials associated package . example calculate degree across multiple layers using degree_ml function run Louvain cluster detection algorithm across graph layers using glouvain_ml. Multilayer networks considerable potential archaeological data hope see research area future.archaeological example multilevel network analysis GitHub project Andy Upton.","code":"\n# create object with Florentine multilayer network data\nflorentine <- ml_florentine()\n\n# Examine the data\nflorentine## ml-net[15, 2, 26, 35 (35,0)]\nsummary(florentine)##           n  m dir nc slc      dens        cc      apl dia\n## _flat_   15 35   0  1  15 0.3333333 0.3409091 2.085714   4\n## business 11 15   0  1  11 0.2727273 0.4166667 2.381818   5\n## marriage 15 20   0  1  15 0.1904762 0.1914894 2.485714   5\n# plot the data\nplot(florentine)\n# If we want to calculate degree centrality across multiple layers of a\n# multilayer network, the multinet package can help us do that directly\n# and quite simply.\nmultinet::degree_ml(florentine)##  [1]  6  3  1  6  5  2 11  3  4  3  4  7  6  6  3\n# Similarly, we could apply cluster detection algorithms to all layers\n# of a multilayer network simultaneously.\nmultinet::glouvain_ml(florentine)##           actor    layer cid\n## 1     Barbadori marriage   0\n## 2     Barbadori business   0\n## 3       Albizzi marriage   0\n## 4    Acciaiuoli marriage   0\n## 5         Pazzi marriage   0\n## 6         Pazzi business   0\n## 7        Medici marriage   0\n## 8        Medici business   0\n## 9      Salviati marriage   0\n## 10     Salviati business   0\n## 11   Tornabuoni marriage   0\n## 12   Tornabuoni business   0\n## 13      Ridolfi marriage   0\n## 14       Ginori marriage   0\n## 15       Ginori business   0\n## 16     Bischeri marriage   1\n## 17     Bischeri business   1\n## 18 Lamberteschi marriage   1\n## 19 Lamberteschi business   1\n## 20      Strozzi marriage   1\n## 21      Peruzzi marriage   1\n## 22      Peruzzi business   1\n## 23     Guadagni marriage   1\n## 24     Guadagni business   1\n## 25   Castellani marriage   1\n## 26   Castellani business   1"},{"path":"NetworkData.html","id":"ConvertingNetworkFormats","chapter":"Section 3 Network Data in R","heading":"3.3 Converting Among Network Object Types","text":"\nexamples document using \nigraph package similarity networks chose \nuse statnet due convenience functions working\ndirectly similarity data. worry easy convert one\nformat another preserve attributes using package\ncalled intergraph. way example can covert\nweighted network object created previous step convert\nigraph object view attributes using \nasIgraph function. wanted go direction\ncovert igraph object network object\n(format statnet package require) \ninstead use asNetwrok.\nsimple example:back direction:","code":"\nmor_wt_i <- asIgraph(mor_wt)\nmor_wt_i## IGRAPH ab5a7d9 U-W- 31 465 -- \n## + attr: na (v/l), vertex.names (v/c), na (e/l), weight (e/n)\n## + edges from ab5a7d9:\n##   [1] 1-- 2 1-- 3 1-- 4 1-- 5 1-- 6 1-- 7 1-- 8 1-- 9 1--10 1--11 1--12 1--13\n##  [13] 1--14 1--15 1--16 1--17 1--18 1--19 1--20 1--21 1--22 1--23 1--24 1--25\n##  [25] 1--26 1--27 1--28 1--29 1--30 1--31 2-- 3 2-- 4 2-- 5 2-- 6 2-- 7 2-- 8\n##  [37] 2-- 9 2--10 2--11 2--12 2--13 2--14 2--15 2--16 2--17 2--18 2--19 2--20\n##  [49] 2--21 2--22 2--23 2--24 2--25 2--26 2--27 2--28 2--29 2--30 2--31 3-- 4\n##  [61] 3-- 5 3-- 6 3-- 7 3-- 8 3-- 9 3--10 3--11 3--12 3--13 3--14 3--15 3--16\n##  [73] 3--17 3--18 3--19 3--20 3--21 3--22 3--23 3--24 3--25 3--26 3--27 3--28\n##  [85] 3--29 3--30 3--31 4-- 5 4-- 6 4-- 7 4-- 8 4-- 9 4--10 4--11 4--12 4--13\n## + ... omitted several edges\n# view first 10 edge weights to show that they are retained\nE(mor_wt_i)$weight[1:10]##  [1] 0.4885799 0.6014729 0.9060751 0.4049019 1.0000000 0.7087214 0.7724938\n##  [8] 0.4521581 0.7996468 1.0000000\nmor_new <- asNetwork(mor_wt_i)\nmor_new##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 465 \n##     missing edges= 0 \n##     non-missing edges= 465 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n##  Edge attribute names: \n##     weight\n(mor_new %e% \"weight\")[1:10]##  [1] 0.4885799 0.6014729 0.9060751 0.4049019 1.0000000 0.7087214 0.7724938\n##  [8] 0.4521581 0.7996468 1.0000000"},{"path":"Exploratory.html","id":"Exploratory","chapter":"Section 4 Exploratory Network Analysis","heading":"Section 4 Exploratory Network Analysis","text":"Exploratory network analysis simply exploratory data analysis applied network data. covers range statistical visual techniques designed explore structure networks well relative positions nodes edges. methods can used look particular structures patterning interest, central nodes, summarize describe structure network paint general picture analysis. section serves companion Chapter 4 Brughmans Peeples book (2023) provides basic examples exploratory network analysis methods outlined book well others.Note created distinct section exponential random graph models (ERGM) “Going Beyond Book” section document approach necessitates extended discussion. replicate boxed example Chapter 4 book section.","code":""},{"path":"Exploratory.html","id":"ExampleNetworkObjects","chapter":"Section 4 Exploratory Network Analysis","heading":"4.1 Example Network Objects","text":"order facilitate exploratory analysis examples section, want first create set igraph statnet network objects serve purposes across analyses . Specifically, generate define:simple_net - simple undirected binary network isolatessimple_net_noiso - simple undirected binary network without isolatesdirected_net - directed binary networkweighted_net - undirected weighted networksim_net_i - similarity network edges weighted similarity igraph formatsim_net - similarity network edges weighted similarity network formatsim_mat - data frame object containing weighted similarity matrixEach used appropriate illustrate particular methods.following chunk code initialize packages use section define network objects use (using object names ). examples use Cibola technological similarity data used Network Data Formats section previously.","code":"\n# initialize packages\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(vegan)\n\n# read in csv data\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\ncibola_adj_mat <- read.csv(file = \"data/Cibola_adj.csv\",\n                           header = T,\n                           row.names = 1)\n\n# Simple network with isolates\nsimple_net <-\n  igraph::graph_from_adjacency_matrix(as.matrix(cibola_adj_mat),\n                                      mode = \"undirected\")\n\n# Simple network with no isolates\nsimple_net_noiso <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist),\n                              directed = FALSE)\n\n#Create a directed network by sub-sampling edge list\nset.seed(45325)\nel2 <- cibola_edgelist[sample(seq(1, nrow(cibola_edgelist)), 125,\n                              replace = FALSE), ]\n\ndirected_net <- igraph::graph_from_edgelist(as.matrix(el2),\n                                            directed = TRUE)\n\n# Create a weighted undirected network by adding column of random\n# weights to edge list\ncibola_edgelist$weight <- sample(seq(1, 4), nrow(cibola_edgelist),\n                                 replace = TRUE)\nweighted_net <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist[, 1:2]),\n                              directed = FALSE)\n\nE(weighted_net)$weight <- cibola_edgelist$weight\n\n# Create a similarity network using the Brainerd-Robinson metric\ncibola_clust <-\n  read.csv(file = \"data/Cibola_clust.csv\",\n           header = TRUE,\n           row.names = 1)\nclust_p <- prop.table(as.matrix(cibola_clust), margin = 1)\nsim_mat <-\n  (2 - as.matrix(vegan::vegdist(clust_p, method = \"manhattan\"))) / 2\nsim_net <- network(\n  sim_mat,\n  directed = FALSE,\n  ignore.eval = FALSE,\n  names.eval = \"weight\"\n)\nsim_net_i <- asIgraph(sim_net)"},{"path":"Exploratory.html","id":"CalcMetric","chapter":"Section 4 Exploratory Network Analysis","heading":"4.2 Calculating Network Metrics in R","text":"Although calculations behind scenes centrality metrics, clustering algorithms, network measures may somewhat complicated, calculating measures R using network objects usually quite straight forward typically involves single function couple arguments within . , however, things need kept mind applying methods network data. document, provide examples common functions may use well caveats potential problems.Certain network metrics require networks specific properties may produce unexpected results wrong kind network used. example, closeness centrality well defined binary networks isolates. use igraph::closeness command calculate closeness centrality network isolates, get results, also get warning telling “closeness centrality well-defined disconnected graphs.” functions provide data meet criteria required function may instead get error results returned. cases, however, function may simply return results provide warning, important careful selecting methods avoid providing data violates assumptions method provided. Remember, questions function works requires can type ?function_name console function question get help document provide information. can also include package names help call ensure get correct function (.e., ?igraph::degree)","code":""},{"path":"Exploratory.html","id":"Centrality","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3 Centrality","text":"One common kinds exploratory network analysis involves calculating basic network centrality centralization statistics. wide array methods available R igraph statnet packages. section highlight examples well caveats keep mind.","code":""},{"path":"Exploratory.html","id":"Degree","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.1 Degree Centrality","text":"Degree centrality can calculated using igraph::degree function simple networks without isolates well simple directed networks. method , however, appropriate weighted networks similarity networks (expects binary values). apply igraph::degree function weighted network object simply get binary network degree centrality values. alternative calculating weighted degree weighted similarity networks simply calculate row sums underlying similarity matrix (minus 1 account self loops) adjacency matrix. degree function returned output vector values representing degree centrality can assigned R object, plotted, otherwise used. provide examples illustrate. Note directed graphs can also specify mode -degree -degree sum .Graph level degree centralization equally simple call using centr_degree function. function returns object multiple parts including vector degree centrality scores, graph level centralization metric, theoretical maximum number edges (n * [n-1]). metric can normalized maximum centralization value 1 using normalize = TRUE argument demonstrate . See comments code chunk follow along type network object used call. cases display first 5 values prevent long lists output (using [1:5] command).interested calculating graph level density can using edge_density function. Note just like degree function , works binary networks submit weighted network object simply get binary edge density value.","code":"\n# simple network with isolates\nigraph::degree(simple_net)[1:5]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega \n##           11            8            1           11           13\n# simple network no isolates\nigraph::degree(simple_net_noiso)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##              11              11              11              11              12\n# directed network\nigraph::degree(directed_net, mode = \"in\")[1:5] # in-degree##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##               1               6               5               6               2\nigraph::degree(directed_net, mode = \"out\")[1:5] # out-degree##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##               6               2               5               2              11\n# weighted network - rowSums of adjacency matrix\n(rowSums(as.matrix(\n  as_adjacency_matrix(weighted_net,\n                      attr = \"weight\")\n)) - 1)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##              25              29              21              18              27\n# similarity network. Note we use the similarity matrix here and\n# not the network object\n(rowSums(sim_mat) - 1)[1:5]## Apache Creek      Atsinna  Baca Pueblo Casa Malpais      Cienega \n##     16.00848     15.87024     14.77997     17.30358     17.09394\n# If you want to normalize your degree centrality metric by the\n# number of nodes present you can do that by adding the normalize=TRUE\n# command to the function calls above. For weighted and similarity\n# networks you can simply divide by the number of nodes minus 1.\nigraph::degree(simple_net, normalize = T)[1:5]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega \n##   0.36666667   0.26666667   0.03333333   0.36666667   0.43333333\n# it is also possible to directly plot the degree distribution for\n# a given network using the degree.distribution function.\n# Here we embed that call directly in a call for a histogram plot\n# using the \"hist\" function\nhist(igraph::degree.distribution(simple_net))\n# graph level centralization\nigraph::centr_degree(simple_net)## $res\n##  [1] 11  8  1 11 13 11  6 13 14 18 11 12 13 11 12 12 13 14 11  5 10 12 13 13  9\n## [26] 14 13 14  6  0 10\n## \n## $centralization\n## [1] 0.2408602\n## \n## $theoretical_max\n## [1] 930\n# To calculate centralization score for a similarity matrix, use the\n# sna::centralization function\nsna::centralization(sim_mat, normalize = TRUE, sna::degree)## [1] 0.1082207\nedge_density(simple_net_noiso)## [1] 0.383908\nedge_density(weighted_net)## [1] 0.383908"},{"path":"Exploratory.html","id":"Betweenness","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.2 Betweenness Centrality","text":"betweenness functions work much like degree function calls . Betweenness centrality igraph can calculated simple networks without isolates, directed networks, weighted networks. case weighted networks similarity networks, shortest paths sets nodes calculated path greatest weight taken juncture. can normalize results using normalize = TRUE just like degree. igraph::betweenness function automatically detect graph directed weighted use appropriate method can also specify particular edge attribute use weight perhaps one weighting scheme.","code":"\n# calculate betweenness for simple network\nigraph::betweenness(simple_net)[1:5]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega \n##     1.125000     0.000000     0.000000     8.825306     8.032865\n# calculate betweenness for weighted network\nigraph::betweenness(weighted_net, directed = FALSE)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##        20.94423        18.96259        17.67829        15.66853         2.78036\n# calculate betweenness for weighted network specifying weight attribute\nigraph::betweenness(weighted_net, weights = E(weighted_net)$weight)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##        20.94423        18.96259        17.67829        15.66853         2.78036\n# calculate graph level centralization\ncentr_betw(simple_net)## $res\n##  [1]   1.1250000   0.0000000   0.0000000   8.8253059   8.0328650   3.2862641\n##  [7]   0.2500000  58.7048084  15.6031093 142.3305364   1.1250000   9.0503059\n## [13]  11.9501530   6.2604913   1.2590038  12.8566507   8.0328650  41.0052110\n## [19]   0.5722222   2.7950980   0.2844828   9.0503059  15.3558646   8.0328650\n## [25]   0.0000000  16.0653473  11.9501530  17.0225282   0.0000000   0.0000000\n## [31]   2.1735632\n## \n## $centralization\n## [1] 0.3064557\n## \n## $theoretical_max\n## [1] 13050"},{"path":"Exploratory.html","id":"Eigenvector","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.3 Eigenvector Centrality","text":"igraph::eigen_centrality function can calculated simple networks without isolates, directed networks, weighted networks. default scores scaled maximum score 1. can turn scaling using scale = FALSE argument. function automatically detects whether network object directed weighted can also call edge attributes specify particular weight attribute. default function outputs many features analysis number steps toward convergence number iterations just want centrality results can use atomic vector call $vector.","code":"\neigen_centrality(simple_net,\n   scale = TRUE)$vector[1:5]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega \n##   0.46230981   0.54637071   0.07114132   0.53026366   0.85007181\neigen_centrality(\n  weighted_net,\n  weights = E(weighted_net)$weight,\n  directed = FALSE,\n  scale = FALSE\n)$vector[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##      0.08116512      0.10608344      0.07254989      0.05355994      0.10123595"},{"path":"Exploratory.html","id":"PageRank","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.4 Page Rank Centrality","text":"igraph::page_rank function can calculated simple networks without isolates, directed networks, weighted networks. default scores scaled maximum score 1. can turn scaling using scale = FALSE argument. function automatically detects whether network object directed weighted can also call edge attributes specify particular weight attribute. can change algorithm used implement page rank algorithm (see help details) can also change damping factor desired.","code":"\npage_rank(directed_net,\n  directed = TRUE)$vector[1:5]##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##      0.01375364      0.03433734      0.02521968      0.04722743      0.01549665\npage_rank(\n  weighted_net,\n  weights = E(weighted_net)$weight,\n  directed = FALSE,\n  algo = \"prpack\"\n)$vector[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##      0.03340837      0.03761940      0.02901255      0.02610001      0.03551477"},{"path":"Exploratory.html","id":"Closeness","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.5 Closeness Centrality","text":"igraph::closeness function calculates closeness centrality can calculated directed undirected simple weighted networks isolates. function can also used networks isolates, may receive additional message suggesting closeness undefined networks fully connected. large networks can use igraph::estimate_closeness function cutoff setting consider paths length cutoff calculate closeness scores. directed networks can also specify whether connections , , directions used.\nNote function igraph::closeness() \nnormally used networks multiple components. Depending \nsettings, however, function call may return error \ncareful.\nLet’s take look examples:","code":"\nigraph::closeness(simple_net)[1:5]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega \n##   0.01470588   0.01470588   0.01315789   0.01886792   0.02000000\nigraph::closeness(simple_net_noiso)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##      0.01470588      0.01886792      0.01754386      0.01470588      0.01923077\nigraph::closeness(weighted_net, weights = E(weighted_net)$weight)[1:5]##    Apache Creek    Casa Malpais    Coyote Creek    Hooper Ranch Horse Camp Mill \n##      0.01010101      0.01298701      0.01219512      0.01111111      0.01063830\nigraph::closeness(directed_net, mode = \"in\")[1:5]##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##      1.00000000      0.04166667      0.04761905      0.04347826      0.09090909"},{"path":"Exploratory.html","id":"HubsAndAuthorities","chapter":"Section 4 Exploratory Network Analysis","heading":"4.3.6 Hubs and Authorities","text":"directed networks possible calculate hub authority scores identify nodes characterized high -degree high -degree particular. measure depends direction appropriate directed network objects. run function undirected network hub scores authority scores identical. functions can also applied networks directed weighted. want options printed can use atomic vector $vector call well.","code":"\nigraph::hub_score(directed_net)$vector[1:5]##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##      0.31998744      0.12265832      0.30740409      0.08450797      1.00000000\nigraph::authority_score(directed_net)$vector[1:5]##    Coyote Creek Techado Springs   Hubble Corner    Tri-R Pueblo    Heshotauthla \n##      0.05372558      0.32708203      0.28835263      0.35970234      0.25265287"},{"path":"Exploratory.html","id":"TriadsAndClustering","chapter":"Section 4 Exploratory Network Analysis","heading":"4.4 Triads and clustering","text":"Another important topic network science concerns considerations overall structure clustering connections across network whole. variety methods developed characterize overall degree clustering closure networks, many based counting triads various configurations. section, briefly outline approaches toward evaluating triads, transitivity, clustering R.","code":""},{"path":"Exploratory.html","id":"Triads","chapter":"Section 4 Exploratory Network Analysis","heading":"4.4.1 Triads","text":"triad simply set three nodes description configuration edges among . undirected graphs, four possibilities describing connections among nodes (empty graph, 1 connection, 2 connections, 3 connections). directed graphs situation considerably complicated ties can considered directions edge one direction isn’t necessarily reciprocated. Thus 16 different configurations can exist (see Brughmans Peeples 2023: Figure 4.4).One common method outlining overall structural properties network conduct “triad census” counts 4 16 possible triads given network. Although triad census can conducted undirected network using igraph::triad_census function, warning returned along 0 results impossible triad configurations aware. results returned vector counts possible node configuration order outlined help document associated function (see ?triad_census ).Often can useful visualize motifs defined entry triad census can done using graph_from_isomorphism_class() function outputs every possible combination nodes given size specify (3 case). can plot configurations single plot using ggraph ggpubr packages. packages described detail visualization section document. label configuration using “isomporhism code” frequently used describe triads.","code":"\nigraph::triad_census(directed_net)##  [1] 1404 2007    0  134  146  174    0    0  195    0    0    0    0    0    0\n## [16]    0\nigraph::triad_census(simple_net)## Warning in igraph::triad_census(simple_net): At\n## vendor/cigraph/src/misc/motifs.c:1140 : Triad census called on an undirected\n## graph. All connections will be treated as mutual.##  [1] 1033    0 2551    0    0    0    0    0    0    0  441    0    0    0    0\n## [16]  470\nlibrary(ggraph)\nlibrary(ggpubr)\n\ng <- list()\nxy <-\n  as.data.frame(matrix(\n    c(0.1, 0.1, 0.9, 0.1, 0.5, 0.45),\n    nrow = 3,\n    ncol = 2,\n    byrow = TRUE\n  ))\n\n\nnames <- c(\"003\", \"012\", \"102\", \"021D\", \"021U\", \"021C\",\n           \"111D\", \"111U\", \"030T\", \"030C\", \"201\", \"120D\",\n           \"120U\", \"120C\", \"210\", \"300\")\n\nfor (i in 0:15) {\n  g_temp <- graph_from_isomorphism_class(size = 3,\n                                         number = i,\n                                         directed = TRUE)\n  g[[i + 1]] <- ggraph(g_temp,\n                       layout = \"manual\",\n                       x = xy[, 1],\n                       y = xy[, 2]) +\n    xlim(0, 1) +\n    ylim(0, 0.5) +\n    geom_node_point(size = 6, col = \"purple\") +\n    geom_edge_fan(\n      arrow = arrow(length = unit(4, \"mm\"),\n                    type = \"closed\"),\n      end_cap = circle(6, \"mm\"),\n      start_cap = circle(6, \"mm\"),\n      edge_colour = \"black\"\n    ) +\n    theme_graph(\n      plot_margin =\n        margin(2, 2, 2, 2)\n    ) +\n    ggtitle(names[i + 1]) +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\n# motifs ordered by order in triad_census function\nggarrange(\n  g[[1]], g[[2]], g[[4]], g[[7]],\n  g[[3]], g[[5]], g[[6]], g[[10]],\n  g[[8]], g[[12]], g[[11]], g[[9]],\n  g[[14]], g[[13]], g[[15]], g[[16]],\n  nrow = 4,\n  ncol = 4\n)"},{"path":"Exploratory.html","id":"Transitivity","chapter":"Section 4 Exploratory Network Analysis","heading":"4.4.2 Transitivity and Clustering","text":"network’s global average transitivity (clustering coefficient) three times number closed triads total number triads network. measure can calculated using igraph::transitivity simple networks without isolates, directed networks, weighted networks. options within function determine specific type transitivity (global transitivity default) treat isolates. See help document (?igraph::transitivity) details. want calculate local transitivity particular node can use type = \"local\" argument. return NA value nodes part triads (isolates nodes single connection).","code":"\nigraph::transitivity(simple_net, type = \"global\")## [1] 0.7617504\nigraph::transitivity(simple_net, type = \"local\")##          Apache.Creek               Atsinna           Baca.Pueblo \n##             0.8727273             1.0000000                   NaN \n##          Casa.Malpais               Cienega          Coyote.Creek \n##             0.8363636             0.8333333             0.8727273 \n##          Foote.Canyon          Garcia.Ranch          Heshotauthla \n##             0.8666667             0.4358974             0.7252747 \n##               Hinkson          Hooper.Ranch       Horse.Camp.Mill \n##             0.4183007             0.8727273             0.8333333 \n##         Hubble.Corner               Jarlosa          Los.Gigantes \n##             0.7435897             0.8000000             0.8787879 \n##  Mineral.Creek.Pueblo               Mirabal            Ojo.Bonito \n##             0.7272727             0.8333333             0.6703297 \n##       Pescado.Cluster           Platt.Ranch Pueblo.de.los.Muertos \n##             0.9272727             0.7000000             0.9555556 \n##       Rudd.Creek.Ruin              Scribe.S             Spier.170 \n##             0.8333333             0.7692308             0.8333333 \n##       Techado.Springs                Tinaja          Tri.R.Pueblo \n##             1.0000000             0.7582418             0.7435897 \n##                 UG481                 UG494              WS.Ranch \n##             0.7142857             1.0000000                   NaN \n##           Yellowhouse \n##             0.8222222"},{"path":"Exploratory.html","id":"WalksPathsDistance","chapter":"Section 4 Exploratory Network Analysis","heading":"4.5 Walks, Paths, and Distance","text":"variety network metrics rely distance paths across networks can calculated R. great many functions available highlight just .","code":""},{"path":"Exploratory.html","id":"Distance","chapter":"Section 4 Exploratory Network Analysis","heading":"4.5.1 Distance","text":"cases, may simply want information graph distance nodes general perhaps average distance. variety functions can help including igraph::distances igraph::mean_distance. work simple networks, directed networks, weighted networks.","code":"\n# Create matrix of all distances among nodes and view the first\n# few rows and columns\nigraph::distances(simple_net)[1:4, 1:4]##              Apache.Creek Atsinna Baca.Pueblo Casa.Malpais\n## Apache.Creek            0       4           4            1\n## Atsinna                 4       0           2            3\n## Baca.Pueblo             4       2           0            3\n## Casa.Malpais            1       3           3            0\n# Calculate the mean distance for a network\nigraph::mean_distance(simple_net)## [1] 1.949425"},{"path":"Exploratory.html","id":"ShortestPaths","chapter":"Section 4 Exploratory Network Analysis","heading":"4.5.2 Shortest Paths","text":"want identify particular shortest paths nodes network can use igraph::shortest_paths function alternatively igraph::all_shortest_paths want shortest paths originating particular node. call function simply need provide network object id origin destination path. simplest solution just call node number. function works directed undirected networks without weights. Although can applied networks isolates, isolates produce NA results.output provides ids nodes crossed path origin destination.","code":"\n# track shortest path from Apache Creek to Pueblo de los Muertos\nigraph::shortest_paths(simple_net, from = 1, to = 21)## $vpath\n## $vpath[[1]]\n## + 5/31 vertices, named, from b06c715:\n## [1] Apache.Creek          Casa.Malpais          Garcia.Ranch         \n## [4] Heshotauthla          Pueblo.de.los.Muertos\n## \n## \n## $epath\n## NULL\n## \n## $predecessors\n## NULL\n## \n## $inbound_edges\n## NULL"},{"path":"Exploratory.html","id":"Diameter","chapter":"Section 4 Exploratory Network Analysis","heading":"4.5.3 Diameter","text":"igraph::diameter function calculates diameter network (longest shortest path) can also use farthest_vertices function get ids nodes form ends longest shortest path. metric can calculated directed undirected, weighted unweighted networks, without isolates.","code":"\nigraph::diameter(directed_net, directed = TRUE)## [1] 4\nigraph::farthest_vertices(directed_net, directed = TRUE)## $vertices\n## + 2/30 vertices, named, from b06cf70:\n## [1] Apache Creek          Pueblo de los Muertos\n## \n## $distance\n## [1] 4"},{"path":"Exploratory.html","id":"ComponentsAndBridges","chapter":"Section 4 Exploratory Network Analysis","heading":"4.6 Components and Bridges","text":"Identifying fully connected subgraphs within large network common analytical procedure quite straight forward R using igraph package. first want know whether given network fully connected can use igraph::is_connected function check.can also count components using count_components function.","code":"\nigraph::is_connected(simple_net)## [1] FALSE\nigraph::is_connected(simple_net_noiso)## [1] TRUE\nigraph::count_components(simple_net)## [1] 2"},{"path":"Exploratory.html","id":"IdentifyingComponents","chapter":"Section 4 Exploratory Network Analysis","heading":"4.6.1 Identifying Components","text":"want decompose network object distinct components can use igraph::decompose function outputs list object entry representing distinct component. object list can called using [[k]] k number item list.example network fully connected exception 1 node (WS Ranch). run decompose function separates WS ranch component isolate edges.","code":"\ncomponents <- igraph::decompose(simple_net, min.vertices = 1)\n\ncomponents## [[1]]\n## IGRAPH b1aaf1f UN-- 30 167 -- \n## + attr: name (v/c)\n## + edges from b1aaf1f (vertex names):\n##  [1] Apache.Creek--Casa.Malpais          Apache.Creek--Coyote.Creek         \n##  [3] Apache.Creek--Hooper.Ranch          Apache.Creek--Horse.Camp.Mill      \n##  [5] Apache.Creek--Hubble.Corner         Apache.Creek--Mineral.Creek.Pueblo \n##  [7] Apache.Creek--Rudd.Creek.Ruin       Apache.Creek--Techado.Springs      \n##  [9] Apache.Creek--Tri.R.Pueblo          Apache.Creek--UG481                \n## [11] Apache.Creek--UG494                 Atsinna     --Cienega              \n## [13] Atsinna     --Los.Gigantes          Atsinna     --Mirabal              \n## [15] Atsinna     --Ojo.Bonito            Atsinna     --Pueblo.de.los.Muertos\n## + ... omitted several edges\n## \n## [[2]]\n## IGRAPH b1aaf31 UN-- 1 0 -- \n## + attr: name (v/c)\n## + edges from b1aaf31 (vertex names):\nV(components[[2]])$name## [1] \"WS.Ranch\""},{"path":"Exploratory.html","id":"Cutpoints","chapter":"Section 4 Exploratory Network Analysis","heading":"4.6.2 Cutpoints","text":"cutpoint node, removal creates network higher number components. convenient igraph function identifying cutpoints function sna package within statnet suite. Using intergraph package can easily convert igraph object network object (using asNetwork function) within call use function.sna::cutpoint function returns node id cutpoints detected. can use numbers returned find name node question.example reveals Ojo Bonito cutpoint look figure can see sole connection Baca Pueblo otherwise become isolate distinct component Ojo Bonito removed.","code":"\ncut_p <- cutpoints(asNetwork(simple_net))\ncut_p## [1] 18\nV(simple_net)$name[cut_p]## [1] \"Ojo.Bonito\"\nset.seed(4536)\nplot(simple_net)"},{"path":"Exploratory.html","id":"Bridges","chapter":"Section 4 Exploratory Network Analysis","heading":"4.6.3 Bridges","text":"bridge edge, removal results network higher number components. function igraph::min_cut finds bridges network objects sets nodes graph whole. output function includes vector called $cut provides edges representing bridges. default function outputs cut value can use argument value.= FALSE get full output.example illustrates edge Ojo Bonito Baca Pueblo bridge (perhaps surprising Ojo Bonito cut point).","code":"\nmin_cut(simple_net_noiso, value.only = FALSE)## $value\n## [1] 1\n## \n## $cut\n## + 1/167 edge from b06caf8 (vertex names):\n## [1] Ojo Bonito--Baca Pueblo\n## \n## $partition1\n## + 1/30 vertex, named, from b06caf8:\n## [1] Baca Pueblo\n## \n## $partition2\n## + 29/30 vertices, named, from b06caf8:\n##  [1] Apache Creek          Casa Malpais          Coyote Creek         \n##  [4] Hooper Ranch          Horse Camp Mill       Hubble Corner        \n##  [7] Mineral Creek Pueblo  Rudd Creek Ruin       Techado Springs      \n## [10] Tri-R Pueblo          UG481                 UG494                \n## [13] Atsinna               Cienega               Los Gigantes         \n## [16] Mirabal               Ojo Bonito            Pueblo de los Muertos\n## [19] Scribe S              Spier 170             Tinaja               \n## [22] Garcia Ranch          Hinkson               Heshotauthla         \n## [25] Jarlosa               Pescado Cluster       Yellowhouse          \n## [28] Foote Canyon          Platt Ranch"},{"path":"Exploratory.html","id":"CliquesAndCommunities","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7 Cliques and Communities","text":"Another common task network analysis involves creating cohesive sub-groups nodes larger network. wide variety methods available defining groups highlight common .","code":""},{"path":"Exploratory.html","id":"Cliques","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.1 Cliques","text":"clique network science concept arguably strictest method defining cohesive subgroup. set three nodes node directly connected nodes. can alternatively defined completely connected subnetwork, subnetwork maximum density. function igraph::max_cliques finds maximal cliques network outputs list object nodes set indicated. sake space output one clique 24 defined function call.Note list node can appear one maximal clique.","code":"\nmax_cliques(simple_net, min = 1)[[24]]## + 9/31 vertices, named, from b06c715:\n## [1] Los.Gigantes    Cienega         Tinaja          Spier.170      \n## [5] Scribe.S        Pescado.Cluster Mirabal         Heshotauthla   \n## [9] Yellowhouse"},{"path":"Exploratory.html","id":"KCores","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.2 K-cores","text":"k-core maximal subnetwork vertex least degree k within subnetwork. R can obtained using igraph::coreness function filtering value appropriate. function creates vector k values can used remove nodes appropriate symbolize plots.plot shown darker read colors represent higher maximal k-core values.","code":"\n# Define coreness of each node\nkcore <- coreness(simple_net)\nkcore[1:6]## Apache.Creek      Atsinna  Baca.Pueblo Casa.Malpais      Cienega Coyote.Creek \n##            9            8            1            9            9            9\n# set up color scale\ncol_set <- heat.colors(max(kcore), rev = TRUE)\nset.seed(2509)\nplot(simple_net, vertex.color = col_set[kcore])"},{"path":"Exploratory.html","id":"ClusterDetection","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3 Cluster Detection Algorithms","text":"R allows use variety common cluster detection algorithms define groups nodes network using variety different assumptions. highlight common .","code":""},{"path":"Exploratory.html","id":"GirvanNewman","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3.1 Girvan-Newman Clustering","text":"Girvan-Newman clustering divisive algorithm based betweenness defines partition network maximizes modularity removing nodes high betweenness iteratively (see discussion Brughmans Peeples 2023 Chapter 4.6). R referred igraph::edge.betweenness.community function. function can used directed undirected networks without edge weights. function outputs variety information including individual edge betweenness scores, modularity information, partition membership. See help documents information","code":"\ngn <- igraph::edge.betweenness.community(simple_net)## Warning: `edge.betweenness.community()` was deprecated in igraph 2.0.0.\n## ℹ Please use `cluster_edge_betweenness()` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.\nset.seed(4353)\nplot(simple_net, vertex.color = gn$membership)"},{"path":"Exploratory.html","id":"Walktrap","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3.2 Walktrap Algorithm","text":"walktrap algorithm designed work either binary weighted networks defines communities generating large number short random walks determining sets nodes consistently fall along short random walks. can called using igraph::cluster_walktrap function. “steps” argument determines length short walks set 4 default.","code":"\nwt <- igraph::cluster_walktrap(simple_net, steps = 4)\nset.seed(4353)\nplot(simple_net, vertex.color = wt$membership)"},{"path":"Exploratory.html","id":"Louvain","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3.3 Louvain Modularity","text":"Louvain modularity cluster detection algorithm based modularity. algorithm iteratively moves nodes among community definitions way optimizes modularity. measure can calculated simple networks, directed networks, weighted networks implemented R igraph::cluster_louvain function.","code":"\nlv <- igraph::cluster_louvain(simple_net)\nset.seed(4353)\nplot(simple_net, vertex.color = lv$membership)"},{"path":"Exploratory.html","id":"Modularity","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3.4 Calculating Modularity for Partitions","text":"like compare modularity scores among partitions graph, can achieved using igraph::modularity function. modularity call simply supply argument indicating partition membership node. Note can also used attribute data regional designations. following chunk code compare modularity clustering methods described well using subregion designations original Cibola region attribute dataNote although modularity can useful comparing among partitions like approach shown poor detecting small communities within network always appropriate.","code":"\n# Modularity for Girvan-Newman\nmodularity(simple_net, membership = membership(gn))## [1] 0.4103589\n# Modularity for walktrap\nmodularity(simple_net, membership = membership(wt))## [1] 0.4157195\n# Modularity for Louvain clustering\nmodularity(simple_net, membership = membership(lv))## [1] 0.4131378\n# Modularity for subregion\ncibola_attr <- read.csv(\"data/Cibola_attr.csv\")\nmodularity(simple_net, membership = as.factor(cibola_attr$Region))## [1] 0.1325612"},{"path":"Exploratory.html","id":"FindingEdgesBetween","chapter":"Section 4 Exploratory Network Analysis","heading":"4.7.3.5 Finding Edges Within and Between Communities","text":"many cases may interested identifying edges remain within extend network partition. can done using igraph::crossing function. function expects igraph cluster definition object igraph network return list TRUE FALSE values edge true indicates edge extends beyond cluster assigned nodes. Let’s take look first 10 edges simple_net object based Louvain cluster definition.Beyond , plot igraph object add cluster definition call produce network graph clusters outlined nodes extend clusters shown red.","code":"\nigraph::crossing(lv, simple_net)[1:6]##         Apache.Creek|Casa.Malpais         Apache.Creek|Coyote.Creek \n##                             FALSE                             FALSE \n##         Apache.Creek|Hooper.Ranch      Apache.Creek|Horse.Camp.Mill \n##                             FALSE                             FALSE \n##        Apache.Creek|Hubble.Corner Apache.Creek|Mineral.Creek.Pueblo \n##                             FALSE                             FALSE\nset.seed(54)\nplot(lv, simple_net)"},{"path":"Exploratory.html","id":"ExploratoryRomanRoads","chapter":"Section 4 Exploratory Network Analysis","heading":"4.8 Case Study: Roman Roads","text":"case study provided end Chapter 4 Brughmans Peeples (2023) take simple network based Roman era roads spatial proximity settlements Iberian Peninsula calculate basic exploratory network statistics. described book, can create different definitions criteria network edges can impacts network node level properties. case, define three different networks follows:road_net - basic network every road connecting two settlements edgeroad_net2 - network retains ties network also connects isolated nodes within 50 Kms one road network settlementsroad_net3 - network retains ties first road network connects isolate nearest neighbor among road network settlementsFirst let’s read data file contains three networks start plotting turn map. using custom network map function save file called map_net.R takes locations decimal degrees locations plots network directly map. go specifics function detail Network Visualization Spatial Networks sections simply call script directly .R file. Make sure libraries initialized replicate map.Now ’ve replicated visuals, want replicate network statistics. Since ’re going calculate several network statistics networks question, can wrap function save bit time. following function expects igraph network object calculates 10 variables show example book returns matrix.Although function somewhat long, simple. defines function single argument net igraph network object. creates output matrix called appropriate number rows columns populates first column name measure. Next network measure evaluated turn assigned appropriate row column 2 matrix. Finally, full matrix returned: return().Now let’s run three networks turn reproduce results book. combine results single table nicely formatted using kable function. ’d prefer can simply view results net_stats() right console.extended discussion Cranborne Chase case study exponential random graph models click ","code":"\nlibrary(igraph)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(dplyr)\n\n# Read in required data\nload(\"data/road_networks.RData\")\n\nsource(\"scripts/map_net.R\")\n\n# Create Basic network map\nmap_net(\n  nodes = nodes,\n  net = road_net,\n  bounds = c(-9.5, 36, 3, 43.8),\n  gg_maptype = \"watercolor\",\n  zoom_lev = 6,\n  map_title = \"Basic Network\"\n)\n# Create Basic network map\nmap_net(\n  nodes = nodes,\n  net = road_net2,\n  bounds = c(-9.5, 36, 3, 43.8),\n  gg_maptype = \"watercolor\",\n  zoom_lev = 6,\n  map_title = \"Basic Network+ 50Km Buffer\"\n)\n# Create Basic network map\nmap_net(\n  nodes = nodes,\n  net = road_net3,\n  bounds = c(-9.5, 36, 3, 43.8),\n  gg_maptype = \"watercolor\",\n  zoom_lev = 6,\n  map_title = \"Basic Network + Nearest Neighbor Isolates\"\n)\nlibrary(igraph)\n\nnet_stats <- function(net) {\n  out <- matrix(NA, 10, 2)\n  out[, 1] <- c(\"Nodes\", \"Edges\", \"Isolates\", \"Density\", \"Average Degree\",\n               \"Average Shortest Path\", \"Diamater\",\n               \"Clustering Coefficient\", \"Closed Triad Count\",\n               \"Open Triad Count\")\n  # number of nodes\n  out[1, 2] <- vcount(net)\n  # number of edges\n  out[2, 2] <- ecount(net)\n  # number of isolates\n  out[3, 2] <- sum(igraph::degree(net) == 0)\n  # network density rounding to the third digit\n  out[4, 2] <- round(edge_density(net), 3)\n  # mean degree rounding to the third digit\n  out[5, 2] <- round(mean(igraph::degree(net)), 3)\n  # mean shortest path length rounding to the third digit\n  out[6, 2] <- round(igraph::mean_distance(net), 3)\n  # network diameter\n  out[7, 2] <- igraph::diameter(net)\n  # average global transitivity rounding to the third digit\n  out[8, 2] <- round(igraph::transitivity(net, type = \"average\"), 3)\n  # closed triads in triad_census\n  out[9, 2] <- igraph::triad_census(net)[16]\n  # open triads in triad_census\n  out[10, 2] <- igraph::triad_census(net)[11]\nreturn(out)\n}\nns1 <- net_stats(road_net)\n\nns2 <- net_stats(road_net2)\n\nns3 <- net_stats(road_net3)\n\nns_res <- cbind(ns1, ns2[, 2], ns3[, 2])\ncolnames(ns_res) <- c(\"Measure\", \"Basic Network\", \"50 Km Buffer\",\n                      \"Nearest Neighbors\")\n\nknitr::kable(ns_res, format = \"html\")"},{"path":"Uncertainty.html","id":"Uncertainty","chapter":"Section 5 Quantifying Uncertainty","heading":"Section 5 Quantifying Uncertainty","text":"almost archaeological network study, networks create incomplete (.e., know missing nodes edges various reasons: site destruction, lack survey coverage, looting, etc.). might fact networks samples larger typically unobtainable “total network” influence interpretations network structure node position? section, take inspiration recent research areas network research (Borgatti et al. 2006; Costenbader Valente 2003; Smith Moody 2013; Smith et al. 2017; Smith et al. 2022) develop means assessing impact missing poor quality information networks. accompanies Chapter 5 Brughmans Peeples (2023) recommend read Chapter 5 work examples .analyses presented book possible use number different network software packages conduct similar analyses. analyses presented Chapter 5, however, require creation custom scripts procedures possible programming language environment like R. attempt provide information replicate examples book also provide guidance might modify functions code provided purposes.","code":""},{"path":"Uncertainty.html","id":"UncertaintyScripts","chapter":"Section 5 Quantifying Uncertainty","heading":"5.1 R Scripts and Custom Functions","text":"chapter, created number relatively complex custom functions conduct assessments network uncertainty outlined Chapter 5. provide step step overviews functions work useful bundle functions .R script files call directly file working data.scripts described detail include:sim_missing_nodes.R - Assessments stability centrality metrics networks nodes missing random due biased sampling process.sim_missing_edges.R -Assessments stability centrality metrics networks edges missing random due biased sampling process.sim_missing_inc.R - Assessments stability centrality metrics networks nodes missing random based biased sampling incidence matrix data.sim_target_node.R - Assessments stability rank order position target node networks nodes missing random due biased sampling process.sim_samp_error.R - Assessments stability centrality metrics due sampling error frequency data underlying similarity networks.edge_prob.R - Functions conducting edge probability modeling plotting candidate networks centrality distributions.described greater detail along example. run scripts R, need put working directory use source() function. source function run code within .R file initialize functions contain. example:Note must include correct absolute relative file path script run properly.","code":"\nsource(\"scripts/sim_missing_nodes.R\")"},{"path":"Uncertainty.html","id":"UncertaintyGeneral","chapter":"Section 5 Quantifying Uncertainty","heading":"5.2 A General Approach to Uncertainty","text":"outlined book, basic approach quantifying dealing uncertainty use sample means understanding robustness vulnerability population sample drawn kinds variability perturbations might expect. procedures outline primarily take following basic form:Define network based available sample, calculate metrics characterize properties interest network.Derive large number modified samples network created step 1 (underlying data) simulate potential data problem sampling issue trying address. example, interested impact nodes missing random, randomly delete proportion nodes sample derived network created step 1.Calculate metrics characterize properties features interest every one random samples created step 2 assess central tendency (mean, median) distributional properties (range, standard deviation, distribution shape, etc.) features output appropriate.Compare distributions metrics properties (graph, node, edge level) random samples “original” network created step 1 assess potential impacts perturbation data treatment. comparison properties network created step 1 distribution properties created step 3 provide information directly relevant assessing impact kind perturbation created step 2 original network sample , extension, complete network drawn.underlying assumption approach outlined robustness vulnerability particular perturbation observed network data, drawn total network unattainable, provides information robustness vulnerability unattainable total network kinds perturbations. example, interested exploring degree distribution network sampling experiments show massive fluctuations degree sub-samples small numbers nodes removed random, suggest particular properties network robust nodes missing random degree calculations. , place much confidence results obtained original sample indicative total network drawn. hand, say instead find resampling experiments degree distributions sub-samples substantially similar original network sample even moderate large numbers nodes removed. case, might conclude network structure assessments degree distribution robust node missigness within range might expect original sample. important note, however, finding transferred metrics given network likely robust certain kinds perturbations certain network metrics, others.","code":""},{"path":"Uncertainty.html","id":"NodesAtRandom","chapter":"Section 5 Quantifying Uncertainty","heading":"5.3 Nodes Missing at Random","text":"sub-section accompanies discussion nodes edges missing random Brughmans Peeples (2023) Chapter 5.3.1. take one interval Chaco World ceramic similarity network (ca. .D. 1050-1100) simulate impact nodes missing random network centrality statistics. Download ceramic similarity adjacency matrix follow along.first thing need initialize required libraries, import network adjacency matrix, convert igraph network object. several examples section using simple undirected network though code also work weighted directed networks well.First, following Chapter 5.3.1, assess robustness data nodes missing random betweenness eigenvector centrality. order need define function removes specified proportion nodes random, assesses specified metric interest, compares sub-sample original sample terms rank order correlation (Spearman’s \\(\\rho\\)) among nodes metric question.help understand works, first walk example line line single centrality measure can see process designed. Following , initialize complex script can conduct analysis multiple measures even accommodate biased sampling processes see .Let’s start simple version. commented code chunk can follow along process. define two variables along way:nsim number simulations conduct sampling fractionprops vector sampling proportions test (0 > value < 1).code worked reasonably well bit laborious modify code every time wanted use different data set different network metric consider biased sampling processes. order address issue, created general function called sim_missing_nodes can replicate analysis shown previous section centrality measures (betweenness, degree, eigenvector) , see , can also used assess biased sampling processes. function essentially structured just like saw last chunk additions assess measure plan using, catch errors.function requires following arguments:net - igraph network object can undirected, directed, weighted must one-mode network.nsim - number random simulated networks created sampling fraction. default 1000.props - vector containing sampling fractions consider. Numbers must decimal form greater 0 less 1. default props = c(0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1). Note small networks inadvisable use small values props.met - argument used define metric interest must one : \"betweenness\", \"degree\", \"eigenvector\". specify argument receive error.missing_probs - argument expects vector many values nodes network. value probability value 0 1 (inclusive) node retained sub-sample network. default argument NA. argument isn’t specified function assumes testing nodes missing random.Let’s take look code. can also download script use data.script long, largely consists series ...else statements select appropriate analyses based user supplied arguments.Let’s give new function try calculate eigenvector centrality chaco_net network object. Note function melt function built data returned format required create plot.","code":"\nlibrary(igraph)\nlibrary(reshape2)\nlibrary(ggraph)\nlibrary(ggpubr)\nlibrary(statnet)\n\n# Import adjacency matrix and covert to network\nchaco <- read.csv(file = \"data/AD1050net.csv\", row.names = 1)\n\nchaco_net <- igraph::graph_from_adjacency_matrix(as.matrix(chaco),\n                                                 mode = \"undirected\")\n# Calculate node level metric of interest (betweenness in this case)\n# in the original network object\nmet_orig <- igraph::betweenness(chaco_net)\n\n# Define variables\nnsim <- 1000 # How many random simulations to create at each sampling level\nprops <- c(0.9, 0.8, 0.7, 0.6, 0.5, # set sub-sample proportions to test\n           0.4, 0.3, 0.2, 0.1)\n\n# Create an output matrix that will receive the results\noutput <- matrix(NA, nsim, length(props))\ncolnames(output) <- as.character(props)\n\n# Using for loops iterate over every value of props defined above nsim times\nfor (j in seq_len(length(props))) {\n  for (i in 1:nsim) {\n    # define a sub-sample at props[j] by retaining nodes from network\n    sub_samp <- sample(seq(1, vcount(chaco_net)), size =\n                       round(vcount(chaco_net) * props[j], 0))\n    # Create a network sub-set based on the sample defined above\n    sub_net <- igraph::induced_subgraph(chaco_net, sort(sub_samp))\n    # Calculate betweenness (or any measure of interest) in the sub-set\n    temp_stats <- igraph::betweenness(sub_net)\n    # Assess Spearman's rho correlation between met_orig and temp_stats\n    # and record in the output object at row i and column j.\n    output[i, j] <- suppressWarnings(cor(temp_stats,\n                                         met_orig[sort(sub_samp)],\n                                         method = \"spearman\"))\n  }\n} # repeat for all values of props, nsim times each\n\n\n# Visualize the results as a box plot using ggplot.\n# Melt wide data format into long data format first.\ndf <- melt(as.data.frame(output))\n\n# Plot visuals\nggplot(data = df) +\n  geom_boxplot(aes(x = variable, y = value)) +\n  xlab(\"Sub-Sample Size as Proportion of Original\") +\n  ylab(expression(\"Spearman's\" ~ rho)) +\n  theme_bw() +\n  # The lines inside this theme() call are simply\n  # there to change the font size of the figure\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(1))\n  )\nsim_missing_nodes <- function(net,\n                              nsim = 1000,\n                              props = c(0.9, 0.8, 0.7, 0.6, 0.5,\n                                        0.4, 0.3, 0.2, 0.1),\n                              met = NA,\n                              missing_probs = NA) {\n  # Initialize required library\n  require(reshape2)\n\n  props <- as.vector(props)\n\n  if (FALSE %in% (is.numeric(props) & (props > 0) & (props <= 1))) {\n    stop(\"Variable props must be numeric and be between 0 and 1\",\n         call. = F)\n  }\n\n  # Select measure of interest based on variable met and calculate\n  if (!(met %in% c(\"degree\", \"betweenness\", \"eigenvector\"))) {\n    stop(\n      \"Argument met must be either degree, betweenness, or eigenvector.\n      Check function call.\",\n      call. = F\n    )\n  }\n  else {\n    if (met == \"degree\") {\n      met_orig <- igraph::degree(net)\n    }\n    else   {\n      if (met == \"betweenness\") {\n        met_orig <- igraph::betweenness(net)\n      }\n      else {\n        if (met == \"eigenvector\") {\n          met_orig <- igraph::eigen_centrality(net)$vector\n        }\n      }\n    }\n  }\n\n# Create data frame for out put and name columns\n  output <- matrix(NA, nsim, length(props))\n  colnames(output) <- as.character(props)\n\n# Iterate over each value of props and then each value from 1 to nsim\n  for (j in seq_len(length(props))) {\n    for (i in 1:nsim) {\n      # Run code in brackets if missing_probs is NA\n      if (is.na(missing_probs)[1]) {\n        sub_samp <- sample(seq(1, vcount(net)),\n                           size = round(vcount(net) * props[j], 0))\n        sub_net <- igraph::induced_subgraph(net, sort(sub_samp))\n      }\n      # Run code in brackets if missing_probs contains values\n      else {\n        sub_samp <- sample(seq(1, vcount(net), prob = missing_probs),\n                           size = round(vcount(net) * props[j], 0))\n        sub_net <- igraph::induced_subgraph(net, sort(sub_samp))\n      }\n      # Select measure of interest based on met and calculate(same as above)\n      if (met == \"degree\") {\n        temp_stats <- igraph::degree(sub_net)\n      }\n      else   {\n        if (met == \"betweenness\") {\n          temp_stats <- igraph::betweenness(sub_net)\n        }\n        else {\n          if (met == \"eigenvector\") {\n            temp_stats <- igraph::eigen_centrality(sub_net)$vector\n          }\n        }\n      }\n      # Record output for row and column by calculating Spearman's rho between\n      # met_orig and each temp_stats iteration.\n      output[i, j] <- suppressWarnings(cor(temp_stats,\n                                           met_orig[sort(sub_samp)],\n                                           method = \"spearman\"))\n    }\n  }\n  # Return output as data.frame\n  df_output <- suppressWarnings(reshape2::melt(as.data.frame(output)))\n  return(df_output)\n}\n# Run the function\nset.seed(5609)\nev_test <- sim_missing_nodes(net = chaco_net, met = \"eigenvector\")\n\nggplot(data = ev_test) +\n  geom_boxplot(aes(x = variable, y = value)) +\n  xlab(\"Sub-Sample Size as Proportion of Original\") +\n  ylab(expression(\"Spearman's\" ~ rho)) +\n  theme_bw() +\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(1))\n  )"},{"path":"Uncertainty.html","id":"EdgesAtRandom","chapter":"Section 5 Quantifying Uncertainty","heading":"5.4 Edges Missing at Random","text":"cases, interested potential impact missing edges rather missing nodes. example, created network co-presence (based shared ceramic types, site mentions monuments, similar data) robust network omission certain edges? different centrality metrics influenced edge omission?section, conduct analysis similar described assessing missing nodes. Specifically, sub-sample networks removing fraction edges test stability centrality measures node position across range sampling fractions.function defined previous needs modified slightly help assess edges well. created new function associated script file accomplishes goal. give peak beneath hood, primary lines needed change. replaced first chunk code creates sub sample based vcount vertex count new line uses ecount edge count. switched induced_subgraph instead used delete_edges function.\nNote try evaluate chunk code \ncontains portions larger functions described \nreturn error.\nLet’s call new function assess impact edges missing random degree centrality give try. use default arguments nsim props . Since saved function .R file, can initialize using source function lets run code specified .R file.","code":"\n# Code from sim_missing_nodes\nsub_samp <- sample(seq(1, vcount(net), prob = missing_probs),\n                   size = round(vcount(net) * props[j], 0))\nsub_net <- igraph::induced_subgraph(net, sort(sub_samp))\n\n# Replaced code in sim_missing_edges\nsub_samp <- sample(seq(1, ecount(net), prob = missing_probs),\n                           size = round(ecount(net) * props[j], 0))\nsub_net <- igraph::delete_edges(net, which(!(seq(1, ecount(net))\n                                             %in% sub_samp)))\n# First initialize the function using the .R script\nsource(\"scripts/sim_missing_edges.R\")\n\n# Run the function\nset.seed(5609)\ndg_edge_test <- sim_missing_edges(net = chaco_net, met = \"degree\")\n\n# Visualize the results\nggplot(data = dg_edge_test) +\n  geom_boxplot(aes(x = variable, y = value)) +\n  xlab(\"Sub-Sample Size as Proportion of Original\") +\n  ylab(expression(\"Spearman's\" ~ rho)) +\n  theme_bw() +\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(1))\n  )"},{"path":"Uncertainty.html","id":"IndNodesAtRandom","chapter":"Section 5 Quantifying Uncertainty","heading":"5.5 Assessing Indivdiual Nodes/Edges","text":"sub-section follows along Chapter 5.3.2 Brughmans Peeples (2023). cases may interested simply robustness particular network metric specific kind perturbation across nodes edges, instead potential variability position characteristics single node (group nodes) due perturbations. order explore individual nodes, can employ similar procedures outlined additional modifications function. example use Cibola technological similarity network. describe book, want assess stability position Garcia Ranch site. Specifically, want know whether high betweenness centrality value Garcia Ranch robust nodes missing random network.define new function conduct analyses . function similar used instead providing Spearman’s \\(/rho\\) values outputs specific rank order node question across simulation.function requires six pieces information user:net - igraph network object. currently set simple networks easily modified.target - name target node wish assess (exactly written network object).prop - proportion nodes wish retain test. single number > 0 < 1.nsim - number simulations. default 1000.met - argument used define metric interest must one : \"betweenness\", \"degree\", \"eigenvector\". specify argument receive error.missing_probs - argument expects vector many values nodes network. value probability value 0 1 (inclusive) node retained sub-sample network. must include probability value target node though node always retained matter value use. default argument NA. argument isn’t specified function assumes testing nodes missing random.Briefly function works first determines node number corresponds target wish assess creates nsim subgraphs retain target. metric interest calculated network rank order position target node every network returned. function can calculated either “missing random” process leaving missing_probs set default NA.Let’s take look example. Use data follow along. can download sim_target_node.R script hereFirst read data:Now lets initialize function script using source() function, run function, create bar plot visualize results. Following example book, assessing robustness rank order position Garcia Ranch terms betweenness centrality nodes missing random. Note Garcia Ranch second highest centrality score original network:describe book, position Garcia Ranch highly central node appears stable nodes missing random. Indeed, far common position node 2 position original network.","code":"\n# Read in edge list file as data frame and create network object\ncibola_edgelist <-\n  read.csv(file = \"data/Cibola_edgelist.csv\", header = TRUE)\ncibola_net <-\n  igraph::graph_from_edgelist(as.matrix(cibola_edgelist),\n                              directed = FALSE)\nsource(\"scripts/sim_target_node.R\")\n\n# Run the function\nset.seed(52793)\ngr <- sim_target_node(\n  net = cibola_net,\n  target = \"Garcia Ranch\",\n  prop = 0.8,\n  nsim = 1000,\n  met = \"betweenness\"\n)\n\n# Visualize the results\ndf <- as.data.frame(gr)\ncolnames(df) <- \"RankOrder\"\n\nggplot(df, aes(x = RankOrder)) +\n  geom_bar() +\n  theme_bw() +\n  labs(title = \" \", x = \"Rank Order\", y = \"Count\") +\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2))\n  )"},{"path":"Uncertainty.html","id":"MissingBiased","chapter":"Section 5 Quantifying Uncertainty","heading":"5.6 Nodes/Edges Missing Due to Biased Sampling","text":"sub-section follows along Brughmans Peeples (2023) Chapter 5.3.3. many contexts interested modeling data missing random instead influenced biased sampling process. example, say study area lots general reconnaissance surveys recorded large sites full coverage surveys captured smaller sites. case, may wish model missingness small sites likely missing large sites.sim_missing_nodes sime_missing_edges functions created can help us test impacts biased sampling processes. order simply use additional argument missing_probs. argument requires vector length number nodes edges, depending function using. vector contain numeric values 0 1 denote probabilities node edge retained sub-sampling effort (must order nodes edges recorded network object).Let’s look hood see change implemented code. need modify one line code include biased sampling processes. chunk code two lines use sample function. function takes vector numbers selects sample (without replacement default) specified size. add argument prob use vector probabilities provided weight sample. ’s .\ncode chunk just purposes demonstration \nrepresents part function don’t try evaluate chunk\n’ll get error.\nNow, let’s try real example using chaco_net data creating random variable stand missing_probs . test impact missing nodes. simply create vector 223 random uniform numbers using runif function simulate probabilities associated 223 nodes. practice, probabilities based site size, visibility, feature choose.","code":"\n# Random sampling process\nsub_samp <- sample(seq(1, vcount(net)),\n                   size = round(vcount(net) * props[j], 0))\n\n# Biased sampling process\nsub_samp <- sample(seq(1, vcount(net)), prob = missing_probs,\n                   size = round(vcount(net) * props[j], 0))\n# Create 233 random numbers between 0 and 1 to stand in for\n# node probabilities\nset.seed(4463)\nmis <- runif(223, 0, 1)\nmis[1:10]##  [1] 0.6903157 0.9895447 0.3810867 0.2849476 0.2689112 0.9784197 0.8042309\n##  [8] 0.5805580 0.8660900 0.6179489\n# Run the function\ndg_test <- sim_missing_nodes(chaco_net, met = \"degree\", missing_probs = mis)\n\n# Visualize the results\nggplot(data = dg_test) +\n  geom_boxplot(aes(x = variable, y = value)) +\n  xlab(\"Sub-Sample Size as Proportion of Original\") +\n  ylab(expression(\"Spearman's\" ~ rho)) +\n  theme_bw() +\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(1))\n  )"},{"path":"Uncertainty.html","id":"SimIncidence","chapter":"Section 5 Quantifying Uncertainty","heading":"5.6.1 Resampling with Incidence Matrices","text":"book, illustrate approach biased sampling using co-authorship network data. case start incidence matrix publications authors want assess potential impact missing publications network authors. Since gathered data digital repositories citations, likely missing publications reasonable assume likely miss older publications newer ones given inclusion newer publications searchable digital indexes. Thus, example want assess missingness newer publications likely retained older ones sample. compare missing random assess results relate one another.First need provide two data files. first bibliographic attribute data includes date, publication type, information publication designated unique identifier. second incidence matrix publications denoted unique identifier (rows) authors (columns). read R create adjacency matrix author author connections using matrix algebra (multiply incidence matrix transpose incidence matrix), convert igraph network object calculate betweenness centrality nodes. plot simple network node link diagram visualize data.Although may first seem like use function used previously assess missing nodes, key differences organization data network won’t permit . Specifically, interested nodes (authors) missing random, want model probabilities associated publications. slightly complicated procedure function needs network object incidence matrix generated sub-networks can defined inside function. created sim_missing_inc function (simulating missing data using incidence matrix) conducts task.function requires five specific pieces information user:net - must include network object igraph format. use simple network code modified directed valued networks.inc - must also include incidence matrix (R matrix object) describes relationships . incidence matrix needs unique row names column names. mode interested assessing columns (words interested authors missing random authors represented columns publications rows).nsim - must specify number simulations perform. default 1000.props - must specify proportion nodes retained set nsim runs. provided vector proportions ranging > 0 1. default, script calculate 0.9 sub-sample way 0.1 sub-sample 0.1 intervals using props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1).lookup_dat - Finally, need provide data frame matrix contains two columns. first column unique name row incidence matrix (publication key case). second column include numeric value 0 1 indicates probability row retained resampling process. include nothing missing_probs function remove columns random equal probability .example , must first calculate data need provide missing_probs argument . simply take vector publication years bib object read rescale maximum value (recent publication) equals 1 older publications less 1. mean older publications often removed random sub-samples newer ones outlined example book.\nNote script provided focused assessing whichever\ncategory nodes represented columns original incidence\nmatrix. need modify code use incidence\nmatrix rows target simply use t()\ntranspose function place columns target position.\nprobabilities retention missing_probs place, can call source code sim_missing_inc.R script run function. Following example book run function nsim = 1000 3 sampling fractions (0.9, 0.8, 0.7) metric interest betweenness. Let’s first run function “probability date” biased sampling process.Next want run function simulate nodes missing random. need change missing_probs argument NA (exclude argument altogether). Let’s run :Now can combine results single data frame plot paired box plots comparison. order create paired box plots easiest create single data frame contains results runs . combine add new column called “Treatment” specifies row data frame whether part Random Biased sample.","code":"\n# Read in publication and author attribute data\nbib <- read.csv(\"data/biblio_attr.csv\")\nbib[1:3, ]##        Key      Item.Type\n## 1 FUV8A7JK journalArticle\n## 2 C7MRVHWA    bookSection\n## 3 3EG6T4P6 journalArticle\n##                                                         Publication.Title\n## 1                                    Archaeological Review from Cambridge\n## 2 Network analysis in archaeology. New approaches to regional interaction\n## 3                                                      American Antiquity\n##   Publication.Year          Authors\n## 1             2014       Stoner, Jo\n## 2             2013    Isaksen, Leif\n## 3             1991 Peregrine, Peter\n# Read in incidence matrix of publication and author data\nbib_dat <-\n  as.matrix(read.table(\n    \"data/biblio_dat2.csv\",\n    header = TRUE,\n    row.names = 1,\n    sep = \",\"\n  ))\n\n# Create adjacency matrix from incidence matrix using matrix algebra\nbib_adj <- t(bib_dat) %*% bib_dat\n# Convert to igraph network object removing self loops (diag=FALSE)\nbib_net <- igraph::graph_from_adjacency_matrix(bib_adj,\n                                               mode = \"undirected\",\n                                               diag = FALSE)\n# Calculate Betweenness Centrality\nbw_all <- igraph::betweenness(bib_net)\n\n# Plot network with nodes scaled based on betweenness\nset.seed(346)\nggraph(bib_net, layout = \"fr\") +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(shape = 21,\n                  aes(size = bw_all * 5),\n                  fill = \"gray\",\n                  alpha = 0.75) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n# Create a data frame of all unique combinations of publication code\n# and year from attributes data\nlookup <- unique(bib[, c(1, 4)])\n# Assign a probability for a publication to be retained inverse to\n# the year it was published\nlookup_prob <-\n  (lookup$Publication.Year - min(lookup$Publication.Year)) /\n  (max(lookup$Publication.Year) - min(lookup$Publication.Year))\n\n# Create data frame with required output. We have added a sort function\n# here to ensure that the order of probabilities in lookup_dat is the\n# same as the order of rows in the incidence matrix. You will get\n# spurious results if you do not ensure these are the same.\nlookup_dat <- sort(data.frame(Key = lookup[,1], prob = lookup_prob))\nhead(lookup_dat)##          Key      prob\n## 117 24QNVV37 0.9583333\n## 86  29GVMCNZ 0.0625000\n## 81  2QC8N5RN 1.0000000\n## 112 2QU9ZNUG 0.8125000\n## 126 2T8HPW5E 0.9583333\n## 18  37TC37D2 1.0000000\nsource(\"scripts/sim_missing_inc.R\")\n\n# Run function\nset.seed(4634)\nbib_bias <- sim_missing_inc(\n  net = bib_net,\n  inc = bib_dat,\n  missing_probs = lookup_dat$prob,\n  props = c(0.9, 0.8, 0.7),\n  met = \"betweenness\",\n)\nhead(bib_bias)##   variable     value\n## 1      0.9 0.9747220\n## 2      0.9 0.9608842\n## 3      0.9 0.9999614\n## 4      0.9 0.9999803\n## 5      0.9 0.9760737\n## 6      0.9 0.9999803\n# Run the function\nset.seed(4363)\nbib_rand <- sim_missing_inc(\n  net = bib_net,\n  inc = bib_dat,\n  missing_probs = NA,\n  props = c(0.9, 0.8, 0.7),\n  met = \"betweenness\"\n)\nhead(bib_rand)##   variable     value\n## 1      0.9 0.9817859\n## 2      0.9 0.9804552\n## 3      0.9 0.9818085\n## 4      0.9 0.8911948\n## 5      0.9 0.8733779\n## 6      0.9 1.0000000\n# Add a variable denoting which sample design it came from\nbib_rand$treatment <- rep(\"Random\", nrow(bib_rand))\nbib_bias$treatment <- rep(\"Biased\", nrow(bib_bias))\n\n# Bind into a single data frame, convert sampling faction to factor\n# and change order of levels for plotting\ndf <- rbind(bib_rand, bib_bias)\ndf$variable <- as.factor(df$variable)\ndf$variiable <- factor(df$variable, levels = c(\"0.9\", \"0.8\", \"0.7\"))\n\n# Plot the results\nggplot(data = df) +\n  geom_boxplot(aes(x = variable, y = value, fill = treatment)) +\n  scale_fill_manual(values = c(\"white\", \"gray\"), name = \"Group\") +\n  xlab(\"Sub-Sample Size as Proportion of Original\") +\n  ylab(expression(\"Spearman's\" ~ rho)) +\n  theme_bw() +\n  theme(\n    axis.text.x = element_text(size = rel(2)),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(2))\n  )"},{"path":"Uncertainty.html","id":"EdgeProbability","chapter":"Section 5 Quantifying Uncertainty","heading":"5.7 Edge Probability Modeling","text":"section take inspiration recent work area “Dark Networks” (see Everton 2012) investigation illicit networks. field, number methods recently developed allow researchers directly incorporate assessments reliability specific edges analyses. can done number different ways. Perhaps common approach networks based data gathered intelligence sources (studies terrorist networks) qualitatively assign different levels confidence ties pairs actors using ordinal scale determined based source information (reliable, usually reliable,… unreliable). ordinal scale confidence can converted probability (0 1) probability value used inform creation range “possible” networks given underlying data.aware archaeological examples edges formally qualitatively assigned “confidence levels” exactly way, think potential applications method. example, define network assign low probability tie two archaeological sites share import third site/region higher probability tie two sites share imports others’ region. Importantly, methods can used combine information different sources single assessment probability connection.Since data structured exactly way, use small simulated data set consists edge list weights. Use file follow along. simple edge list probability values assigned edge values 0.2, 0.4, 0.6, 0.8, 1.0.Let’s read data plot :next chunk code define function iterates every edge simulated network just created defines edge either present absent using simple random binomial probability set edge weight described . output function (edge_prob) list object contains nsim igraph network objects candidate networks original.order extract values interest candidate networks, created another function called compile_stat. function iterates nsim networks net_list list object calculates centrality metric interest case returning results simple matrix. possible compare things like average degree distribution degree particular nodes across candidate networks. placed two functions additional script file called edge_prob.R can download use modify .Now run edge_prob function nsim = 1000 display candidate networks.use compile_stat function assess degree centrality one particular node, displaying histogram values mean indicated.","code":"\n# Read in edge_list\nsim_edge <- as.matrix(read.csv(\"data/sim_edge.csv\",\n                     header = T, row.names = 1))\n\n# Create network object and assign edge weights and node names\nsim_net <- igraph::graph_from_edgelist(sim_edge[, 1:2])\nE(sim_net)$weight <- sim_edge[order(sim_edge[, 3]), 3]\nV(sim_net)$name <- seq(1:20)\n\n# Create color ramp palette\nedge_cols <- colorRampPalette(c(\"gray\", \"darkblue\"))(5)\n\n# Plot the resulting network\nset.seed(4364672)\nggraph(sim_net, layout = \"fr\") +\n  geom_edge_link0(aes(width = E(sim_net)$weight * 5),\n                  edge_colour = edge_cols[E(sim_net)$weight * 5],\n                  show.legend = FALSE) +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(sim_net) + 3,\n                  fill = \"red\") +\n  geom_node_text(\n    aes(label = as.character(name)),\n    col = \"white\",\n    size = 3.5,\n    repel = FALSE\n  ) +\n  theme_graph()\n# Define function for assessing and retaining edges based on edge\n# weight probabilities\nedge_prob <- function(net, nsim = 1000, probs) {\n  net_list <- list()\n  for (i in 1:nsim) {\n    sub_set <- NULL\n    for (j in 1:ecount(net)) {\n      temp <- rbinom(1, 1, prob = probs[j])\n      if (temp == 1) {\n        sub_set <- c(sub_set, j)\n      }\n    }\n    net_list[[i]] <-\n      igraph::delete_edges(net, which(!(seq(1, ecount(\n        net\n      ))\n      %in% sub_set)))\n  }\n  return(net_list)\n}\n\n# Define function for assessing statistic of interest\ncompile_stat <- function(net_list, met) {\n  out <- matrix(NA, vcount(net_list[[1]]), length(net_list))\n  for (i in seq_len(length(net_list))) {\n    # Select measure of interest based on met and calculate(same as above)\n    if (met == \"degree\") {\n      out[, i] <- igraph::degree(net_list[[i]])\n    }\n    else  {\n      if (met == \"betweenness\") {\n        out[, i] <- igraph::betweenness(net_list[[i]])\n      }\n      else {\n        if (met == \"eigenvector\") {\n          out[, i] <- igraph::eigen_centrality(net_list[[i]])$vector\n        }\n      }\n    }\n  }\n  return(out)\n}\nel_test <- edge_prob(sim_net, nsim = 1000, probs = sim_edge[, 3])\n\nset.seed(9651)\ncomp1 <- ggraph(el_test[[1]], layout = \"fr\") +\n  geom_edge_link0(aes(width = E(el_test[[1]])$weight),\n                  edge_colour = edge_cols[E(el_test[[1]])$weight * 5],\n                  show.legend = FALSE) +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(el_test[[1]]),\n                  fill = \"red\") +\n  geom_node_text(\n    aes(label = as.character(name)),\n    col = \"white\",\n    size = 2.5,\n    repel = FALSE\n  ) +\n  theme_graph()\n\ncomp2 <- ggraph(el_test[[2]], layout = \"fr\") +\n  geom_edge_link0(aes(width = E(el_test[[2]])$weight),\n                  edge_colour = edge_cols[E(el_test[[2]])$weight * 5],\n                  show.legend = FALSE) +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(el_test[[2]]),\n                  fill = \"red\") +\n  geom_node_text(\n    aes(label = as.character(name)),\n    col = \"white\",\n    size = 2.5,\n    repel = FALSE\n  ) +\n  theme_graph()\n\ncomp3 <- ggraph(el_test[[3]], layout = \"fr\") +\n  geom_edge_link0(aes(width = E(el_test[[3]])$weight),\n                  edge_colour = edge_cols[E(el_test[[3]])$weight * 5],\n                  show.legend = FALSE) +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(el_test[[3]]),\n                  fill = \"red\") +\n  geom_node_text(\n    aes(label = as.character(name)),\n    col = \"white\",\n    size = 2.5,\n    repel = FALSE\n  ) +\n  theme_graph()\n\nggarrange(comp1, comp2, comp3)\ndg_stat <- compile_stat(el_test, met = \"degree\")\n\ndg_20 <- data.frame(val = dg_stat[20, ])\n\nggplot(dg_20, aes(val)) +\n  geom_histogram(binwidth = 1) +\n  xlab(\"Degree Centrality of Node 20\") +\n  geom_vline(xintercept = mean(dg_20$val), col = \"red\") +\n  theme_bw()"},{"path":"Uncertainty.html","id":"EdgeProbSim","chapter":"Section 5 Quantifying Uncertainty","heading":"5.7.1 Edge Probability and Similarity Networks","text":"One area archaeological network research edge probability modeling approach outlined may use relates similarity networks. Many similarity networks used archaeology built edge weights scaled 0 1. edge weights thought “probabilities” just saw simulated example . Indeed, conforms frequent interpretation similarity values relating probabilities interaction numerous network studies (e.g., Mills et al. 2013a, 2013b, 2015; Golitko Feinman 2015; Golitko et al. 2012, etc.).Let’s take look example using weighted similarity network generated using Cibola technological similarity data used . Download RData file follow along.Now let’s plot couple candidate networks:","code":"\nload(\"data/Cibola_wt.RData\")\n\n# View first few edge weights in network object\nE(cibola_wt)$weight[1:10]##  [1] 0.7050691 0.7757143 0.8348214 0.8656783 0.8028571 0.7329193 0.7509158\n##  [8] 0.8441558 0.7857143 0.8102919\nset.seed(4446347)\nsim_nets <- edge_prob(cibola_wt, nsim = 1000, probs = E(cibola_wt)$weight)\n# Precompute layout\nset.seed(9631)\nxy <- layout_with_fr(cibola_wt)\n\n# Example 1\ncomp1 <- ggraph(sim_nets[[1]],\n                layout = \"manual\",\n                x = xy[, 1],\n                y = xy[, 2]) +\n  geom_edge_link() +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(sim_nets[[1]]) / 3,\n                  fill = \"red\") +\n  theme_graph()\n\n# Example 2\ncomp2 <- ggraph(sim_nets[[2]],\n                layout = \"manual\",\n                x = xy[, 1],\n                y = xy[, 2]) +\n  geom_edge_link() +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(sim_nets[[2]]) / 3,\n                  fill = \"red\") +\n  theme_graph()\n\n# Example 3\ncomp3 <- ggraph(sim_nets[[3]],\n                layout = \"manual\",\n                x = xy[, 1],\n                y = xy[, 2]) +\n  geom_edge_link() +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(sim_nets[[3]]) / 3,\n                  fill = \"red\") +\n  theme_graph()\n\nggarrange(comp1, comp2, comp3)\nbw_test <- compile_stat(sim_nets, met = \"betweenness\")\n\nbw_10 <- data.frame(val = bw_test[10, ])\n\nggplot(bw_10, aes(val)) +\n  geom_histogram() +\n  xlab(\"Betweenness Centrality of Node 10\") +\n  geom_vline(xintercept = mean(bw_10$val), col = \"red\") +\n  theme_bw()"},{"path":"Uncertainty.html","id":"SampleSize","chapter":"Section 5 Quantifying Uncertainty","heading":"5.8 Uncertainty Due to Small or Variable Sample Size","text":"section follows Brughmans Peeples (2023) Chapter 5.3.5 provide example can use simulation approach outlined assess sampling variability frequency data underlying archaeological networks. example, use apportioned ceramic frequency data Chaco World portion Southwest Social Networks database. can download data follow along.goal sub-section illustrate can use bootstrapping approach assess variability network properties based sampling error raw data underlying archaeological networks. example based ceramic similarity networks involves creating large number random replicates row raw ceramic data sample size held constant (observed sample size site) probabilities given sherd given type determined underlying multinomial frequency distribution types site. words, pull bunch random samples site probability given sample given type determined relative frequency type actual data. procedure completed, can assess centrality metrics graph, node, edge level property determine degree absolute values relative ranks potentially influenced sampling error.many ways set resampling procedure many complications (example, deal limited diversity small samples?). purposes illustration , implement simple procedure simply generate new samples fixed size based observed data determine degree network measures robust perturbation. chunk code create 1000 replicates based original ceramic data.following chunk code first reads ceramic data, converts Brainerd-Robinson similarity matrix defines function called sim_samp_error creates nsim random replicates ceramic data, converts similarity matrices, outputs results list object. can download script fucnction .following chunk code runs sim_samp_error function defined Chaco ceramic data defines new function called sim_cor takes output sim_samp_error original ceramic similarity matrix (ceramic_BR) calculates weighted degree centrality Spearman’s \\(\\rho\\) correlations original similarity matrix random replicate. sim_cor script modified use network metric outputs vector. results returned visualize results histogram.Note take several seconds minutes depending computer.described Chapter 5.3.5, cases want observe patterns variation due sampling error individual sites sets sites. next chunk code illustrate produce figure 5.14 Brughmans Peeples (2023) book. Specifically, plot consists series line plots x axis represents node network ordered degree centrality original observed network. node vertical line represents 95% confidence interval around degree across nsim random replicates produced evaluate sampling error. blue line represents degree original network red line represents median degree resampled networks.create plot, first iterate every object sim_nets calculate weighted degree centrality add two-column matrix along node id. done simulations, use summarise function calculate mean, median, max, min, confidence interval (95%). plot observed values degree blue, mean values red, confidence intervals black vertical bars node. nodes sorted low high degree centrality original network.","code":"\n# Read in raw ceramic data\nceramic <-\n  read.csv(file = \"data/AD1050cer.csv\",\n           header = TRUE,\n           row.names = 1)\n# Convert to proportion\nceramic_p <- prop.table(as.matrix(ceramic), margin = 1)\n# Convert to Brainerd-Robinson similarity matrix\nceramic_br <- ((2 - as.matrix(vegan::vegdist(ceramic_p,\n                                           method = \"manhattan\"))) / 2)\n\n# Create function for assessing impact of sampling error on\n# weighted degree for similarity network\nsim_samp_error <- function(cer, nsim = 1000) {\n  sim_list <- list()\n  for (i in 1:nsim) {\n    data_sim <-  NULL\n    # the for-loop below creates a random multinomial replicate\n    # of the ceramic data\n    for (j in seq_len(nrow(cer))) {\n      data_sim <-\n        rbind(data_sim, t(rmultinom(1, rowSums(cer)[j], prob = cer[j, ])))\n    }\n    # Convert simulated data to proportion, create similarity matrix,\n    # calculate degree, and assess correlation\n    temp_p <- prop.table(as.matrix(data_sim), margin = 1)\n    sim_list[[i]] <- ((2 - as.matrix(vegan::vegdist(temp_p,\n                                           method = \"manhattan\"))) / 2)\n  }\n  return(sim_list)\n}\nset.seed(4634)\nsim_nets <- sim_samp_error(cer = ceramic, nsim = 1000)\n\nsim_cor <- function(sim_nets, sim) {\n  # change this line to use a different metric\n  dg_orig <- rowSums(sim)\n  dg_cor <- NULL\n  for (i in seq_len(length(sim_nets))) {\n    # change this line to use a different metric\n    dg_temp <- rowSums(sim_nets[[i]])\n    dg_cor[i] <-\n      suppressWarnings(cor(dg_orig, dg_temp, method = \"spearman\"))\n  }\n  return(dg_cor)\n}\n\ndg_cor <- sim_cor(sim_nets, ceramic_br)\n\ndf <- as.data.frame(dg_cor)\n\nggplot(df, aes(x = dg_cor)) +\n  geom_histogram(bins = 100, color = \"white\", fill = \"black\") +\n  theme_bw() +\n  scale_x_continuous(name = \"Correlation in Degree Centraility\",\n                     limits = c(0.9, 1)) +\n  theme(\n    axis.text.x = element_text(size = rel(1.5)),\n    axis.text.y = element_text(size = rel(1.5)),\n    axis.title.x = element_text(size = rel(1.5)),\n    axis.title.y = element_text(size = rel(1.5)),\n    legend.text = element_text(size = rel(1.5))\n  )\n# Create data frame containing degree and site id for nsim random\n# similarity matrices\ndf <- matrix(NA, 1, 2) # define empty matrix\n# calculate degree centrality for each random run and bind in\n# matrix along with id\nfor (i in seq_len(length(sim_nets))) {\n  temp <- cbind(seq(1, nrow(sim_nets[[i]])), rowSums(sim_nets[[i]]))\n  df <- rbind(df, temp)\n}\ndf <- as.data.frame(df[-1, ]) # remove first row in initial matrix\ncolnames(df) <- c(\"site\", \"degree\") # add column names\n\n# Use summarise function to create median, confidence intervals,\n# and other statistics for degree by site.\nout <- df %>%\n  group_by(site) %>%\n  dplyr::summarise(\n    Mean = mean(degree),\n    Median = median(degree),\n    Max = max(degree),\n    Min = min(degree),\n    Conf = sd(degree) * 1.96\n  )\nout$site <- as.numeric(out$site)\nout <- out[order(rowSums(ceramic_br)), ]\n\n# Create data frame of degree centrality for the original ceramic\n# similarity matrix\ndg_wt <- as.data.frame(rowSums(ceramic_br))\ncolnames(dg_wt) <- \"dg.wt\"\n\n# Plot the results\nggplot() +\n  geom_line(\n    data = out,\n    aes(\n      x = reorder(site, Median),\n      y = Median,\n      group = 1\n    ),\n    col = \"red\",\n    lwd = 1.5,\n    alpha = 0.5\n  ) +\n  geom_errorbar(data = out, aes(\n    x = reorder(site, Median),\n    ymin = Median - Conf,\n    ymax = Median + Conf\n  )) +\n  geom_path(\n    data = sort(dg_wt),\n    aes(x = order(dg.wt), y = dg.wt),\n    col = \"blue\",\n    lwd = 1.5,\n    alpha = 0.5\n  ) +\n  theme_bw() +\n  ylab(\"Degree\") +\n  scale_x_discrete(name = \"Sites in Rank Order of Degree\") +\n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.y = element_text(size = rel(2)),\n    axis.title.x = element_text(size = rel(2)),\n    axis.title.y = element_text(size = rel(2)),\n    legend.text = element_text(size = rel(2))\n  )"},{"path":"Visualization.html","id":"Visualization","chapter":"Section 6 Network Visualization","heading":"Section 6 Network Visualization","text":"section follows along Brughmans Peeples (2023) chapter 6 illustrate wide variety techniques can used network visualization. begin general examples network plotting demonstrate replicate specific examples appear book. examples rely R cases use software provide additional details data formats.already excellent resources online learning create beautiful informative network visuals. recommend excellent online materials produced Dr. Katherine Ognyanova available website Static dynamic network visualization R workshop materials particular. Many examples book take inspiration work. addition , R Graph Gallery website created Holtz Yan provides numerous excellent examples plots R using ggplot2 ggraph packages among many others. new R, probably helpful read bit basic graphic functions (including tutorials listed ) getting started.","code":""},{"path":"Visualization.html","id":"VizDatasets","chapter":"Section 6 Network Visualization","heading":"6.1 Data and R Setup","text":"order make easy possible users replicate specific visuals book examples tutorial tried make examples modular possible. means provide calls initialize required libraries plot within relevant chunk code (can easily tell package ) also provide links download data required replicate figure description figure . data sets use include .csv format files well .Rdata files contain sets specific R objects formatted required individual chunks code.plan working entire tutorial like download associated data can download zip file. Simply extract zip folder R working directory examples work. Note examples setup data contained sub-folder working directory called “data” (note directories file names case sensitive).","code":""},{"path":"Visualization.html","id":"ViZInR","chapter":"Section 6 Network Visualization","heading":"6.2 Visualizing Networks in R","text":"\nmany tools available creating network visualizations \nR including functions built directly igraph \nstatnet packages. get details, first\nbriefly illustrate primary network plotting options \nigraph, statnet visualization package\ncalled ggraph. start initializing required\nlibraries reading adjacency matrix creating network\nobjects igraph statnet format.\nbasis examples section.\nLet’s start reading example data describe package turn:","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(ggraph)\nlibrary(intergraph)\n\n\ncibola <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = TRUE,\n           row.names = 1)\n\ncibola_attr <- read.csv(file = \"data/Cibola_attr.csv\", header = TRUE)\n\n# Create network in igraph format\ncibola_i <- igraph::graph_from_adjacency_matrix(as.matrix(cibola),\n                                                mode = \"undirected\")\ncibola_i## IGRAPH bd87d74 UN-- 31 167 -- \n## + attr: name (v/c)\n## + edges from bd87d74 (vertex names):\n##  [1] Apache.Creek--Casa.Malpais          Apache.Creek--Coyote.Creek         \n##  [3] Apache.Creek--Hooper.Ranch          Apache.Creek--Horse.Camp.Mill      \n##  [5] Apache.Creek--Hubble.Corner         Apache.Creek--Mineral.Creek.Pueblo \n##  [7] Apache.Creek--Rudd.Creek.Ruin       Apache.Creek--Techado.Springs      \n##  [9] Apache.Creek--Tri.R.Pueblo          Apache.Creek--UG481                \n## [11] Apache.Creek--UG494                 Atsinna     --Cienega              \n## [13] Atsinna     --Los.Gigantes          Atsinna     --Mirabal              \n## [15] Atsinna     --Ojo.Bonito            Atsinna     --Pueblo.de.los.Muertos\n## + ... omitted several edges\n# Create network object in statnet/network format\ncibola_n <- asNetwork(cibola_i)\ncibola_n##  Network attributes:\n##   vertices = 31 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 167 \n##     missing edges= 0 \n##     non-missing edges= 167 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes"},{"path":"Visualization.html","id":"networkpackage","chapter":"Section 6 Network Visualization","heading":"6.2.1 network package","text":"need plot network/statnet network object simply type plot(nameofnetwork). default, creates network plot nodes edges shown color weight using Fruchterman-Reingold graph layout default. , however, many options can altered basic plot. order see details can type ?plot.network console associated document.order change color nodes, layout, symbols, features, can add arguments detailed help document. arguments can include calls functions, mathematical expressions, even additional data attribute files. example following plot, calculate degree centrality directly within plot call divide result 10 ensure nodes reasonable size plot. use vertex.cex argument set node size based results expression. change layout using “mode” argument produce network graph using Kamada-Kawai layout. change color nodes represent Region variable associated attribute file using vertex.col argument set change edge colors using edge.col argument. Finally, use displayisolates = FALSE indicate want single isolated node plotted. many options.","code":"\nset.seed(6332)\nplot(cibola_n)\nset.seed(436)\nplot(\n  cibola_n,\n  vertex.cex = sna::degree(cibola_n) / 10,\n  mode = \"kamadakawai\",\n  vertex.col = as.factor(cibola_attr$Region),\n  edge.col = \"darkgray\",\n  displayisolates = FALSE\n)"},{"path":"Visualization.html","id":"igraphpackage","chapter":"Section 6 Network Visualization","heading":"6.2.2 igraph package","text":"igraph package also built plotting function called plot.igraph. call just need type plot(yournetworkhere) provide igraph object (R can tell kind object simply type plot). default igraph plot uses Fruchterman-Reingold layout just like statnet/network default node labeled.Let”s take look options can alter change plot. many options explore help documents igraph.plotting describe detail (type ?igraph.plotting console ). want explore igraph , suggest check Network Visualization tutorial linked provides discussion wide variety options.","code":"\nset.seed(435)\nplot(cibola_i)\nset.seed(3463)\nplot(\n  cibola_i,\n  vertex.size = igraph::eigen_centrality(cibola_i)$vector * 20,\n  layout = layout_with_kk,\n  vertex.color = as.factor(cibola_attr$Great.Kiva),\n  edge.color = \"darkblue\",\n  vertex.frame.color = \"red\",\n  vertex.label = NA\n)"},{"path":"Visualization.html","id":"ggraphpackage","chapter":"Section 6 Network Visualization","heading":"6.2.3 ggraph package","text":"ggraph package provides powerful set tools plotting visualizing network data R. format used package bit different saw instead relies ggplot2 style plots plot type called modifications made sets lines additional arguments separated +. Although takes bit getting used found ggplot format often intuitive making complex graphics understand basics.Essentially, way ggraph call works start ggraph function call includes network object layout information. provide lines specifying edges geom_edge_link nodes geom_node_point features . Conveniently ggraph function call take either igraph network object need convert.example. first call igraph network object Cibola_i specify Fruchterman-Reingold layout using layout = \"fr\". Next, call geom_edge_link specify edge colors. geom_node_point call specifies many attributes nodes including fill color, outline color, transparency (alpha), shape, size using igraph::degree function. scale_size call tells plot scale node size specified previous line range 1 4. Finally theme_graph basic call ggraph theme tells plot make background white remove margins around edge plot. Let’s see looks.next section go common options ggraph detail.many options ggraph package recommend exploring help document (?ggraph) well Data Imaginist ggraph tutorial online . examples use ggraph format.","code":"\nset.seed(4368)\n# Specify network to use and layout\nggraph(cibola_i, layout = \"fr\") +\n  # Specify edge features\n  geom_edge_link(color = \"darkgray\") +\n  # Specify node features\n  geom_node_point(\n    fill = \"blue\",\n    color = \"red\",\n    alpha = 0.5,\n    shape = 22,\n    aes(size = igraph::degree(cibola_i)),\n    show.legend = FALSE\n  ) +\n  # Set the upper and lower limit of the \"size\" variable\n  scale_size(range = c(1, 10)) +\n  # Set the theme \"theme_graph\" is the default theme for networks\n  theme_graph()## Warning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated."},{"path":"Visualization.html","id":"NetVizOptions","chapter":"Section 6 Network Visualization","heading":"6.3 Network Visualization Options","text":"section illustrate useful graphical options visualizing networks, focusing particular ggraph format. cases similar options available plotting functions network igraph. relevant reference specific figures book tutorial code figures produced R presented next session. examples section use Cibola technological similarity data (click download). First call required packages import data.","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(ggraph)\n\nload(\"data/Peeples2018.Rdata\")\n\n# Create igraph object for plots below\nnet <- asIgraph(brnet)"},{"path":"Visualization.html","id":"GraphLayouts","chapter":"Section 6 Network Visualization","heading":"6.3.1 Graph Layout","text":"Graph layout simply refers placement organization 2-dimensional 3-dimensional space nodes edges network.","code":""},{"path":"Visualization.html","id":"ManualLayouts","chapter":"Section 6 Network Visualization","heading":"6.3.1.1 Manual or User Defined Layouts","text":"options manually defining node placement graph layout R easiest simply provide x y coordinates directly. example, plot Cibola technological similarity network set x y coordinates group sites region grid configuration. another example approach see Figure 6.1 . example can interactively define layout see Figure 6.5","code":"\n# site_info - site location and attribute data\n\n# Create xy coordinates grouped by region\nxy <-\n  matrix(\n    c(1, 1, 3, 3, 2, 1, 2, 1.2, 3, 3.2, 2, 1.4, 1, 1.2, 2, 2.2, 3,\n      2, 3, 1, 2.2, 1, 2, 3, 2, 3.2, 3, 1.2, 3, 3.4, 1, 2, 3.2, 3.2,\n      3, 1.4, 3, 2.2, 2, 2, 3.2, 3.4, 2.2, 1.2, 3.4, 3.2, 3.2, 1, 2,\n      3.4, 3.4, 3.4, 2.2, 3, 2.2, 3.2, 2.2, 3.4, 1, 1.4, 3, 2.4),\n    nrow = 31,\n    ncol = 2,\n    byrow = TRUE\n)\n\n# Plot using \"manual\" layout and specify xy coordinates\nggraph(net,\n       layout = \"manual\",\n       x = xy[, 1],\n       y = xy[, 2]) +\n  geom_edge_link(edge_color = \"gray\") +\n  geom_node_point(aes(size = 4, col = site_info$Region),\n                  show.legend = FALSE) +\n  theme_graph()"},{"path":"Visualization.html","id":"GeographicLayouts","chapter":"Section 6 Network Visualization","heading":"6.3.1.2 Geographic Layouts","text":"Plotting networks using geographic layout essentially plotting manual layout except specify geographic coordinates instead coordinates. See Figure 6.2 another example.working geographic data, also sometimes useful plot directly top sort base map. many options one convenient use sf ggmap packages directly download relevant base map layer plot directly top . first requires converting points latitude longitude decimal degrees already format. See details sf package ggmap package details.demonstrate use ggmap get_stadiamap function requires bit additional explanation. function automatically retrieves background map using arguments:bbox - bounding box represents decimal degrees longitude latitude coordinates lower left upper right area wish map.maptype - name indicates style map use (check options).zoom - variable denoting detail zoom level retrieved. Higher number give detail take longer detail.early 2024 get_stadiamap function also requires sign account stadiamaps.com. account free allows download large number background maps R per month (likely FAR individual ever use). setup steps required get work. can follow steps click YouTube video outlining steps 1 thorugh 3 .First, need sign free account Stadiamaps.First, need sign free account Stadiamaps.sign , asked create Property Name, designating using data. can simply call “R analysis” anything ’d like.sign , asked create Property Name, designating using data. can simply call “R analysis” anything ’d like.create property ’ll able assign API key clicking “Add API” button.create property ’ll able assign API key clicking “Add API” button.Now simply need let R know API allow map download access. order copy API key visible stadiamaps page property created run following line code adding actual API key place [KEY ]Now simply need let R know API allow map download access. order copy API key visible stadiamaps page property created run following line code adding actual API key place [KEY ]Note, ease demonstration, remainder online guide (code chunk ) pre-download maps provide file instead using get_stadiamap function.\ndescribe specifics spatial data handling, geographic\ncoordinates, projection section Spatial Networks. See section \nfull description R deals geographic information.\n","code":"\nggraph(net,\n       layout = \"manual\",\n       x = site_info$x,\n       y = site_info$y) +\n  geom_edge_link(edge_color = \"gray\") +\n  geom_node_point(aes(size = 4, col = site_info$Region),\n                  show.legend = FALSE) +\n  theme_graph()\nlibrary(ggmap)\nactivate(key=\"[YOUR KEY HERE]\")## ℹ Google's Terms of Service: <https://mapsplatform.google.com>\n##   Stadia Maps' Terms of Service: <https://stadiamaps.com/terms-of-service/>\n##   OpenStreetMap's Tile Usage Policy: <https://operations.osmfoundation.org/policies/tiles/>\n## ℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\nlibrary(sf)\nlibrary(ggmap)\n\n# Convert attribute location data to sf coordinates and change\n# map projection\nlocations_sf <-\n  st_as_sf(site_info, coords = c(\"x\", \"y\"), crs = 26912)\nloc_trans <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(loc_trans)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n# Get basemap \"stamen_terrain_background\" data for map in black and white\n# the bbox argument is used to specify the corners of the box to be\n# used and zoom determines the detail.\nbase_cibola <- get_stadiamap(\n  bbox = c(-110.2, 33.4, -107.8, 35.3),\n  zoom = 10,\n  maptype = \"stamen_terrain_background\",\n  color = \"bw\"\n)\n\n# Extract edge list from network object\nedgelist <- get.edgelist(net)\n\n# Create data frame of beginning and ending points of edges\nedges <- data.frame(xy[edgelist[, 1], ], xy[edgelist[, 2], ])\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Plot original data on map\nggmap(base_cibola, darken = 0.35) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"white\",\n    alpha = 0.8,\n    size = 1\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y, col = site_info$Region),\n    alpha = 0.8,\n    size = 5,\n    show.legend = FALSE\n  ) +\n  theme_void()"},{"path":"Visualization.html","id":"AlgorithmicLayouts","chapter":"Section 6 Network Visualization","heading":"6.3.1.3 Shape-Based and Algorithmic Layouts","text":"wide variety shape-based algorithmic layouts available use R. cases, takes change layouts simply modify single line ggraph call specify desired layout. ggraph package can use igraph layouts well many built directly package. See ?ggraph details see options. show examples. Note leave figures calls except argument layout = \"yourlayout\" ggraph call ggtitle name. layouts involve randomization, use set.seed() function make sure always plot . See discussion Figure 6.8 details. Beyond Figure 6.9 provides additional options can used hierarchical network data.\nspecify graph layout ggraph, \nplotting function automatically choose layout using \nlayout_nicely() function. Although sometimes produces\nuseful layout used specified call recommend\nsupplying layout argument directly.\n\ncode used ggarrange function within\nggpubr package combine figures single\noutput. function works ggplot2 \nggraph format output supply names \nfigure order want appear number rows\nnrow number columns ncol want \nresulting combined figure . want label figure\nusing ggarrange function can use \nlabels argument.\n","code":"\n# circular layout\ncirc_net <- ggraph(net, layout = \"circle\") +\n  geom_edge_link(edge_color = \"gray\") +\n  geom_node_point(aes(size = 4, col = site_info$Region),\n                  show.legend = FALSE) +\n  ggtitle(\"Circle\") +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1)))\n\n# Fruchcterman-Reingold layout\nset.seed(4366)\nfr_net <- ggraph(net, layout = \"fr\") +\n  geom_edge_link(edge_color = \"gray\") +\n  geom_node_point(aes(size = 4, col = site_info$Region),\n                  show.legend = FALSE) +\n  ggtitle(\"Fruchterman-Reingold\") +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1)))\n\n# Davidsons and Harels annealing algorithm layout\nset.seed(3467)\ndh_net <- ggraph(net, layout = \"dh\") +\n  geom_edge_link(edge_color = \"gray\") +\n  geom_node_point(aes(size = 4, col = site_info$Region),\n                  show.legend = FALSE) +\n  ggtitle(\"Davidson-Harel\") +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1)))\n\nlibrary(ggpubr)\nggarrange(circ_net, fr_net, dh_net, nrow = 1)"},{"path":"Visualization.html","id":"NodeEdgeOptions","chapter":"Section 6 Network Visualization","heading":"6.3.2 Node and Edge Options","text":"many options altering color symbol nodes edges within R. section briefly discuss common options. details see discussion figures 6.10 6.16 .","code":""},{"path":"Visualization.html","id":"NodeOptions","chapter":"Section 6 Network Visualization","heading":"6.3.2.1 Nodes","text":"ggraph changing node options mostly consists changing options within geom_node_point call within ggraph figure call. already seen possible set color nodes variable, change size points, can also scale points metric like centrality. Indeed, even possible make call centrality function question directly within figure code.selecting point shapes can use shapes available base R using pch point codes. available options:many options selecting colors nodes edges. can assigned using standard color names can assigned using rgb hex codes. also possible use standard palettes packages like RColorBrewer scales specify categorical continuous color schemes. often done using either scale_fill_brewer scale_color_brewer calls RColorBrewer. couple examples. examples, colors grouped site region, node size scaled degree centrality, node edge color shape specified call. Note alpha command controls transparency relevant part plot. scale_size call specifies maximum minimum size points plot.R Graph Gallery good overview available color palettes RColorBrewer can used. “Set2” palette used good one people many kinds color vision deficiencies.also number advanced methods displaying nodes including displaying figures data visualizations place nodes using images nodes. examples book code outlining create visuals discussions Figure 6.3 Figure 6.13 .","code":"\nlibrary(ggpubr)\nggpubr::show_point_shapes()\nlibrary(RColorBrewer)\n\nset.seed(347)\ng1 <- ggraph(net, layout = \"kk\") +\n  geom_edge_link(edge_color = \"gray\", alpha = 0.7) +\n  geom_node_point(\n    aes(fill = site_info$Region),\n    shape = 21,\n    size = igraph::degree(net) / 2,\n    alpha = 0.5\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\nset.seed(347)\ng2 <- ggraph(net, layout = \"kk\") +\n  geom_edge_link(edge_color = \"blue\", alpha = 0.3) +\n  geom_node_point(\n    aes(col = site_info$Region),\n    shape = 15,\n    size = igraph::degree(net) / 2,\n    alpha = 1\n  ) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\nggarrange(g1, g2, nrow = 1)"},{"path":"Visualization.html","id":"EdgeOptions","chapter":"Section 6 Network Visualization","heading":"6.3.2.2 Edges","text":"Edges can modified terms color, line type, thickness many features just like nodes typically done using geom_edge_link call within ggraph. Let”s take look couple additional examples. case ”re going use weighted network object original Peeples2018.Rdata file show can vary edges relation edge attributes like weight.example plot line thickness transparency using edge weights associated network object. also using scale_edge_color_gradient2 specify continuous edge color scheme three anchors. details see ?scale_edge_colorAnother feature edges often important visualizations presence absence type arrows. Arrows can modified ggraph using arrow argument within geom_edge_link call. relevant options length arrow (determines size), type argument specifies open closed arrow, spacing arrow can set end_cap start_cap respectively define gap arrow point node. values can set using absolute measurements shown example . Since undirected network use argument ends = \"first\" simulated directed network arrowheads drawn first time edge appears edge list. See ?arrow details options.Another common consideration edges shape edges . far used examples edges straight lines, also possible draw arcs fan nodes multiple connections visible. general, need change option use another command geom_edge_ family commands. example, following chunk code produce network arcs rather straight lines. case argument strength controls amount bend lines.also possible show edges instead just gradient scale representing density edges using geom_edge_density call. useful large complex networks.\nwant see possible options \ngeom_edge_ commands, simply use help command one\nfunctions (.e., ?geom_edge_arc) scroll \nhelp window section labeled “See Also.”\n","code":"\nlibrary(intergraph)\nnet2 <- asIgraph(brnet_w)\n\nset.seed(436)\nggraph(net2, \"stress\") +\n  geom_edge_link(aes(width = weight, alpha = weight, col = weight)) +\n  scale_edge_color_gradient2(\n    low = \"#440154FF\",\n    mid = \"#238A8DFF\",\n    high = \"#FDE725FF\",\n    midpoint = 0.8\n  ) +\n  scale_edge_width(range = c(1, 5)) +\n  geom_node_point(size = 4, col = \"blue\") +\n  labs(edge_color = \"Edge Weight Color Scale\") +\n  theme_graph()\nset.seed(436)\nggraph(net, \"stress\") +\n  geom_edge_link(\n    arrow = arrow(\n      length = unit(2, \"mm\"),\n      ends = \"first\",\n      type = \"closed\"\n    ),\n    end_cap = circle(0, \"mm\"),\n    start_cap = circle(3, \"mm\"),\n    edge_colour = \"black\"\n  ) +\n  geom_node_point(size = 4, col = \"blue\") +\n  theme_graph()\nset.seed(436)\nggraph(net, \"kk\") +\n  geom_edge_arc(edge_colour = \"black\", strength = 0.1) +\n  geom_node_point(size = 4, col = \"blue\") +\n  theme_graph()\nset.seed(436)\nggraph(net2, \"kk\") +\n  geom_edge_density() +\n  geom_node_point(size = 4, col = \"blue\") +\n  theme_graph()"},{"path":"Visualization.html","id":"LabelOptions","chapter":"Section 6 Network Visualization","heading":"6.3.3 Labels","text":"many cases may want label either nodes, edges, features network. relatively easy ggraph geom_node_text() command. place labels specified node. use repel = TRUE argument repel names slightly node make readable. shown example Figure 6.4 also possible filter labels label certain nodes.also possible label edges adding argument directly geom_edge_ command. practice, really works small networks. next chunk code, create small network demonstrate function.","code":"\nset.seed(436)\nggraph(net2, \"fr\") +\n  geom_edge_link() +\n  geom_node_point(size = 4, col = \"blue\") +\n  geom_node_text(aes(label = vertex.names), size = 3, repel = TRUE) +\n  theme_graph()\ng <- graph(c(\"A\", \"B\",\n             \"B\", \"C\",\n             \"A\", \"C\",\n             \"A\", \"A\",\n             \"C\", \"B\",\n             \"D\", \"C\"))\n\nE(g)$weight <- c(3, 1, 6, 8, 4, 2)\n\nset.seed(4351)\nggraph(g, layout = \"stress\") +\n  geom_edge_fan(aes(label = weight),\n                angle_calc = \"along\",\n                label_dodge = unit(2, \"mm\")) +\n  geom_node_point(size = 20, col = \"lightblue\") +\n  geom_node_text(label = V(g)$name) +\n  theme_graph()"},{"path":"Visualization.html","id":"Colorblind","chapter":"Section 6 Network Visualization","heading":"6.3.4 Be Kind to the Color Blind","text":"selecting color schemes, important consider impact particular color scheme color blind readers. excellent set R scripts GitHub package called colorblindr Claus Wilke can help just . slightly modified code colorblindr package created script called colorblindr.R can download use test network. Simply run code script use cvd_grid2() function ggplot ggraph object see simulated colors.chunk code loads colorblindr.R script plots figure using RColorBrewer color Set2 original unmodified format might look readers common forms color vision issues. Download colorblindr.R script follow along.","code":"\nlibrary(colorspace)\nsource(\"scripts/colorblindr.R\")\ncvd_grid2(g1)"},{"path":"Visualization.html","id":"VizCommunities","chapter":"Section 6 Network Visualization","heading":"6.3.5 Communities and Groups","text":"Showing communities groups network visualizations can simple color coding nodes edges seen many examples . sometimes also useful highlight groups creating convex hull circle around relevant points. can done ggraph using geom_mark_hull command within ggforce package. also need package called concaveman allows set concavity hulls around points.following chunk code provides simple example using Louvain clustering algorithm.discussion Figure 6.4 provides another similar example. many complicated ways showing network groups provided examples covering figures book. example, Figure 6.18 provides example “group---box” technique using NodeXL software package. Figure 6.19 illustrates use matrices visualization tools Figure 6.20 provides links Nodetrix hybrid visualization software.","code":"\nlibrary(ggforce)\nlibrary(concaveman)\n\n# Define clusters\ngrp <- as.factor(cluster_louvain(net2)$membership)\n\nset.seed(4343)\nggraph(net2, layout = \"fr\") +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp),\n                  shape = 21,\n                  size = 5,\n                  alpha = 0.75) +\n  # Create hull around points within group and label\n  geom_mark_hull(\n    aes(\n      x,\n      y,\n      group = grp,\n      fill = grp,\n    ),\n    concavity = 4,\n    expand = ggplot2::unit(2, \"mm\"),\n    alpha = 0.25,\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_graph()"},{"path":"Visualization.html","id":"ReplicatingBookFigures","chapter":"Section 6 Network Visualization","heading":"6.4 Replicating the Book Figures","text":"section go figure Chapter 6 Brughmans Peeples (2023) detail final graph created figures created using R. figures created R describe software data used provide additional resources available. hope examples serve inspiration network visualization experiments. figures relatively simple others quite complex. presented order appear book.","code":""},{"path":"Visualization.html","id":"Figure_6_1","chapter":"Section 6 Network Visualization","heading":"Figure 6.1: Manual Layout","text":"Figure 6.1. example early hand drawn network graph (sociogram) published Moreno (1932: 101). Moreno noted nodes top bottom sociogram connections therefore represent nodes greatest importance. specific “important” points emphasized size placement.Note hand drawn version figure presented book digital example presented illustrative purposes. shows can employ user defined layouts directly supplying coordinates nodes plot. Download Moreno data follow along.","code":"\nlibrary(igraph)\nlibrary(ggraph)\n\n# Read in adjacency matrix of Moreno data and covert to network\nmoreno <-\n  as.matrix(read.csv(\"data/Moreno.csv\", header = TRUE, row.names = 1))\ng_moreno <- graph_from_adjacency_matrix(moreno)\n\n# Create xy coordinates associated with each node\nxy <- matrix(\n  c(4, 7, 1, 5, 6, 5, 2, 4, 3, 4, 5, 4, 1, 2.5, 6, 2.5, 4, 1),\n  nrow = 9,\n  ncol = 2,\n  byrow = TRUE\n)\n\n# Plot the network using layout = \"manual\" to place nodes using xy coordinates\nggraph(g_moreno,\n       layout = \"manual\",\n       x = xy[, 1],\n       y = xy[, 2]) +\n  geom_edge_link() +\n  geom_node_point(fill = \"white\",\n                  shape = 21,\n                  size = igraph::degree(g_moreno)) +\n  scale_size(range = c(2, 3)) +\n  theme_graph()"},{"path":"Visualization.html","id":"Figure_6_2","chapter":"Section 6 Network Visualization","heading":"Figure 6.2: Examples of Common Network Plot Formats","text":"Figure. 6.2. plots different visual representations network data Peeples’s (2018) data edges defined based technological similarities cooking pots node represent archaeological settlements.code creates individual figures compiles single composite figure plotting.First read data (data combined single RData file ).Fig 6.2a - simple network graph nodes placed based Fruchterman-Reingold algorithmFig 6.2b - Network graph nodes placed based real geographic locations settlements color coded based sub-regions.Fig 6.2c - graph designed show many different kinds information can combined single network plot. network graph node placement defined stress majorization algorithm (see ), nodes color coded based region, different symbols different kinds public architectural features found sites, nodes scaled based betweenness centrality scores. line weight edge used indicate relative tie-strength.Fig. 6.2d - network graph laid using Kamada-Kawai force directed algorithm nodes color coded based communities detected using Louvain community detection algorithm. community also indicated circle highlighting relevant nodes. Edges within communities shown black edges communities shown red.plot use .ggplot function convert traditional igraph plot ggraph plot illustrate can done.Finally, use ggarrange function ggpubr package combine plots single composite plot.","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(ggplotify)\nlibrary(ggraph)\nlibrary(ggpubr)\n\nload(file = \"data/Peeples2018.Rdata\")\n## contains objects\n# site_info - site locations and attributes\n# ceramic_br - raw Brainerd-Robinson similarity among sites\n# brnet - binary network with similarity values > 0.65\n#     defined as edges in statnet/network format\n# brnet_w - weighted network with edges (>0.65) given weight\n#     values based on BR similarity in statnet/network format\n##\n## create simple graph with Fruchterman - Reingold layout\nset.seed(423)\nf6_2a <- ggraph(brnet, \"fr\") +\n  geom_edge_link(edge_colour = \"grey66\") +\n  geom_node_point(aes(size = 5), col = \"red\", show.legend = FALSE) +\n  theme_graph()\nf6_2a\n## create graph with layout determined by site location and\n## nodes color coded by region\nf6_2b <- ggraph(brnet, \"manual\",\n                x = site_info$x,\n                y = site_info$y) +\n  geom_edge_link(edge_colour = \"grey66\") +\n  geom_node_point(aes(size = 2, col = site_info$Region),\n                  show.legend = FALSE) +\n  theme_graph()\nf6_2b\n# create vectors of attributes and betweenness centrality and plot\n# network with nodes color coded by region, sized by betweenness,\n# with symbols representing public architectural features, and\n# with edges weighted by BR similarity\ncol1 <- as.factor((site_info$Great.Kiva))\ncol2 <- as.factor((site_info$Region))\nbw <- sna::betweenness(brnet_w)\n\nf6_2c <- ggraph(brnet_w, \"stress\") +\n  geom_edge_link(aes(width = weight, alpha = weight),\n                 edge_colour = \"black\",\n                 show.legend = FALSE) +\n  scale_edge_width(range = c(1, 2)) +\n  geom_node_point(aes(\n    size = bw,\n    shape = col1,\n    fill = col1,\n    col = site_info$Region\n  ),\n  show.legend = FALSE) +\n  scale_fill_discrete() +\n  scale_size(range = c(4, 12)) +\n  theme_graph()\nf6_2c\n# convert network object to igraph object and calculate Louvain\n# cluster membership plot and convert to grob to combine in ggplot\ng <- asIgraph(brnet_w)\nclst <- cluster_louvain(g)\n\nf6_2d <- as.ggplot(\n  ~ plot(\n    clst,\n    g,\n    layout = layout_with_kk,\n    vertex.label = NA,\n    vertex.size = 10,\n    col = rainbow(4)[clst$membership]\n  )\n)\nf6_2d\n# Combine all plots into a single figure using ggarrange\nfigure_6_2 <- ggarrange(\n  f6_2a,\n  f6_2b,\n  f6_2c,\n  f6_2d,\n  nrow = 2,\n  ncol = 2,\n  labels = c(\"(a)\", \"(b)\", \"(c)\", \"(d)\"),\n  font.label = list(size = 22)\n)\n\nfigure_6_2"},{"path":"Visualization.html","id":"Figure_6_3","chapter":"Section 6 Network Visualization","heading":"Figure 6.3: Examples of Rare Network Plot Formats","text":"Figure 6.3. Examples less common network visuals techniques Peeples’s (2018) ceramic technological similarity data.Fig 6.3a - weighted heat plot underlying similarity matrix hierarchical clusters shown axis. plot relies packages called superheat produces plots formatted see . required input symmetric similarity matrix object.\nchunk code use .ggplot function\nggplotify package. function converts non\nggplot2 style function ggplot2 format\ncan used packages like ggpubr\ncolorblindr.\nFig. 6.3b - arcplot within group ties shown plot group ties shown .plot, read adjacency matrix ordered order want show final plot. Download file follow along. Note object grp must produced order nodes appear original adjacency matrix file.Fig. 6.3c - Network plot sites geographic locations edges bundled using edge bundling hammer routine.\nfunction requires edgebundle package \ninstalled along reticulate Python 3.8 (see Packages) uses Cibola technological similarity data.\nCheck Data Workspace Setup section \ndetails getting edge bundling package Python \nrunning.\n\naware function may take long time computer\ndepending processing power RAM.\nFig. 6.3d - Network graph nodes replaced waffle plots show relative frequencies common ceramic technological clusters.somewhat complicated plot requires couple specialized libraries additional steps along way. provide comments code help follow along. Essentially routine creates series waffle plots uses annotations replace nodes final ggraph. plot requires install development package called ggwaffle. Run line code creating figure need add package.\nnumerous projects R CRAN archive \npackages peer reviewed evaluated. many \npackages compendiums designed use R yet \nCRAN archive. Frequently found packages development \nGitHub. order use packages development, can use \ninstall_github function wrapped inside \ndevtools package (though originates \nremotes package). order install package \nGitHub, type supply “username/packagename” inside \ninstall_github call.\nLet’s now look figure code:\ninspiration example came R\nblogpost schochastics (David Schoch). post shows, \nfigures can treated ggplot2 objects can used\nplace nodes defining “annotations.” See post\ndetails.\nNow let’s look figures together.","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(ggraph)\nlibrary(ggplotify)\nlibrary(superheat)\n\nceramic_br_a <- ceramic_br\ndiag(ceramic_br_a) <- NA\n\nf6_3a <- as.ggplot(\n  ~ superheat(\n    ceramic_br_a,\n    row.dendrogram = TRUE,\n    col.dendrogram = TRUE,\n    grid.hline.col = \"white\",\n    grid.vline.col = \"white\",\n    legend = FALSE,\n    left.label.size = 0,\n    bottom.label.size = 0\n  )\n)\nf6_3a\narc_dat <- read.csv(\"data/Peeples_arcplot.csv\",\n                    header = TRUE,\n                    row.names = 1)\ng <- graph_from_adjacency_matrix(as.matrix(t(arc_dat)))\n\n# set groups for color\ngrp <- as.factor(c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n                   3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n                   1, 1, 1, 1))\n\n\n# Make the graph\nf6_3b <- ggraph(g, layout = \"linear\") +\n  geom_edge_arc(\n    edge_colour = \"black\",\n    edge_alpha = 0.2,\n    edge_width = 0.7,\n    fold = FALSE,\n    strength = 1,\n    show.legend = FALSE\n  ) +\n  geom_node_point(\n    aes(\n      size = igraph::degree(g),\n      color = grp,\n      fill = grp\n    ),\n    alpha = 0.5,\n    show.legend = FALSE\n  ) +\n  scale_size_continuous(range = c(4, 8)) +\n  theme_graph()\nf6_3b\nlibrary(edgebundle)\nload(\"data/Peeples2018.Rdata\")\n\n# Create attribute file with required data\nxy <- as.data.frame(site_info[, 1:2])\nxy <- cbind(xy, site_info$Region)\ncolnames(xy) <- c(\"x\", \"y\", \"Region\")\n\n# Run hammer bundling routine\ng <- asIgraph(brnet)\nhbundle <- edge_bundle_hammer(g, xy, bw = 5, decay = 0.3)\n\nf6_3c <-   ggplot() +\n  geom_path(data = hbundle, aes(x, y, group = group),\n            col = \"gray66\", size = 0.5) +\n  geom_point(data = xy, aes(x, y, col = Region),\n             size = 5, alpha = 0.75, show.legend = FALSE) +\n  theme_void()\nf6_3c\ndevtools::install_github(\"liamgilbey/ggwaffle\")\n# Initialize libraries\n\nlibrary(ggwaffle)\nlibrary(tidyverse)\n\n# Create igraph object from data imported above\ncibola_adj <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = TRUE,\n           row.names = 1)\ng <- graph_from_adjacency_matrix(as.matrix(cibola_adj),\n                                 mode = \"undirected\")\n\n# Import raw ceramic data and convert to proportions\nceramic_clust <- read.csv(file = \"data/Cibola_clust.csv\",\n                          header = TRUE,\n                          row.names = 1)\nceramic_p <- prop.table(as.matrix(ceramic_clust), margin = 1)\n\n# Assign vertex attributes to the network object g which represent\n# columns in the ceramic.p table\nV(g)$c1 <- ceramic_p[, 1]\nV(g)$c2 <- ceramic_p[, 2]\nV(g)$c3 <- ceramic_p[, 3]\nV(g)$c4 <- ceramic_p[, 4]\nV(g)$c5 <- ceramic_p[, 5]\nV(g)$c6 <- ceramic_p[, 6]\nV(g)$c7 <- ceramic_p[, 7]\nV(g)$c8 <- ceramic_p[, 8]\nV(g)$c9 <- ceramic_p[, 9]\nV(g)$c10 <- ceramic_p[, 10]\n\n# Precompute the layout and assign coordinates as x and y in network g\nset.seed(345434534)\nxy <- layout_with_fr(g)\nV(g)$x <- xy[, 1]\nV(g)$y <- xy[, 2]\n\n# Create a data frame that contains the 4 most common\n# categories in the ceramic table, the node id, and the proportion\n# of that ceramic category at that node\nnodes_wide <- igraph::as_data_frame(g, \"vertices\")\nnodes_long <- nodes_wide %>%\n  dplyr::select(c1:c4) %>%\n  mutate(id = seq_len(nrow(nodes_wide))) %>%\n  gather(\"attr\", \"value\", c1:c4)\nnodes_out <- NULL\nfor (j in seq_len(nrow(nodes_long))) {\n  temp <- do.call(\"rbind\", replicate(round(nodes_long[j, ]$value * 50, 0),\n                                     nodes_long[j, ], simplify = FALSE))\n  nodes_out <- rbind(nodes_out, temp)\n}\n\n# Create a list object for the call to each bar chart by node\nbar_list <- lapply(1:vcount(g), function(i) {\n  gt_plot <- ggplotGrob(\n    ggplot(waffle_iron(nodes_out[nodes_out$id == i, ],\n                       aes_d(group = attr))) +\n      geom_waffle(aes(x, y, fill = group), size = 10) +\n      coord_equal() +\n      labs(x = NULL, y = NULL) +\n      theme(\n        legend.position = \"none\",\n        panel.background = element_rect(fill = \"white\", colour = NA),\n        line = element_blank(),\n        text = element_blank()\n      )\n  )\n  panel_coords <- gt_plot$layout[gt_plot$layout$name == \"panel\", ]\n  gt_plot[panel_coords$t:panel_coords$b, panel_coords$l:panel_coords$r]\n})\n\n# Convert the results above into custom annotation\nannot_list <- lapply(1:vcount(g), function(i) {\n  xmin <- nodes_wide$x[i] - .25\n  xmax <- nodes_wide$x[i] + .25\n  ymin <- nodes_wide$y[i] - .25\n  ymax <- nodes_wide$y[i] + .25\n  annotation_custom(\n    bar_list[[i]],\n    xmin = xmin,\n    xmax = xmax,\n    ymin = ymin,\n    ymax = ymax\n  )\n})\n\n# create basic network\np <- ggraph(g, \"manual\", x = V(g)$x, y = V(g)$y) +\n  geom_edge_link0() +\n  theme_graph() +\n  coord_fixed()\n\n# put everything together by combining with the annotation (bar plots + network)\nf6_3d <- Reduce(\"+\", annot_list, p)\nf6_3d"},{"path":"Visualization.html","id":"Figure_6_4","chapter":"Section 6 Network Visualization","heading":"Figure 6.4: Simple Network with Clusters","text":"Figure 6.4. network among Clovis era sites Western U.S. connections based shared lithic raw material sources. Nodes scaled based betweenness centrality top seven sites labelled. Color-coded clusters defined using Louvain algorithm.\nexample shows define indicate groups label points\nbased values. Note use ifelse call \ngeom_node_text portion plot. See information \nifelse statements work.\n","code":"\nlibrary(ggforce)\nlibrary(ggraph)\nlibrary(statnet)\nlibrary(igraph)\n\nclovis <- read.csv(\"data/Clovis.csv\", header = TRUE, row.names = 1)\ncolnames(clovis) <- row.names(clovis)\ngraph <- graph_from_adjacency_matrix(as.matrix(clovis),\n                                     mode = \"undirected\",\n                                     diag = FALSE)\n\nbw <- igraph::betweenness(graph)\n\ngrp <- as.factor(cluster_louvain(graph)$membership)\n\nset.seed(43643548)\nggraph(graph, layout = \"fr\") +\n  geom_edge_link(edge_width = 1, color = \"gray\") +\n  geom_node_point(aes(fill = grp, size = bw, color = grp),\n                  shape = 21,\n                  alpha = 0.75) +\n  scale_size(range = c(2, 20)) +\n  geom_mark_hull(\n    aes(\n      x,\n      y,\n      group = grp,\n      fill = grp,\n      color = NA\n    ),\n    concavity = 4,\n    expand = unit(2, \"mm\"),\n    alpha = 0.25,\n    label.fontsize = 12\n  ) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n  # If else statement only labels points that meet the condition\n  geom_node_text(aes(label = ifelse(bw > 40,\n                                    as.character(name),\n                                    NA_character_)),\n                 size = 4) +\n  theme_graph() +\n  theme(legend.position = \"none\")"},{"path":"Visualization.html","id":"Figure_6_5","chapter":"Section 6 Network Visualization","heading":"Figure 6.5: Interactive Layout","text":"Figure 6.5. example network graph two simple user defined layouts created interactively.Figure 6.5 produced NetDraw creating simple network taking screen shots two configurations nodes. options creating similar figures R. simplest use igraph network object tkplot function. function brings window lets drag move nodes (without initial algorithmic layout) ”re done can assign new positions variable use plotting. Use data follow along.\nNote running package browser via binder,\nfunction work permission open\ntkplot virtual server. follow along plotting \nfigure can use pre-determined locations reading \nfile load(file=“data/Coords.Rdata”)\nbring window like example click “Close” automatically create variables node location information plotting.","code":"\nlibrary(igraph)\nlibrary(intergraph)\n\nload(\"data/Peeples2018.Rdata\")\n\ncibola_i <- asIgraph(brnet)\n\nlocs <- tkplot(cibola_i)\ncoords <- tkplot.getcoords(locs)\nplot(cibola_i, layout = coords)"},{"path":"Visualization.html","id":"Figure_6_6","chapter":"Section 6 Network Visualization","heading":"Figure 6.6: Absolute Geographic Layout","text":"Fig. 6.6. Map major Roman roads major settlements Iberian Peninsula, () roads mapped along actual geographic paths (b) roads shown simple line segments nodes.figure appears book originally created using GIS software possible prepare quite similar figure R using tools outlined . reproduce results presented need download node information file road edge list. created script called map_net.R produce similar maps supplied network object file node locations lat/long coordinates. information R works geographic data see spatial networks section document.","code":"\nlibrary(igraph)\nlibrary(ggmap)\nlibrary(sf)\n\n# Load my_map background map\nload(\"data/Figure6_6.Rdata\")\n\nedges1 <- read.csv(\"data/Hispania_roads.csv\", header = TRUE)\nedges1 <- edges1[which(edges1$Weight > 25), ]\nnodes <- read.csv(\"data/Hispania_nodes.csv\", header = TRUE)\nnodes <- nodes[which(nodes$Id %in% c(edges1$Source, edges1$Target)), ]\n\nroad_net <-\n  graph_from_edgelist(as.matrix(edges1[, 1:2]), directed = FALSE)\n\n# Convert attribute location data to sf coordinates\nlocations_sf <-\n  st_as_sf(nodes, coords = c(\"long\", \"lat\"), crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(locations_sf)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n# Extract edge list from network object\nedgelist <- get.edgelist(road_net)\n\n# Create data frame of beginning and ending points of edges\nedges <- as.data.frame(matrix(NA, nrow(edgelist), 4))\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\nfor (i in seq_len(nrow(edgelist))) {\n  edges[i, ] <- c(nodes[which(nodes$Id == edgelist[i, 1]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 1]), 2],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 2])\n}\n\n\nggmap(my_map) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.8,\n    col = \"black\",\n    fill = \"white\",\n    shape = 21,\n    size = 1.5,\n    show.legend = FALSE\n  ) +\n  theme_void()"},{"path":"Visualization.html","id":"Figure_6_7","chapter":"Section 6 Network Visualization","heading":"Figure 6.7: Distorted Geographic Layout","text":"Figure 6.7. ceramic similarity network San Pedro River Valley Arizona shows challenges creating geographic network layouts. () Shows sites original locations whereas (b) shifts locations improve visibility network structure. Note distorted geographic layout retains basic relationships among nodes altering locations slightly.Unfortunately first map contains real site locations share data . second map can still reproduced given nothing code . difference required produce Figure 6.7a replace coord site coordinates actual site locations. coord object used created taking original site locations applying jitter function, jitters x y coordinates specified amount.","code":"\nlibrary(igraph)\nlibrary(sf)\nlibrary(ggmap)\nlibrary(ggrepel)\nlibrary(ggpubr)\n\nload(\"data/Figure6_7.Rdata\")\n# g.net - igraph network object of San Pedro sites based on\n# ceramic similarity\n# base3 - basemap background terrain\n\n# Define coordinates of \"jittered\" points\n# These points were originally created using the \"jitter\" function\n# until a reasonable set of points were found.\ncoord <- c(-110.7985, 32.97888,\n-110.7472, 32.89950,\n-110.6965, 32.83496,\n-110.6899, 32.91499,\n-110.5508, 32.72260,\n-110.4752, 32.60533,\n-110.3367, 32.33341,\n-110.5930, 32.43487,\n-110.8160, 32.86185,\n-110.6650, 32.64882,\n-110.4558, 32.56866,\n-110.6879, 32.60055,\n-110.7428, 32.93124,\n-110.4173, 32.34401,\n-110.7000, 32.73344)\n\nattr <- c(\"Swingle's Sample\", \"Ash Terrace\", \"Lost Mound\",\n          \"Dudleyville Mound\", \"Leaverton\", \"High Mesa\",\n          \"Elliott Site\", \"Bayless Ruin\", \"Flieger\",\n          \"Big Bell\", \"111 Ranch\", \"Twin Hawks\", \"Artifact Hill\",\n          \"Jose Solas Ruin\", \"Wright\")\n\n\n# Convert coordinates to data frame\nzz <- as.data.frame(matrix(coord, nrow = 15, byrow = TRUE))\ncolnames(zz) <- c(\"x\", \"y\")\n\n\n# Extract edge list from network object\nedgelist <- get.edgelist(g.net)\n\n# Create data frame of beginning and ending points of edges\nedges2 <- data.frame(zz[edgelist[, 1], ], zz[edgelist[, 2], ])\ncolnames(edges2) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Plot jittered coordinates on map\nfigure_6_7 <- ggmap(base3, darken = 0.35) +\n  geom_segment(\n    data = edges2,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"white\",\n    size = 1\n  ) +\n  geom_point(\n    data = zz,\n    aes(x, y),\n    alpha = 0.8,\n    col = \"red\",\n    size = 5,\n    show.legend = FALSE\n  ) +\n  geom_text_repel(aes(x = x, y = y, label = attr), data = zz, size = 3) +\n  theme_void()\n\nfigure_6_7"},{"path":"Visualization.html","id":"Figure_6_8","chapter":"Section 6 Network Visualization","heading":"Figure 6.8: Graph Layout Algorithms","text":"Fig. 6.8. Several different graph layouts using Bronze Age Aegean geographic network (Evans et al. 2011). graph, nodes scaled based betweenness centrality color-coded based clusters defined using modularity maximisation.code thing change plot layout argument ggraph. See CRAN project page ggraph information available layouts. plot clusters color make easier track differences layout options. Use data dowload background map Aegean area.","code":"\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(ggpubr)\nlibrary(igraphdata)\nlibrary(graphlayouts)\nlibrary(sf)\nlibrary(ggmap)\n\n# Load igraph Aegean_net data\n\naegean <- read.csv(\"data/aegean.csv\", row.names = 1, header = T)\naegean_dist <- aegean\naegean_dist[aegean_dist > 124] <- 0\naegean_dist[aegean_dist > 0] <- 1\naegean_net <- graph_from_adjacency_matrix(as.matrix(aegean_dist))\nload(\"data/aegean_map.Rdata\")\n\n# Define cluster membership and betweenness centrality for plotting\ngrp <- as.factor(cluster_optimal(aegean_net)$membership)\nbw <- as.numeric(igraph::betweenness(aegean_net))\n\n# Create geographic network and plot\nnodes <- read.csv(\"data/aegean_locs.csv\")\n\n# Convert attribute location data to sf coordinates\nlocations_sf <-\n  st_as_sf(nodes,\n           coords = c(\"Longitude\", \"Latitude\"),\n           crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(locations_sf)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n\n# Extract edge list from network object for road_net\nedgelist1 <- get.edgelist(aegean_net)\n\n# Create data frame of beginning and ending points of edges\nedges1 <- as.data.frame(matrix(NA, nrow(edgelist1), 4))\ncolnames(edges1) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\nfor (i in seq_len(nrow(edgelist1))) {\n  edges1[i, ] <-\n    c(nodes[which(nodes$Name == edgelist1[i, 1]), ]$Longitude,\n      nodes[which(nodes$Name == edgelist1[i, 1]), ]$Latitude,\n      nodes[which(nodes$Name == edgelist1[i, 2]), ]$Longitude,\n      nodes[which(nodes$Name == edgelist1[i, 2]), ]$Latitude)\n}\n\ngeo_net <- ggmap(my_map) +\n  geom_segment(\n    data = edges1,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y, size = bw, fill = grp),\n    alpha = 0.8,\n    shape = 21,\n    show.legend = FALSE\n  ) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_graph() +\n  ggtitle(\"Geographic\") +\n  theme(plot.title = element_text(size = rel(1)))\n\n# Multidimensional Scaling Layout with color by cluster and node\n# size by betweenness\nset.seed(435353)\ng_mds <- ggraph(aegean_net, layout = \"mds\") +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp, size = bw),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1))) +\n  ggtitle(\"Multi-Dimensional Scaling\") +\n  theme(legend.position = \"none\")\n\n# Fruchterman-Reingold Layout with color by cluster and node size\n# by betweenness\nset.seed(435353)\ng_fr <- ggraph(aegean_net, layout = \"fr\") +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp, size = bw),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1))) +\n  ggtitle(\"Fruchterman-Reingold\") +\n  theme(legend.position = \"none\")\n\n# Kamada-Kawai Layout with color by cluster and node size by betweenness\nset.seed(435353)\ng_kk <- ggraph(aegean_net, layout = \"kk\") +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp, size = bw),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1))) +\n  ggtitle(\"Kamada-Kawai\") +\n  theme(legend.position = \"none\")\n\n# Radial Centrality Layout with color by cluster and node size by\n# betweenness\nset.seed(435353)\ng_cent <- ggraph(aegean_net,\n                 layout = \"centrality\",\n                 centrality = igraph::betweenness(aegean_net)) +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp, size = bw),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1))) +\n  ggtitle(\"Radial Centrality\") +\n  theme(legend.position = \"none\")\n\n# Spectral Layout with color by cluster and node size by betweenness\nu1 <- layout_with_eigen(aegean_net)\ng_spec <- ggraph(aegean_net,\n                 layout = \"manual\",\n                 x = u1[, 1],\n                 y = u1[, 2]) +\n  geom_edge_link0(width = 0.2) +\n  geom_node_point(aes(fill = grp, size = bw),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(4, 12)) +\n  scale_color_brewer(palette = \"Set2\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3),\n                                     rgb(0, 0, 0, 1))) +\n\n  theme_graph() +\n  theme(plot.title = element_text(size = rel(1))) +\n  ggtitle(\"Spectral\") +\n  theme(legend.position = \"none\")\n\n\nfigure_6_8 <-\n  ggarrange(geo_net,\n            g_mds,\n            g_fr,\n            g_kk,\n            g_cent,\n            g_spec,\n            ncol = 2,\n            nrow = 3)\nfigure_6_8"},{"path":"Visualization.html","id":"Figure_6_9","chapter":"Section 6 Network Visualization","heading":"Figure 6.9: Heirarchical Graph Layouts","text":"Fig. 6.9. Examples visualisations based hierarchical graph data. () Graph nodes color-coded hierarchical level. (b) Bubble plot nodes scaled proportional sub-group size. (c) Dendrogram hierarchical cluster data. (d) Radial graph edges bundled based similarity relations. Edges colour-coded red origin purple destination help visualise direction.graphs based hierarchical graph created assigning nodes leaves hierarchical cluster analysis performed Cibola ceramic technological cluster data. data 6.9d randomly generated following example R Graph Gallery. Use data follow along.","code":"\n# initialize libraries\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(ape)\nlibrary(RColorBrewer)\nlibrary(ggpubr)\n\nload(file = \"data/Figure6_9.Rdata\")\n\nset.seed(4353543)\nh1 <- ggraph(h_graph, \"circlepack\") +\n  geom_edge_link() +\n  geom_node_point(aes(colour = depth, size = (max(depth) - depth) / 2),\n                  show.legend = FALSE) +\n  scale_color_viridis() +\n  theme_graph() +\n  coord_fixed()\n\nset.seed(643346463)\nh2 <- ggraph(h_graph, \"circlepack\") +\n  geom_node_circle(aes(fill = depth),\n                   size = 0.25,\n                   n = 50,\n                   show.legend = FALSE) +\n  scale_fill_viridis() +\n  theme_graph() +\n  coord_fixed()\n\nh3 <- ggraph(h_graph, \"dendrogram\") +\n  geom_node_point(aes(filter = leaf),\n                  color = \"blue\",\n                  alpha = 0.7,\n                  size = 3) +\n  theme_graph() +\n  geom_edge_link()\n\nh4 <-\n  ggraph(sub_grp_graph, layout = \"dendrogram\", circular = TRUE) +\n  geom_conn_bundle(\n    data = get_con(from = from, to = to),\n    alpha = 0.2,\n    width = 0.9,\n    tension = 0.9,\n    aes(colour = ..index..)\n  ) +\n  scale_edge_colour_distiller(palette = \"RdPu\") +\n  geom_node_point(aes(\n    filter = leaf,\n    x = x * 1.05,\n    y = y * 1.05,\n    colour = group),\n    size = 3) +\n  scale_colour_manual(values = rep(brewer.pal(9, \"Paired\"), 30)) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\nfigure_6_9 <- ggarrange(\n  h1,\n  h2,\n  h3,\n  h4,\n  ncol = 2,\n  nrow = 2,\n  labels = c(\"(a)\", \"(b)\", \"(c)\", \"(d)\")\n)\nfigure_6_9"},{"path":"Visualization.html","id":"Figure_6_10","chapter":"Section 6 Network Visualization","heading":"Figure 6.10: Be kind to the color blind","text":"Fig. 6.10. Examples simple network graph color-coded clusters. top left example shows unmodified figure remaining examples simulate figure might look like people various kinds colour vision deficiencies.function calls script modified colorblindr package Claus Wilke available . function cv2_grid take ggplot object outputs 2 x 2 grid original figure examples figure might look like people three common forms color vision deficiency. Use data script follow along.","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(ggraph)\nlibrary(RColorBrewer)\nlibrary(colorspace)\nsource(\"scripts/colorblindr.R\")\n\nload(\"data/Peeples2018.Rdata\")\n\n# Create igraph object for plots below\nnet <- asIgraph(brnet)\n\nset.seed(347)\ng1 <- ggraph(net, layout = \"kk\") +\n  geom_edge_link(edge_color = \"gray\", alpha = 0.7) +\n  geom_node_point(\n    aes(fill = site_info$Region),\n    shape = 21,\n    size = igraph::degree(net) / 2,\n    alpha = 0.5\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\ncvd_grid2(g1)"},{"path":"Visualization.html","id":"Figure_6_11","chapter":"Section 6 Network Visualization","heading":"Figure 6.11: Node Symbol and Color Schemes","text":"Fig. 6.11. Examples different node color symbol schemes. Note adding color size eases identification particular values, particular closely spaced points. Using transparency can similarly aid showing multiple overlapping nodes.version appears book compiled labeled Adobe Illustrator using output created .","code":"\nlibrary(scales)\n\nplot(\n  x = 1:5,\n  y = rep(2, 5),\n  pch = 16,\n  cex = seq(5:10),\n  col = \"blue\",\n  ylim = c(0, 4),\n  bty = \"n\",\n  xaxt = \"n\",\n  yaxt = \"n\",\n  xlab = \"\",\n  ylab = \"\"\n)\npoints(\n  x = 1:5,\n  y = rep(1.5, 5),\n  pch = 21,\n  cex = seq(5:10),\n  bg = heat.colors(5, rev = TRUE)\n)\npoints(\n  x = 1:5,\n  y = rep(1, 5),\n  pch = c(1, 2, 3, 4, 5),\n  cex = seq(5:10),\n  bg = \"skyblue\",\n  col = \"blue\",\n  lwd = 2\n)\nset.seed(34456)\nx <- rnorm(15, 1, 0.5)\ny <- rnorm(15, 1, 0.5)\nxy <- cbind(x, y)\nxy2 <- cbind(x + 5, y)\nxy3 <- cbind(x + 10, y)\nxy4 <- cbind(x + 15, y)\nxy5 <- cbind(x + 20, y)\n\nsize <- sample(c(5, 6, 7, 8, 9), size = 15, replace = TRUE)\nsize <- size - 4\n\nh_col <- heat.colors(5, rev = TRUE)\n\nplot(\n  xy[order(size, decreasing = TRUE), ],\n  pch = 16,\n  col = \"blue\",\n  cex = size[order(size, decreasing = TRUE)],\n  xlim = c(0, 22),\n  ylim = c(-1, 3),\n  bty = \"n\",\n  xaxt = \"n\",\n  yaxt = \"n\",\n  xlab = \"\",\n  ylab = \"\"\n)\npoints(xy2[order(size, decreasing = TRUE), ],\n       pch = 21,\n       bg = h_col[size[order(size, decreasing = TRUE)]],\n       cex = size[order(size, decreasing = TRUE)])\npoints(xy3[order(size, decreasing = TRUE), ],\n       pch = size[order(size, decreasing = TRUE)],\n       col = \"blue\",\n       cex = size[order(size, decreasing = TRUE)])\npoints(\n  xy4[order(size, decreasing = TRUE), ],\n  pch = 21,\n  col = \"gray66\",\n  bg = alpha(\"blue\", 0.7),\n  cex = size[order(size, decreasing = TRUE)]\n)\npoints(xy5[order(size, decreasing = TRUE), ],\n       pch = 21,\n       bg = alpha(h_col[size[order(size, decreasing = TRUE)]], 0.7),\n       cex = size[order(size, decreasing = TRUE)])"},{"path":"Visualization.html","id":"Figure_6_12","chapter":"Section 6 Network Visualization","heading":"Figure 6.12: Image for Node","text":"Fig. 6.12. Network graph showing similarity among carved faces Banés, Holguín province, Cuba. Nodes depicted objects question edges represent shared attributes numbers indicating number shared attributes pair faces.Figure 6.12 used permission Angus Mol original produced 2014 book.","code":""},{"path":"Visualization.html","id":"Figure_6_13","chapter":"Section 6 Network Visualization","heading":"Figure 6.13: Images for Nodes","text":"Fig. 6.13. Two-mode network ceramics sites San Pedro Valley ceramic ware categories represented graphic example type.version Figure 6.13 Brughmans Peeples (2023) book originally created NetDraw modified add node pictures Adobe Photoshop. approach preferred produced higher resolution consistent images graphics produce directly R particular feature. , however, possible use images place nodes R networks example illustrates.found practice feature R works best simple icons. using high resolution images lots color detail images works better create initial image format something like R NetDraw modify network graphical editing software fact.place example book, demonstrate can use image files R create nodes pictures. can download data follow along. .RData file also includes images used R format code used read .png images shown commented .want use images one mode network can follow sample using data. Note line V(Cibola_i)$raster can either assign single image image node network.","code":"\nlibrary(png)\nlibrary(igraph)\n\nload(\"data/Figure6_13.Rdata\")\n# two_mode_net - igraph two mode network object\n\n# Set Vector property to images by mode\n# Note that if you want to set a different image\n# for each node you can simply create a long list\n# containing image names for node type 1 followed\n# by image names for node type 2.\nV(two_mode_net)$raster <- list(img.1, img.2)[V(two_mode_net)$type + 1]\n\nset.seed(34673)\nplot(\n  two_mode_net,\n  vertex.shape = \"raster\",\n  vertex.label = NA,\n  vertex.size = 16,\n  vertex.size2 = 16,\n  edge.color = \"gray\"\n)\nlibrary(png)\nlibrary(igraph)\n\ncibola <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = TRUE,\n           row.names = 1)\n\n# Create network in igraph format\ncibola_i <- igraph::graph_from_adjacency_matrix(as.matrix(cibola),\n                                                mode = \"undirected\")\n# Set Vector property to images using a list with a length\n# determined by the number of nodes in the network.\n# Here we divide the northern and southern portions of the\n# study area.\nV(cibola_i)$raster <- list(img.2, img.1, img.2, img.2,\n                           img.1, img.2, img.2, img.1,\n                           img.1, img.1, img.2, img.2,\n                           img.2, img.1, img.1, img.2,\n                           img.1, img.1, img.1, img.1,\n                           img.1, img.2, img.1, img.1,\n                           img.2, img.1, img.2, img.2,\n                           img.2, img.2, img.1)\n\nset.seed(34673)\nplot(\n  cibola_i,\n  vertex.shape = \"raster\",\n  vertex.label = NA,\n  vertex.size = 16,\n  vertex.size2 = 16,\n  edge.color = \"gray\"\n)"},{"path":"Visualization.html","id":"Figure_6_14","chapter":"Section 6 Network Visualization","heading":"Figure 6.14: Edge Thickness and Color","text":"Fig. 6.14. random weighted graph edge line thickness color used indicate weight 5 categories.can download data follow along.","code":"\nlibrary(igraph)\nlibrary(ggraph)\n\nload(\"data/Figure6_14.Rdata\")\n\nedge_cols <- colorRampPalette(c(\"gray\", \"darkblue\"))(5)\n\nset.seed(43644)\nggraph(g_net, layout = \"fr\") +\n  geom_edge_link0(aes(width = E(g_net)$weight),\n                  edge_colour = edge_cols[E(g_net)$weight]) +\n  geom_node_point(shape = 21,\n                  size = igraph::degree(g_net) + 3,\n                  fill = \"red\") +\n  theme_graph() +\n  theme(legend.title = element_blank())"},{"path":"Visualization.html","id":"Figure_6_15","chapter":"Section 6 Network Visualization","heading":"Figure 6.15: Edge Direction","text":"Fig. 6.15. Two methods displaying directed ties using arrows (left) arcs (right). simple networks represent relationships shown adjacency matrix center.See tutorial edges details using arrows ggraph. use grid.table function gridExtra package plot tabular data figure.","code":"\nlibrary(igraph)\nlibrary(grid)\nlibrary(gridExtra)\n\ng <- graph(c(\"A\", \"B\",\n              \"B\", \"C\",\n              \"A\", \"C\",\n              \"A\", \"A\",\n              \"C\", \"B\",\n              \"D\", \"C\"))\n\nlayout(matrix(c(1, 1, 2, 3, 3), 1, 5, byrow = TRUE))\n\nset.seed(4355467)\nplot(\n  g,\n  edge.arrow.size = 1,\n  vertex.color = \"black\",\n  vertex.size = 50,\n  vertex.frame.color = \"gray\",\n  vertex.label.color = \"white\",\n  edge.width = 2,\n  vertex.label.cex = 2.75,\n  vertex.label.dist = 0,\n  vertex.label.family = \"Helvetica\"\n)\n\nplot.new()\nadj1 <- as.data.frame(as.matrix(as_adjacency_matrix(g)))\ntt2 <- ttheme_minimal(base_size = 25)\ngrid.table(adj1, theme = tt2)\n\nplot(\n  g,\n  edge.arrow.size = 1.25,\n  vertex.color = \"black\",\n  vertex.size = 50,\n  vertex.frame.color = \"gray\",\n  vertex.label.color = \"white\",\n  edge.width = 2,\n  edge.curved = 0.3,\n  vertex.label.cex = 2.75,\n  vertex.label.dist = 0,\n  vertex.label.family = \"Helvetica\"\n)"},{"path":"Visualization.html","id":"Figure_6_16","chapter":"Section 6 Network Visualization","heading":"Figure 6.16: Edge Binarization","text":"Fig. 6.16. networks show data based similarity scores among sites U.S. Southwest (ca. AD 1350–1400) different cutoff binarization.following chunk code uses ceramic similarity data SWSN database defines three different cutoff thresholds defining edges. Note difference thresh argument event2dichot function.","code":"\nlibrary(igraph)\nlibrary(statnet)\nlibrary(intergraph)\nlibrary(ggraph)\nlibrary(ggpubr)\n\nload(\"data/Figure6_16.Rdata\")\n# Contains similarity matrix AD1350sim\n\nad1350sim_cut0_5 <- asIgraph(network(\n  event2dichot(ad1350sim,\n               method = \"absolute\",\n               thresh = 0.25),\n  directed = FALSE\n))\nad1350sim_cut0_75 <- asIgraph(network(\n  event2dichot(ad1350sim,\n               method = \"absolute\",\n               thresh = 0.5),\n  directed = FALSE\n))\nad1350sim_cut0_9 <- asIgraph(network(\n  event2dichot(ad1350sim,\n               method = \"absolute\",\n               thresh = 0.75),\n  directed = FALSE\n))\n\nset.seed(4637)\ng0_50 <- ggraph(ad1350sim_cut0_5, layout = \"fr\") +\n  geom_edge_link0(edge_colour = \"black\") +\n  geom_node_point(shape = 21, fill = \"gray\") +\n  ggtitle(\"0.25\") +\n  theme_graph()\n\nset.seed(574578)\ng0_75 <- ggraph(ad1350sim_cut0_75, layout = \"fr\") +\n  geom_edge_link0(edge_colour = \"black\") +\n  geom_node_point(shape = 21, fill = \"gray\") +\n  ggtitle(\"0.50\") +\n  theme_graph()\n\nset.seed(7343)\ng0_90 <- ggraph(ad1350sim_cut0_9, layout = \"fr\") +\n  geom_edge_link0(edge_colour = \"black\") +\n  geom_node_point(shape = 21, fill = \"gray\") +\n  ggtitle(\"0.75\") +\n  theme_graph()\n\nggarrange(g0_50, g0_75, g0_90, nrow = 1, ncol = 3)"},{"path":"Visualization.html","id":"Figure_6_17","chapter":"Section 6 Network Visualization","heading":"Figure 6.17: Edge Bundling","text":"Fig. 6.17. Network map ceramic similarity U.S. Southwest/Mexican Northwest ca. AD 1350–1400 based hammer bundling algorithm. Note figure look somewhat different one book locations sites jittered data security\nfunction relies edgebundle package \ncombine sets nodes similar relations single paths. \npackage also requires install reticulate\npackage connects R Python 3.7 must also Python\ninstalled computer datashader Python\nlibraries.\n\nNote require 1.4 GB disk space several\nminutes make sure adequate space time \nbeginning.\ninstall instance Python required libraries can use following call:Use data follow along.","code":"\nedgebundle::install_bundle_py(method = \"auto\", conda = \"auto\")\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(edgebundle)\nlibrary(ggmap)\nlibrary(sf)\n\nload(\"data/Figure6_17.Rdata\")\n# attr.dat - site attribute data\n# g.net - igraph network object\nload(\"data/map.RData\")\n# map3 - state outlines\n# base2 - terrain basemap in black and white\n\nlocations_sf <- st_as_sf(attr.dat, coords = c(\"V3\", \"V4\"),\n                         crs = 26912)\nz <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(z)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\nhbundle <- edge_bundle_hammer(g.net, xy, bw = 0.9, decay = 0.2)\n\nggmap(base2, darken = 0.15) +\n  geom_polygon(\n    data = map3,\n    aes(x, y,\n        group = Group.1),\n    col = \"black\",\n    size = 0.5,\n    fill = NA\n  ) +\n  geom_path(\n    data = hbundle,\n    aes(x, y, group = group),\n    color = \"white\",\n    show.legend = FALSE\n  ) +\n  geom_path(\n    data = hbundle,\n    aes(x, y, group = group),\n    color = \"darkorchid4\",\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.4,\n    size = 2.5,\n    show.legend = FALSE\n  ) +\n  theme_graph()"},{"path":"Visualization.html","id":"Figure_6_18","chapter":"Section 6 Network Visualization","heading":"Figure 6.18: Group-in-a-box","text":"Fig. 6.18. Example group---box custom graph layout created NodeXL based ceramic similarity data U.S. Southwest/Mexican Northwest ca. AD 1350-1400.group---box network format , far aware, currently implemented NodeXL platform. software package add-Microsoft Excel allows creation analysis network graphs using wide variety useful visualization tools. produce “Group---box” layout simply need paste set edge list values NodeXL Excel Template, define groups (based algorithm vertex attribute), sure select “Layout graph’s groups box” layout options.details use NodeXL see extensive documentation online. commercial versions software available group---box example shown can produced free version.download Excel workbook set example provided book click . open Excel, ask can install necessary extensions. Say yes continue replicate results book.","code":""},{"path":"Visualization.html","id":"Figure_6_19","chapter":"Section 6 Network Visualization","heading":"Figure 6.19: Weighted Adjacency Matrix","text":"Fig. 6.19. Dual display network graph associated weighted adjacency matrix based Peeples (2018) ceramic technology data.plot uses sub-set Cibola technological similarity network data produce typical node-link diagram associated weighted adjacency matrix. Use data follow along.","code":"\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(ggpubr)\n\nload(\"data/Figure6_19.Rdata\")\n# graph6.18 - graph object in igraph format\n# node_list - data frame with node details\n# edge_list - edge_list which contains information on groups\n# and edge weight\n\nset.seed(343645)\ncoords <- layout_with_fr(graph6.18)\ng1 <- ggraph(graph6.18, \"manual\",\n             x = coords[, 1],\n             y = coords[, 2]) +\n  geom_edge_link(aes(),\n                 color = \"gray75\",\n                 alpha = 0.5,\n                 show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(graph6.18)$comm), size = 5),\n                  show.legend = FALSE) +\n  scale_color_manual(values = c(\"#8da0cb\", \"#66c2a5\", \"#fc8d62\"),\n                     guide = FALSE) +\n  theme_graph()\n\n# Set order of nodes to order in which they appear in the y axis in\n# the network graph above\nname_order <- node_list[order(coords[, 2]), ]$name\n\n# Adjust the \"to\" and \"from\" factor levels so they are equal\n# to this complete list of node names\nplot_data <- edge_list %>% mutate(to = factor(to, levels = name_order),\n                                  from = factor(from, levels = rev(name_order)))\n\n# Now run the ggplot code again\n# Create the adjacency matrix plot\ng2 <- ggplot(plot_data, aes(\n  x = from,\n  y = to,\n  fill = group,\n  alpha = (weight * 1.5)\n)) +\n  geom_tile() +\n  theme_bw() +\n  scale_x_discrete(drop = FALSE) +\n  scale_y_discrete(drop = FALSE) +\n  theme(\n    axis.text.x = element_text(\n      angle = 270,\n      hjust = 0,\n      size = rel(0.5)\n    ),\n    axis.text.y = element_text(size = rel(0.5)),\n    aspect.ratio = 1,\n    legend.position = \"none\"\n  ) +\n  xlab(\"\") +\n  ylab(\"\") +\n  scale_fill_manual(values = c(\"#8da0cb\", \"#66c2a5\", \"#fc8d62\", \"black\"),\n                    guide = FALSE)\n\n# Combine into a single figure\nfigure6_19 <- ggarrange(g1, g2, nrow = 1)\n\nfigure6_19"},{"path":"Visualization.html","id":"Figure_6_20","chapter":"Section 6 Network Visualization","heading":"Figure 6.20: Nodetrix Diagram","text":"Fig. 6.20. Nodetrix visualisation Peeples (2018) ceramic technological data showing one dense cluster adjacency matrix remainder graph node-link diagram.Nodetrix interactive visualization created using Javascript implementation available GitHub user jdfekete, Jean-Daniel Fekete one original authors method (Henry et al. 2007). see live demo Nodetrix Application use Cibola technological similarity data click .details running Javascript program described GitHub page beyond scope tutorial. illustrate , however, can export R *.json format required program using d3r rjson packages. code expects igraph network object.\nNote Nodetrix.js application expects node names/designations\nspaces node attribute called “name” sure check\nrun code .\n","code":"\nlibrary(d3r)\nlibrary(rjson)\n\n# net <- igraph network object\n\ndata_json <- d3_igraph(net)\n\n\ndj <- jsonlite::fromJSON(data_json)\ndj$links[[1]] <- as.numeric(dj$links[[1]])\ndj$links[[2]] <- as.numeric(dj$links[[2]])\ndj <- jsonlite::toJSON(dj)\n\nwrite(dj, \"network.json\")"},{"path":"Visualization.html","id":"Figure_6_21","chapter":"Section 6 Network Visualization","heading":"Figure 6.21: The Filmstrip Approach","text":"Fig. 6.21. demonstration filmstrip approach plotting longitudinal network data. data represent networks ceramic similarity San Pedro Valley Arizona three consecutive 50-year intervals.Use data replicate figures shown .","code":"\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(ggpubr)\n\nload(\"data/Figure6_21.Rdata\")\n\nset.seed(4543)\ng1 <- ggraph(AD1250net, \"kk\") +\n  geom_edge_link(aes(), color = \"gray75\", show.legend = FALSE) +\n  geom_node_point(aes(),\n                  size = 1,\n                  show.legend = FALSE,\n                  color = \"blue\") +\n  ggtitle(\"AD1250-1300\") +\n  theme_graph()\n\nset.seed(4543)\ng2 <- ggraph(AD1300net, \"kk\") +\n  geom_edge_link(aes(), color = \"gray75\", show.legend = FALSE) +\n  geom_node_point(aes(),\n                  size = 1,\n                  show.legend = FALSE,\n                  color = \"blue\") +\n  ggtitle(\"AD1300-1350\") +\n  theme_graph()\n\n\nset.seed(4543)\ng3 <- ggraph(AD1350net, \"kk\") +\n  geom_edge_link(aes(), color = \"gray75\", show.legend = FALSE) +\n  geom_node_point(aes(),\n                  size = 1,\n                  show.legend = FALSE,\n                  color = \"blue\") +\n  ggtitle(\"AD1350-1400\") +\n  theme_graph()\n\nfigure6_21 <- ggarrange(g1, g2, g3, nrow = 1)\n\nfigure6_21"},{"path":"Visualization.html","id":"Figure_6_22","chapter":"Section 6 Network Visualization","heading":"Figure 6.22: Similtaneous Display","text":"Fig. 6.22. Examples simultaneous display two consecutive intervals San Pedro valley ceramic similarity network. () network using Kamada-Kawai algorithm edges color-coded based time period. (b) arc plot showing ties consecutive intervals line.Use data follow along. Note first plot add colour argument aes() statement include period designation.","code":"\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(ggpubr)\nlibrary(ggrepel)\n\nload(\"data/Figure6_22.Rdata\")\n\ngraph <- graph_from_data_frame(net_all)\n\nxy <- layout_with_kk(graph)\nxy <- cbind(sites, xy)\nxy <- as.data.frame(xy)\ncolnames(xy) <- c(\"site\", \"x\", \"y\")\nxy$x <- as.numeric(xy$x)\nxy$y <- as.numeric(xy$y)\n\nset.seed(6436)\nsimilt_net <- ggraph(graph, layout = \"manual\",\n                     x = xy$x, y = xy$y) +\n  geom_edge_link(aes(colour = Period), alpha = 0.3, width = 1) +\n  geom_node_point(size = 3) +\n  theme_graph() +\n  theme(legend.title = element_text(size = rel(1)),\n        legend.text = element_text(size = rel(1)),\n        legend.key.height = unit(1, \"cm\"),\n        legend.key.width = unit(2, \"cm\"))\n\n# Make the graph\nlin_net <- ggraph(spgraph, layout = \"linear\") +\n  geom_edge_arc(edge_colour = \"black\", edge_alpha = 0.4, edge_width = 0.3,\n                fold = FALSE, strength = 1) +\n  geom_node_point(aes(size = igraph::degree(spgraph)), col = \"red\",\n                  alpha = 0.5) +\n  scale_size_continuous(range = c(4, 8)) +\n  theme_graph() +\n  theme(legend.title = element_blank(),\n        plot.margin = unit(c(0, 0, 0.4, 0), \"null\"),\n        panel.spacing = unit(c(0, 0, 3.4, 0), \"null\")) +\n  annotate(\"text\", x = 3, y = 3, label = \"AD 1250-1300\",\n           size = 4) +\n  annotate(\"text\", x = 3, y = -3, label = \"AD 1300-1350\",\n           size = 4)\n\nsimilt_net\nlin_net"},{"path":"Visualization.html","id":"Figure_6_23","chapter":"Section 6 Network Visualization","heading":"Figure 6:23: Timelines and Time Prisms","text":"Fig. 6.23. plot shows two displays ceramic similarity data Sonoran Desert U.S. Southwest time prism (top) timeline (bottom).examples drawn work outline workshop focused temporal networks Skye Bender-deMoll. Click see detailed workshop overview. functions animating plotting temporal networks used come ndtv networkDynamic packages.\nNote data required list object contains multiple\ntemporal slices network network format \nstatnet suite packages. network must \nnumber nodes node identifiers must used every\nnetwork list.\nUse data follow along.","code":"\nlibrary(networkDynamic)\nlibrary(ndtv)\nlibrary(scatterplot3d)\nlibrary(prettyGraphs)\nlibrary(statnet)\n\nload(\"data/Figure6_23.Rdata\")\n\n# create networkDynamic object from list containing multiple\n# sna network objects\nsanpedro <- networkDynamic(network.list = sp_nets)## Neither start or onsets specified, assuming start=0\n## Onsets and termini not specified, assuming each network in network.list should have a discrete spell of length 1\n## Argument base.net not specified, using first element of network.list instead\n## Created net.obs.period to describe network\n##  Network observation period info:\n##   Number of observation spells: 1 \n##   Maximal time range observed: 0 until 5 \n##   Temporal mode: discrete \n##   Time unit: step \n##   Suggested time increment: 1\n# Compute animation\ncompute.animation(sanpedro, default.dist = 7, animation.mode = \"kamadakawai\")## slice parameters:\n##   start:0\n##   end:5\n##   interval:1\n##   aggregate.dur:1\n##   rule:latest\n# Define colors for regions\nmycol <- c(\n  add.alpha(\"#1b9e77\", 0.75),\n  add.alpha(\"#d95f02\", 0.75),\n  add.alpha(\"#7570b3\", 0.75),\n  add.alpha(\"#e7298a\", 0.75),\n  add.alpha(\"#66a61e\", 0.75),\n  add.alpha(\"#e6ab02\", 0.75)\n)\n\n# Plot time prism\nset.seed(364467)\ntimePrism(\n  sanpedro,\n  at = c(1, 2, 3),\n  displaylabels = FALSE,\n  planes = TRUE,\n  display.isolates = FALSE,\n  label.cex = 0.5,\n  usearrows = FALSE,\n  vertex.cex = 0.5,\n  edge.col = \"gray50\",\n  vertex.col = mycol[factor(sp_attr$SWSN_MacroGroup)]\n)\n# Plot proximity timeline\nset.seed(235254)\nproximity.timeline(\n  sanpedro,\n  default.dist = 10,\n  mode = \"sammon\",\n  labels.at = 17,\n  vertex.cex = 4,\n  render.edges = FALSE,\n  vertex.col = mycol[factor(sp_attr$SWSN_MacroGroup)],\n  chain.direction = \"reverse\",\n  xaxt = \"n\"\n)"},{"path":"Visualization.html","id":"Figure_6_24","chapter":"Section 6 Network Visualization","heading":"Figure 6.24: Animation","text":"Fig. 6.24. example three frames network animation.Figure 6.24 created using ndtv package data produced figure 6.23. simply rendered animation output interactive html widget. figure book represents 3 screen shots interactive plot. See ndtv documentation details.","code":"\nrender.d3movie(sanpedro, vertex.col = mycol[factor(sp_attr$SWSN_MacroGroup)])\nrender.d3movie(sanpedro, vertex.col = mycol[factor(sp_attr$SWSN_MacroGroup)],\n               output.mode = \"inline\")"},{"path":"Visualization.html","id":"Figure_6_25","chapter":"Section 6 Network Visualization","heading":"Figure 6.25: Interactive Networks","text":"Fig. 6.25. example dynamic network visual created R. Notice nodes edges responding movement edge cursor drop menu allows selection nodes group.example closely follow example provided Static dynamic network visualization R workshop documents online using Cibola technological similarity data instead.","code":"\nlibrary(visNetwork)\nlibrary(networkD3)\nlibrary(igraph)\n\nload(\"data/Figure6_25.Rdata\") # Contains an igraph graph object\n\n# Use igraph to make the graph and find membership\nclust <- cluster_louvain(graph)\nmembers <- membership(clust)\n\n# Convert to object suitable for networkD3\ngraph_d3 <- igraph_to_networkD3(graph, group = members)\n\n# Modify interactive network to allow highlighting by groups, etc.\nlinks <- graph_d3$links\ncolnames(links) <- c(\"from\", \"to\")\nlinks[, 1] <- links[, 1] + 1\nlinks[, 2] <- links[, 2] + 1\nnodes <- graph_d3$nodes\ncolnames(nodes)[1] <- \"id\"\n\n# Create node and link objects in d3 format\nvis_nodes <- nodes\nvis_links <- links\n\n# Set visualization options\nvis_nodes$shape  <- \"dot\"\nvis_nodes$shadow <- TRUE # Nodes will drop shadow\nvis_nodes$borderWidth <- 2 # Node border width\nvis_nodes$color.background <- c(\"slategrey\", \"tomato\", \"gold\",\n                                \"purple\")[nodes$group]\nvis_nodes$color.border <- \"black\"\nvis_nodes$color.highlight.background <- \"orange\"\nvis_nodes$color.highlight.border <- \"darkred\"\n\n# Create network in d3 format\nvisnet <- visNetwork(vis_nodes, vis_links)\n\n# View network with visualization options active\nvisOptions(visnet, highlightNearest = TRUE, selectedBy = \"group\")"},{"path":"Visualization.html","id":"Figure_6_26","chapter":"Section 6 Network Visualization","heading":"Figure 6.26: SWSN Example 1","text":"Fig. 6.26. Networks time SWSN project area (Mills et al. 2013).figure original plot Mills et al. 2013 produced R compiled modified using Adobe Illustrator. First regional color scheme defined time period plotted using color scheme. Illustrator components arranged rough geographic positions isolates placed margin. Click link info Southwest Social Networks ProjectThe following chunk code reproduces Figure 6.26 one time period (AD1300-1350). Download data follow along.","code":"\nlibrary(statnet)\nlibrary(ggraph)\n\nload(\"data/Figure6_26.Rdata\")\n\n# Create sna network object\nnet <-\n  network(event2dichot(sim, method = \"absolute\", thresh = 0.75),\n          directed = FALSE)\n\n# define color scheme. colors listed in order based on the\n# factor attr$Macro\nmycols <- c(\"#000738\", \"#ffa1a1\", \"#ad71d8\", \"#016d1b\", \"#00ff30\",\n            \"#92d8ff\", \"#ffffff\", \"#adadad\", \"#846b00\", \"#ff0000\",\n            \"#5273dd\", \"#946a43\", \"#a00000\", \"#f97c00\", \"#00ffec\",\n            \"#ffff3e\", \"#824444\", \"#00ba89\", \"#00ba89\", \"#0303ff\")\n\n# Plot network\nset.seed(235)\nggraph(net, layout = \"fr\") +\n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(fill = as.factor(attr$Macro), size = evcent(net)),\n                  shape = 21,\n                  show.legend = FALSE) +\n  scale_size(range = c(1.5, 3)) +\n  scale_fill_manual(values = mycols) +\n  theme_graph()"},{"path":"Visualization.html","id":"Figure_6_27","chapter":"Section 6 Network Visualization","heading":"Figure 6.27: SWSN Example 2","text":"Fig. 6.27. explicit geographic map network SWSN project area time (Mills et al. 2013).original version figure produced ArcGIS using data prepared R. show network maps edges color coded geographic length can produced R. provide code prepare map one time period (AD1300-1350). Use data follow along. Note figure differ slightly one book original Mills et al. 2013 publication site locations jittered. example use geographic coordinates calculate distance. See spatial networks section details.\nNote short edges visible top long edges must\nfirst sort order edges bu length original edge list \nconverting igraph network object. three lines beginning\n# Order edges shorest plot last, use \norder function set decreasing = TRUE \nedges listed longest shortest. order \nedge list order edges plotted.\n","code":"\nlibrary(statnet)\nlibrary(igraph)\nlibrary(intergraph)\nlibrary(geosphere)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(ggraph)\n\n# Load in network and map data\nload(\"data/Figure6_27.Rdata\")\n\n# prepare network object\nnet <- network(event2dichot(sim, method = \"absolute\", thresh = 0.75),\n               directed = FALSE)\nr_net <- asIgraph(net)\n\n# convert coordinates to lat/long and covert to sf object\nlocations_sf <- st_as_sf(attr,\n                         coords = c(\"EASTING\", \"NORTHING\"),\n                         crs = 26912)\nz <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(z)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\n# output coordinates in data frame\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n# Create edge list with xy coordinates for each source and target\nedgelist2 <- get.edgelist(r_net)\nedges2 <- data.frame(xy[edgelist2[, 1], ], xy[edgelist2[, 2], ])\ncolnames(edges2) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Determine the geographic distances of edges using the distm\n# function in the geosphere package\ndist_meas <- NULL\nfor (i in seq_len(nrow(edges2))) {\n  temp <- as.matrix(edges2[i, ])\n  dist_meas[i] <- distm(temp[1, 1:2], temp[1, 3:4])\n}\n\n# Order edges so shortest will plot last\nnet_dat <- as.data.frame(cbind(edges2, dist_meas))\nnet_dat <- net_dat[order(net_dat$dist_meas, decreasing = TRUE), ]\n\n# Create bins in distance measurement\nnet_dat <- net_dat %>%\n  mutate(DistBins = cut(dist_meas,\n                        breaks = c(-Inf, 25000, 100000, 250000, Inf)))\n\n# Plot network map\nggmap(base2, darken = 0.5) +\n  geom_segment(\n    data = net_dat,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2,\n      col = DistBins\n    ),\n    size = 0.15,\n    show.legend = FALSE\n  ) +\n  scale_color_manual(values = c(\"white\", \"skyblue\", \"dodgerblue\",\n                                \"darkblue\")) +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"SpatialNetworks","chapter":"Section 7 Spatial Networks","heading":"Section 7 Spatial Networks","text":"section follows along Chapter 7 Brughmans Peeples (2023) provide information implement spatial network models analyses R. Spatial networks one common kinds networks used archaeological research. Many network studies rely GIS tools conduct spatial network research, R quite capable spatial analysis. Note created separate section spatial interaction models “Going Beyond Book” section document approaches particular require extended discussion.Working geographic data R can bit complicated cover aspects brief tutorial. interested exploring geospatial networks , suggest take look excellent free Geocomputation R book Robin Lovelace, Jakob Nowosad, Jannes Muenchow. book bookdown document just like tutorial provides excellent date coverage spatial operations management spatial data R.","code":""},{"path":"SpatialNetworks.html","id":"GeoData","chapter":"Section 7 Spatial Networks","heading":"7.1 Working with Geographic Data in R","text":"\nnumber packages R designed explicitly \nworking spatial data. get spatial analyses \nuseful first briefly introduce packages aspects spatial\ndata analysis R.\nprimary packages include:sf - package designed plotting encoding simple spatial features vector data converting locations among different map projections. Check good brief overview package.ggmap - package visualization tool allows combine typical R figures ggplot2 format static maps available online services like Google Maps, Stamen Maps, OpenStreet Maps, others. package useful quickly generating maps background layer use .cccd - package designed explicitly working spatial data number functions defining networks based relative neighborhoods spatial network definitions.deldir - package designed create spatial partitions including calculating Delaunay triangulation Voronoi tessellations spatial planes.geosphere - package focused spherical trigonometry functions allow us calculate distances points spherical geographic space across globe.RBGL - R implementation package called Boost Graph Library. package number functions use provides function test graph planarity.spatial data use document consists vector data. simply means mapping data re images pixels representing space instead spatial coordinates define locations distances. One key aspect spatial data R, especially large scales, often need define projection coordinate reference system produce accurate maps.coordinate reference system (CRS) formal definition spatial points relate surface globe. CRS typically fall two categories: geographic coordinate systems projected coordinate systems. common geographic coordinate system latitude/longitude system describes locations surface Earth terms angular coordinates Prime Meridian Equator. projected data set refers process map makers take spherical Earth create flat map. Projections distort move area, distance, shape varying degrees provide xy location coordinates linear units. advantages disadvantages systems beyond scope document important note R often requires us define coordinate reference system working spatial data.code several sections book seen function calls include argument called crs. coordinate reference system object used R provides numeric code denoting CRS used given data set. Just like take external .csv data covert network objects R understands, need import spatial data convert object R recognizes. sf package using st_as_sf function.use function take data frame includes location xy information, use coords argument specify fields x y coordinates, use crs code specify coordinate reference system used. example use code 4326 refers WGS84 World Geodetic System geographic coordinates. See website look many common crs code options.working geographic data, also sometimes useful plot directly top sort base map. many options one convenient use sf ggmap packages directly download relevant base map layer plot directly top . first requires converting points latitude longitude decimal degrees already format. See details sf package ggmap package details.demonstrate use ggmap get_stadiamap function requires bit additional explanation. function automatically retrieves background map using arguments:bbox - bounding box represents decimal degrees longitude latitude coordinates lower left upper right area wish map.maptype - name indicates style map use (check options).zoom - variable denoting detail zoom level retrieved. Higher number give detail take longer detail.early 2024 get_stadiamap function also requires sign account stadiamaps.com. account free allows download large number background maps R per month (likely FAR individual ever use). setup steps required get work. can follow steps click YouTube video outlining steps 1 thorugh 3 .First, need sign free account Stadiamaps.First, need sign free account Stadiamaps.sign , asked create Property Name, designating using data. can simply call “R analysis” anything ’d like.sign , asked create Property Name, designating using data. can simply call “R analysis” anything ’d like.create property ’ll able assign API key clicking “Add API” button.create property ’ll able assign API key clicking “Add API” button.Now simply need let R know API allow map download access. order copy API key visible stadiamaps page property created run following line code adding actual API key place [KEY ]Now simply need let R know API allow map download access. order copy API key visible stadiamaps page property created run following line code adding actual API key place [KEY ]Note, ease demonstration, remainder online guide pre-download maps provide file instead using get_stadiamap function.Now ’re ready run code can download stadia map backgrounds automatically:","code":"\nlibrary(sf)\nnodes <- read.csv(\"data/Hispania_nodes.csv\", header = T)\nlocs <- st_as_sf(nodes, coords = c(\"long\", \"lat\"), crs = 4326)\n\nlocs## Simple feature collection with 122 features and 2 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -9.1453 ymin: 36.0899 xmax: 3.1705 ymax: 43.5494\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##    Id                                    name                geometry\n## 1  n0                               \"Bracara\"  POINT (-8.427 41.5501)\n## 2  n1                           \"Iria Flavia\" POINT (-8.5974 42.8101)\n## 3  n2                               \"Saltigi\" POINT (-1.7228 38.9186)\n## 4  n3                              \"Bilbilis\" POINT (-1.6083 41.3766)\n## 5  n4                             \"Scallabis\" POINT (-8.6871 39.2362)\n## 6  n5                  \"Mercablum/Merifabion\" POINT (-6.0886 36.2765)\n## 7  n6 \"Valentia (Hispania Tarraconensis) (1)\" POINT (-0.3755 39.4758)\n## 8  n7                               \"Italica\" POINT (-6.0449 37.4411)\n## 9  n8               \"Acci/Col. Iulia Gemella\" POINT (-3.1346 37.3003)\n## 10 n9                               \"Toletum\" POINT (-4.0245 39.8567)\nlibrary(ggmap)\nactivate(key=\"[YOUR KEY HERE]\")## Loading required package: ggplot2## ℹ Google's Terms of Service: <https://mapsplatform.google.com>\n##   Stadia Maps' Terms of Service: <https://stadiamaps.com/terms-of-service/>\n##   OpenStreetMap's Tile Usage Policy: <https://operations.osmfoundation.org/policies/tiles/>\n## ℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\nlibrary(ggmap)\nmap <- get_stadiamap(bbox = c(-9.5, 36, 3, 43.8),\n                       maptype = \"stamen_terrain_background\",\n                       zoom = 6)\nggmap(map)"},{"path":"SpatialNetworks.html","id":"ExampleData","chapter":"Section 7 Spatial Networks","heading":"7.2 Example Data","text":"initial examples section use Roman Road data Iberian Peninsula. data set consists csv file set Roman settlements csv file edge list defining connections among settlements terms roads.First map basic road network. commented code explain happening stage.","code":"\nlibrary(igraph)\nlibrary(ggmap)\nlibrary(sf)\n\n# Read in edge list and node location data and covert to network object\nedges1 <- read.csv(\"data/Hispania_roads.csv\", header = TRUE)\nnodes <- read.csv(\"data/Hispania_nodes.csv\", header = TRUE)\nroad_net <-\n  graph_from_edgelist(as.matrix(edges1[, 1:2]), directed = FALSE)\n\n# Convert attribute location data to sf coordinates\nlocations_sf <-\n  st_as_sf(nodes, coords = c(\"long\", \"lat\"), crs = 4326)\n# We also create a simple set of xy coordinates as this is used\n# by the geom_point function\nxy <- data.frame(x = nodes$long, y = nodes$lat)\n\n# Extract edge list from network object\nedgelist <- get.edgelist(road_net)\n\n# Create data frame of beginning and ending points of edges\nedges <- as.data.frame(matrix(NA, nrow(edgelist), 4))\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n# Iterate across each edge and assign lat and long values to\n# X1, Y1, X2, and Y2\nfor (i in seq_len(nrow(edgelist))) {\n  edges[i, ] <- c(nodes[which(nodes$Id == edgelist[i, 1]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 1]), 2],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 2])\n}\n\n# Download stamenmap background data.\nmy_map <- get_stadiamap(bbox = c(-9.5, 36, 3, 43.8),\n                       maptype = \"stamen_terrain_background\",\n                       zoom = 6)\n\n# Produce map starting with background\nggmap(my_map) +\n  # geom_segment plots lines by the beginning and ending\n  # coordinates like the edges object we created above\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  # plot site node locations\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.8,\n    col = \"black\",\n    fill = \"white\",\n    shape = 21,\n    size = 2,\n    show.legend = FALSE\n  ) +\n  theme_void()"},{"path":"SpatialNetworks.html","id":"PlanarTrees","chapter":"Section 7 Spatial Networks","heading":"7.3 Planar Networks and Trees","text":"","code":""},{"path":"SpatialNetworks.html","id":"EvaluatingPlanarity","chapter":"Section 7 Spatial Networks","heading":"7.3.1 Evaluating Planarity","text":"planar network network can drawn plane edges cross instead always end nodes. many small networks relatively easy determine whether network planar simply viewing network graph. larger graphs, can sometimes difficult.\npackage available R called RBGL \nR implementation something called Boost Graph Library. \nset routines includes many powerful tools characterizing network\ntopology including planarity. package , however, CRAN\narchive packages worked far reside needs\ninstalled another archive called Bioconductor.\norder install RBGL BiocManager libraries (required), run following lines code.place can now preform analysis called Boyer-Myrvold planarity test (Boyer Myrvold 2004). analysis performs set operations graph structure evaluate whether can defined planar graph (see publication details).Let’s take look Roman Road data.results suggests Roman Road data planar. can plot data evaluate see crossed edges re-positioned.Now, way example, can generate small random network planar see results test. Note network graph produced visual planar small number nodes moved. Unfortunately planar graph drawing currently implemented igraph packages automatically plot graph planar even meets criteria planar graph.another example graph layout algorithm happens produce planar graph.","code":"\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\nBiocManager::install(\"RBGL\")\nlibrary(RBGL)\n# First convert to a graphNEL object for planarity test\ng <- as_graphnel(road_net)\n# Implement test\nboyerMyrvoldPlanarityTest(g)## [1] FALSE\nlibrary(ggraph)\nset.seed(5364)\nggraph(road_net, layout = \"kk\") +\n  geom_edge_link() +\n  geom_node_point(size = 3) +\n  ggtitle(\"Network of Roman Roads\") +\n  theme_graph()\nset.seed(49)\ng <- erdos.renyi.game(20, 1 / 8)\nset.seed(939)\nplot(g)\ng <- as_graphnel(g)\nboyerMyrvoldPlanarityTest(g)## [1] TRUE\nset.seed(4957)\ng <- erdos.renyi.game(20, 1 / 8)\nset.seed(939)\nplot(g)\ng <- as_graphnel(g)\nboyerMyrvoldPlanarityTest(g)## [1] TRUE"},{"path":"SpatialNetworks.html","id":"DefiningTrees","chapter":"Section 7 Spatial Networks","heading":"7.3.2 Defining Trees","text":"tree network connected acyclic. Trees contain minimum number edges set nodes connected, results acyclic network interesting properties:Every edge tree bridge, removal increase number components.number edges tree equal number nodes minus one.can one single path every pair nodes tree.R using igraph package possible generate trees also take existing network define called minimum spanning tree graph minimum acyclic component.Let’s create simple tree using make_tree function igraph.example can see branch leaf structure network central nodes hubs number nodes , cycles back previous nodes. Thus, tree inherently hierarchical. next sub-section, discuss use minimum spanning trees.also possible plot trees hierarchical network layout nodes arranged levels hierarchy. case need specify node nodes represent first layer using root call within ggraph call.","code":"\ntree1 <- make_tree(n = 50, children = 5, mode = \"undirected\")\ntree1## IGRAPH d5f44db U--- 50 49 -- Tree\n## + attr: name (g/c), children (g/n), mode (g/c)\n## + edges from d5f44db:\n##  [1]  1-- 2  1-- 3  1-- 4  1-- 5  1-- 6  2-- 7  2-- 8  2-- 9  2--10  2--11\n## [11]  3--12  3--13  3--14  3--15  3--16  4--17  4--18  4--19  4--20  4--21\n## [21]  5--22  5--23  5--24  5--25  5--26  6--27  6--28  6--29  6--30  6--31\n## [31]  7--32  7--33  7--34  7--35  7--36  8--37  8--38  8--39  8--40  8--41\n## [41]  9--42  9--43  9--44  9--45  9--46 10--47 10--48 10--49 10--50\nplot(tree1)\nggraph(tree1,\n       layout = \"igraph\",\n       algorithm = \"tree\",\n       root = 1) +\n  geom_edge_diagonal(edge_width = 0.5, alpha = .4) +\n  geom_node_text(aes(label = V(tree1)), size = 3.5) +\n  theme_void()"},{"path":"SpatialNetworks.html","id":"SpatialNetworkModels","chapter":"Section 7 Spatial Networks","heading":"7.4 Spatial Network Models","text":"Chapter 7.5 Brughmans Peeples (2023) go series spatial network models provide number different ways defining networks spatial data. sub-section demonstrate define analyze networks using approaches.","code":""},{"path":"SpatialNetworks.html","id":"RelativeNeighborhoods","chapter":"Section 7 Spatial Networks","heading":"7.4.1 Relative Neighborhood Networks","text":"Relative neighborhood graph: pair nodes connected nodes area marked overlap circle around node radius equal distance nodes.\nR package cccd contains functions define relative\nneighborhood networks distance data using rng\nfunction. function can either take distance matrix object \ncreated set coordinates calculate distance within\ncall. output function igraph object. large\ngraphs also possible limit search possible neighbors \n\\(k\\) neighbors.\nLet’s use previously created distance matrix plot results.can also plot results using geographic coordinates.","code":"\nlibrary(cccd)\nrng1 <- rng(nodes[, c(3, 2)])\nggraph(rng1, layout = \"kk\") +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\nggraph(rng1,\n       layout = \"manual\",\n       x = nodes[, 3],\n       y = nodes[, 2]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"GabrialGraphs","chapter":"Section 7 Spatial Networks","heading":"7.4.2 Gabriel Graphs","text":"Gabriel graph: pair nodes connected Gabriel graph nodes lie within circular region diameter equal distance pair nodes.can use function cccd package define Gabriel Graph igraph objects x y coordinates. Let’s take look using Roman Road data. See ?gg details options including different algorithms calculating Gabriel Graphs. define Gabriel graph plot using algorithmic layout geographic coordinates.","code":"\ngg1 <- gg(x = nodes[, c(3, 2)])\nggraph(gg1, layout = \"stress\") +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\nggraph(gg1,\n       layout = \"manual\",\n       x = nodes[, 3],\n       y = nodes[, 2]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"BetaSkeletons","chapter":"Section 7 Spatial Networks","heading":"7.4.3 Beta Skeletons","text":"Beta skeleton: Gabriel graph diameter circle controlled parameter beta.R gg function producing Gabriel Graphs procedure beta skeletons built directly . argument r gg function controls beta parameter. r = 1 traditional Gabriel graph returned. parameter r > 1 stricter definition connection resulting fewer ties r < 1 link criteria loosened. See ?gg details.","code":"\nbeta_s <- gg(x = nodes[, c(3, 2)], r = 1.5)\nggraph(beta_s,\n       layout = \"manual\",\n       x = nodes[, 3],\n       y = nodes[, 2]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"MinSpanningTrees","chapter":"Section 7 Spatial Networks","heading":"7.4.4 Minimum Spanning Trees","text":"Minimum spanning tree: set nodes Euclidean plane, edges created pairs nodes form tree node can reached node, sum Euclidean edge lengths less sum spanning tree.Perhaps common use-case trees archaeological networks define minimum spanning tree given graph minimum set nodes edges required fully connected graph. igraph package function called mst defines minimum spanning tree given graph. Let’s try Roman Road plot node-link diagram map.Note minimum spanning trees can also used weighted graphs weighted connections preferred defining tree structure. See ?mst details.","code":"\nmst_net <- igraph::mst(road_net)\nset.seed(4643)\nggraph(mst_net, layout = \"kk\") +\n  geom_edge_link() +\n  geom_node_point(size = 4) +\n  theme_graph()\n# Extract edge list from network object\nedgelist <- get.edgelist(mst_net)\n# Create data frame of beginning and ending points of edges\nedges <- as.data.frame(matrix(NA, nrow(edgelist), 4))\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\nfor (i in seq_len(nrow(edgelist))) {\n  edges[i, ] <- c(nodes[which(nodes$Id == edgelist[i, 1]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 1]), 2],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 3],\n                  nodes[which(nodes$Id == edgelist[i, 2]), 2])\n}\nggmap(my_map) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  geom_point(\n    data = nodes[, c(3, 2)],\n    aes(long, lat),\n    alpha = 0.8,\n    col = \"black\",\n    fill = \"white\",\n    shape = 21,\n    size = 1.5,\n    show.legend = FALSE\n  ) +\n  theme_void()"},{"path":"SpatialNetworks.html","id":"DelaunayTri","chapter":"Section 7 Spatial Networks","heading":"7.4.5 Delaunay Triangulation","text":"Delaunay triangulation: pair nodes connected edge corresponding regions Voronoi diagram share side.Voronoi diagram Thiessen polygons: node set nodes Euclidean plane, region created covering area closer equidistant node node set.\npackage deldir R allows calculation \nDelaunay triangles x y coordinates input. default \ndeldir function define boundary extends\nslightly beyond xy coordinates points included \nanalysis. boundary can also specified within call using \nrw argument. See ?deldir details.\nresults deldir function can directly plotted output also contains coordinates necessary integrate results another type figure like ggmap. Let’s take look.","code":"\nlibrary(deldir)\ndt1 <- deldir(nodes[, 3], nodes[, 2])\nplot(dt1)\n# Extract Voronoi polygons for plotting\nmapdat <- as.data.frame(dt1$dirsgs)\n# Extract network for plotting\nmapdat2 <- as.data.frame(dt1$delsgs)\nggmap(my_map) +\n  geom_segment(\n    data = mapdat,\n    aes(\n      x = x1,\n      y = y1,\n      xend = x2,\n      yend = y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  geom_segment(\n    data = mapdat2,\n    aes(\n      x = x1,\n      y = y1,\n      xend = x2,\n      yend = y2\n    ),\n    col = \"red\",\n    size = 1\n  ) +\n  geom_point(\n    data = nodes,\n    aes(long, lat),\n    alpha = 0.8,\n    col = \"black\",\n    fill = \"white\",\n    shape = 21,\n    size = 3,\n    show.legend = FALSE\n  ) +\n  theme_void()"},{"path":"SpatialNetworks.html","id":"KNN","chapter":"Section 7 Spatial Networks","heading":"7.4.6 K-nearest Neighbors","text":"K-nearest neighbor network: node connected K nodes closest .cccd package routine allows calculation K-nearest neighbor graphs geographic coordinates precomputed distance matrix. example use Roman Road data calculate K=1 K=6 nearest neighbor networks plot simultaneously.","code":"\n# Calculate k=1 nearest neighbor graph\nnn1 <- nng(x = nodes[, c(3, 2)], k = 1)\n# Calculate k=6 nearest neighbor graph\nnn6 <- nng(x = nodes[, c(3, 2)], k = 6)\nel1 <- as.data.frame(\n  rbind(cbind(get.edgelist(nn6),\n         rep(\"K=6\", nrow(get.edgelist(nn1))\n             )),\n        cbind(get.edgelist(nn1),\n          rep(\"K=1\", nrow(get.edgelist(nn1))\n             ))))\ncolnames(el1) <- c(\"from\", \"to\", \"K\")\ng <- graph_from_data_frame(el1)\n# Plot both graphs\nggraph(g, layout = \"manual\",\n       x = nodes[, 3], y = nodes[, 2]) +\n  geom_edge_link(aes(color = factor(K)), width = 1.5) +\n  geom_node_point(size = 2) +\n  labs(edge_color = \"K\") +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"MaxDist","chapter":"Section 7 Spatial Networks","heading":"7.4.7 Maximum Distance Networks","text":"Maximum distance network: node connected nodes distance closer equal threshold value. order define maximum distance network simply need define threshold distance define nodes greater distance unconnected nodes within distance connected. can done base R using dist function used .\nSince coordinates using decimal degrees \nneed calculate distances based “great circles” across globe\nrather Euclidean distances projected plane. \nfunction called distm geosphere package\nallows us . working projected data, \ncan simply use dist function place \ndistm like example .\nNext, order define minimum distance network simply binarize matrix. can using event2dichot function within statnet package easily create R network objects. Let’s try Roman Road data thresholds 100,000 250,000 meters.","code":"\nlibrary(statnet)\nlibrary(geosphere)\nd1 <- distm(nodes[, c(3, 2)])\n# Note we use the leq=TRUE argument here as we want nodes less than\n# the threshold to count.\nnet100 <- network(event2dichot(\n  d1,\n  method = \"absolute\",\n  thresh = 100000,\n  leq = TRUE\n),\ndirected = FALSE)\nnet250 <- network(event2dichot(\n  d1,\n  method = \"absolute\",\n  thresh = 250000,\n  leq = TRUE\n),\ndirected = FALSE)\n# Plot 100 Km network\nggraph(net100,\n       layout = \"manual\",\n       x = nodes[, 3],\n       y = nodes[, 2]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\n# Plot 250 Km network\nggraph(net250,\n       layout = \"manual\",\n       x = nodes[, 3],\n       y = nodes[, 2]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()"},{"path":"SpatialNetworks.html","id":"SpaceCaseStudies","chapter":"Section 7 Spatial Networks","heading":"7.5 Case Studies","text":"","code":""},{"path":"SpatialNetworks.html","id":"IronAgeSpain","chapter":"Section 7 Spatial Networks","heading":"7.5.1 Proximity of Iron Age sites in Southern Spain","text":"first case study Chapter 7 Brughmans Peeples (2023) example several methods defining networks using spatial data outlined using locations 86 sites Guadalquivir river valley Southern Spain. code chunks , replicate analyses presented book.First read data represents site location information lat/long decimal degrees.Next create distance matrix based decimal degrees locations using “distm” function.can create maximum distance networks 10km 18km distance plot using geographic location nodes node placement.\nwant combine degree distribution plot network\nframe, can use inset_element function\npatchwork package. function lets us place one\nplot inside another ggplot2 format.\nNext, calculate relative neighborhood graph site locations plot nodes positioned geographic space.chunk code calculates plots Gabrial graph associated degree distribution plot.Next, ’ll plot K-nearest neighbors graphs k= 2, 3, 4, 6 associated degree distribution .","code":"\nguad <- read.csv(\"data/Guadalquivir.csv\", header = TRUE)\nlibrary(geosphere)\ng_dist1 <- as.matrix(distm(guad[, c(2, 3)]))\ng_dist1[1:4, 1:4]##          [,1]     [,2]     [,3]     [,4]\n## [1,]     0.00 69995.82 42265.58 51296.53\n## [2,] 69995.82     0.00 28240.50 29202.84\n## [3,] 42265.58 28240.50     0.00 23692.10\n## [4,] 51296.53 29202.84 23692.10     0.00\nlibrary(intergraph)\n# Note we use the leq=TRUE argument here as we want nodes\n# less than the threshold to count.\nnet10 <- asIgraph(network(\n  event2dichot(\n    g_dist1,\n    method = \"absolute\",\n    thresh = 10000,\n    leq = TRUE\n  ),\n  directed = FALSE\n))\nnet18 <- asIgraph(network(\n  event2dichot(\n    g_dist1,\n    method = \"absolute\",\n    thresh = 18000,\n    leq = TRUE\n  ),\n  directed = FALSE\n))\ng10_deg <- as.data.frame(igraph::degree(net10))\ncolnames(g10_deg) <- \"degree\"\ng18_deg <- as.data.frame(igraph::degree(net18))\ncolnames(g18_deg) <- \"degree\"\n# Plot histogram of degree for 10km network\nh10 <- ggplot(data = g10_deg) +\n  geom_histogram(aes(x = degree), bins = 15)\n# Plot histogram of degree for 18km network\nh18 <- ggplot(data = g18_deg) +\n  geom_histogram(aes(x = degree), bins = 15)\n# Plot 10 Km network\ng10 <- ggraph(net10,\n              layout = \"manual\",\n              x = guad[, 2],\n              y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\n# Plot 18 Km network\ng18 <- ggraph(net18,\n              layout = \"manual\",\n              x = guad[, 2],\n              y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng18\nlibrary(patchwork)\nplot_a <- g10 + inset_element(\n  h10,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_b <- g18 + inset_element(\n  h18,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_a\nplot_b\nrng1 <- rng(guad[, 2:3])\ng_rng <- ggraph(rng1,\n                layout = \"manual\",\n                x = guad[, 2],\n                y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng_rng_deg <- as.data.frame(igraph::degree(rng1))\ncolnames(g_rng_deg) <- \"degree\"\n# Plot histogram of degree for relative neighborhood network\nh_rng <- ggplot(data = g_rng_deg) +\n  geom_histogram(aes(x = degree), bins = 3)\nplot_c <- g_rng + inset_element(\n  h_rng,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_c\ngg1 <- gg(x = guad[, 2:3])\ng_gg <- ggraph(gg1,\n               layout = \"manual\",\n               x = guad[, 2],\n               y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng_gg_deg <- as.data.frame(igraph::degree(gg1))\ncolnames(g_gg_deg) <- \"degree\"\n# Plot histogram of degree for relative neighborhood network\nh_gg <- ggplot(data = g_gg_deg) +\n  geom_histogram(aes(x = degree), bins = 5)\nplot_d <- g_gg + inset_element(\n  h_gg,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_d\n# Calculate k=2,3,4, and 6 nearest neighbor graphs\nnn2 <- nng(x = guad[, 2:3], k = 2)\nnn3 <- nng(x = guad[, 2:3], k = 3)\nnn4 <- nng(x = guad[, 2:3], k = 4)\nnn6 <- nng(x = guad[, 2:3], k = 6)\n# Initialize network graph for each k value\ng_nn2 <- ggraph(nn2,\n                layout = \"manual\",\n                x = guad[, 2],\n                y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng_nn3 <- ggraph(nn3,\n                layout = \"manual\",\n                x = guad[, 2],\n                y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng_nn4 <- ggraph(nn4,\n                layout = \"manual\",\n                x = guad[, 2],\n                y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\ng_nn6 <- ggraph(nn6,\n                layout = \"manual\",\n                x = guad[, 2],\n                y = guad[, 3]) +\n  geom_edge_link() +\n  geom_node_point(size = 2) +\n  theme_graph()\n# Set up data frames of degree distribution for each network\nnn2_deg <- as.data.frame(igraph::degree(nn2))\ncolnames(nn2_deg) <- \"degree\"\nnn3_deg <- as.data.frame(igraph::degree(nn3))\ncolnames(nn3_deg) <- \"degree\"\nnn4_deg <- as.data.frame(igraph::degree(nn4))\ncolnames(nn4_deg) <- \"degree\"\nnn6_deg <- as.data.frame(igraph::degree(nn6))\ncolnames(nn6_deg) <- \"degree\"\n# Initialize histogram plot for each degree distribution\nh_nn2 <- ggplot(data = nn2_deg) +\n  geom_histogram(aes(x = degree), bins = 5) +\n  scale_x_continuous(limits = c(0, max(nn2_deg)))\nh_nn3 <- ggplot(data = nn3_deg) +\n  geom_histogram(aes(x = degree), bins = 6) +\n  scale_x_continuous(limits = c(0, max(nn3_deg)))\nh_nn4 <- ggplot(data = nn4_deg) +\n  geom_histogram(aes(x = degree), bins = 6) +\n  scale_x_continuous(limits = c(0, max(nn4_deg)))\nh_nn6 <- ggplot(data = nn6_deg) +\n  geom_histogram(aes(x = degree), bins = 5) +\n  scale_x_continuous(limits = c(0, max(nn6_deg)))\nplot_a <- g_nn2 + inset_element(\n  h_nn2,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_b <- g_nn3 + inset_element(\n  h_nn3,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_c <- g_nn4 + inset_element(\n  h_nn4,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_d <- g_nn6 + inset_element(\n  h_nn6,\n  left = 0,\n  bottom = 0.7,\n  right = 0.25,\n  top = 0.99\n)\nplot_a\nplot_b\nplot_c\nplot_d"},{"path":"SpatialNetworks.html","id":"SpaceSW","chapter":"Section 7 Spatial Networks","heading":"7.5.2 Networks in Space in the U.S. Southwest","text":"second case study Chapter 7 Brughmans Peeples (2023) provides example can use spatial network methods analyze material cultural network data. use Chaco World data can download map data, site attribute data, ceramic frequency data follow along.first analysis explores degree similarities ceramics (terms Brainerd-Robinson similarity based wares) can explained spatial distance. simply define ceramic similarity matrix, Euclidean distance matrix, fit model using distance explain ceramic similarity using general additive model (gam) approach. gam function use mgcv package. Note object dmat created using dist function data started already projected site locations using UTM coordinates.results show described book, spatial distance statistically significant predictor ceramic similarity distance appear explain 37.2% variation ceramic similarity.next analysis presented book creates series minimum distance networks 36Kms way nearly 400Kms concentric days travel (36Kms one day travel foot) explore proportion variance explained networks constrained distance.Finally, let’s recreate figure 7.8 book display 36km minimum distance network Chaco region ca. AD 1050-1100. follows basic format plotting minimum distance networks defined .","code":"\nlibrary(mgcv)\nload(\"data/map.RData\")\nattr <- read.csv(\"data/AD1050attr.csv\", row.names = 1)\ncer <- read.csv(\"data/AD1050cer.csv\",\n                header = T,\n                row.names = 1)\nsim <-\n  (2 - as.matrix(vegan::vegdist(prop.table(\n    as.matrix(cer), 1),\n    method = \"manhattan\"))) / 2\ndmat <- as.matrix(dist(attr[, 9:10]))\nfit <- gam(as.vector(sim) ~ as.vector(dmat))\nsummary(fit)## \n## Family: gaussian \n## Link function: identity \n## \n## Formula:\n## as.vector(sim) ~ as.vector(dmat)\n## \n## Parametric coefficients:\n##                   Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)      7.979e-01  2.547e-03   313.3   <2e-16 ***\n## as.vector(dmat) -2.487e-06  1.448e-08  -171.8   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## \n## R-sq.(adj) =  0.372   Deviance explained = 37.2%\n## GCV = 0.082702  Scale est. = 0.082699  n = 49729\n# Create a sequence of distances from 36km to 400kms by concentric\n# days travel on foot\nkms <- seq(36000, 400000, by = 36000)\n# Define minimum distance networks for each item in \"kms\" and the\n# calculate variance explained\ntemp_out <- NULL\nfor (i in seq_len(length(kms))) {\n  dmat_temp <- dmat\n  dmat_temp[dmat > kms[i]] <- 0\n  dmat_temp[dmat_temp > 0] <- 1\n  # Calculate gam model and output r^2 value\n  temp <- gam(as.vector(sim[lower.tri(sim)]) ~\n                as.vector(dmat_temp[lower.tri(dmat_temp)]))\n  temp_out[i] <- summary(temp)$r.sq\n}\n# Create data frame of output\ndat <- as.data.frame(cbind(kms / 1000, temp_out))\ncolnames(dat) <- c(\"Dist\", \"Cor\")\nlibrary(ggplot2)\n# Plot the results\nggplot(data = dat) +\n  geom_line(aes(x = Dist, y = Cor)) +\n  geom_point(aes(x = Dist, y = Cor), size = 3) +\n  xlab(\"Maximum Distance Network Threshold (Km)\") +\n  ylab(\"Proportion of Variance Explained\") +\n  theme_bw() +\n  theme(\n    axis.text.x = element_text(size = rel(1.5)),\n    axis.text.y = element_text(size = rel(1.5)),\n    axis.title.x = element_text(size = rel(1.5)),\n    axis.title.y = element_text(size = rel(1.5))\n  )\nd36 <- as.matrix(dist(attr[, 9:10]))\nd36[d36 < 36001] <- 1\nd36[d36 > 1] <- 0\ng36_net <- graph_from_adjacency_matrix(d36, mode = \"undirected\")\nlocations_sf <- st_as_sf(attr,\n                         coords = c(\"EASTING\", \"NORTHING\"),\n                         crs = 26912)\nz <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(z)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\nxy <- as.data.frame(cbind(attr$SWSN_Site, coord1))\ncolnames(xy) <- c(\"site\", \"x\", \"y\")\nbase <- get_stadiamap(\n  bbox = c(-110.75, 33.5, -107, 38),\n  zoom = 8,\n  maptype = \"stamen_terrain_background\",\n  color = \"bw\"\n)\n# Extract edge list from network object\nedgelist <- get.edgelist(g36_net)\n# Create data frame of beginning and ending points of edges\nedges <- as.data.frame(matrix(NA, nrow(edgelist), 4))\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\nfor (i in seq_len(nrow(edgelist))) {\n  edges[i, ] <- c(xy[which(xy$site == edgelist[i, 1]), 2],\n                  xy[which(xy$site == edgelist[i, 1]), 3],\n                  xy[which(xy$site == edgelist[i, 2]), 2],\n                  xy[which(xy$site == edgelist[i, 2]), 3])\n}\nfigure7_8 <- ggmap(base, darken = 0.15) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"white\",\n    size = 0.10,\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.65,\n    size = 1,\n    col = \"red\",\n    show.legend = FALSE\n  ) +\n  theme_void()\nfigure7_8"},{"path":"ERGM.html","id":"ERGM","chapter":"Section 8 Exponential Random Graph Models","heading":"Section 8 Exponential Random Graph Models","text":"Exponential Random Graph Models (ERGM; typically pronounced “UR-gum”) class statistical models designed help represent, evaluate, simulate ideas network generating processes structural properties (good introductions method see Lusher et al. 2013; archaeological cases see Amati et al. 2020; Brughmans et al. 2014; Wang Marwick 2021). models allow us formally represent theories particular patterns relationships (paths given length triads specific configuration) associations (mutuality connections among nodes share attribute) emerge persist networks. ERGMs help us evaluate well theories account observed network data. Specifically, ERGM can used generate large numbers networks random process targeted towards particular configurations associations represent theories interest. can compare simulated networks observed network generate perspectives plausibility theory. Essentially, ERGMs help us determine local tendencies network formation generate global properties structures networks.many ways, ERGMs similar logistic regression models predict presence absence ties pairs nodes edge formation modeled dependent network structure properties (e.g., density, transitivity, centralization, etc.). models help us assess probability observed network product specified properties generative processes may less likely occur expect chance random network.details ERGMs underlying mathematics beyond scope document, present brief overview highlights based heavily workshop ERGM statnet team (Krivitsky et al. 2021). See workshop details.general model form ERGM can written :\\[P(Y=y) = \\frac{\\text{exp}(\\theta' g(y))}{k(\\theta)}\\]\\(P(Y=y)\\) probability network take given state \\(y\\) among random possibilities \\(Y\\).\\(g(y)\\) set model ERGM terms considered. essential covariates model.\\(\\theta\\) set coefficients model terms.\\(k(\\theta)\\) normalizing constant defined numerator summed overall possible networks constrained node set \\(y\\). words, possible network configurations exist given node set.general form ERGM expressed terms entire network see can also expressed terms conditional log odds edge existing two nodes follows:\\[\\text{logit}(Y_{ij}=y_{ij}) = \\theta'\\delta(y_{ij})\\]\\(Y_{ij}\\) random variable state edge (present absent) given pair nodes \\(\\) \\(j\\) \\(y_{ij}\\) observed state.\\(\\delta (y_{ij})\\) change statistic representing \\(g(y)\\) (state graph associated terms) changes edge \\(\\) \\(j\\) active .\\(\\theta\\) describes contribution term log odds individual edge \\(\\) \\(j\\) conditioned state edges remaining (explain detail examples).coefficient estimates ERGM models returned log odds indicates change likelihood edge per unit change given predictor (“change statistic”) comes . example coefficient estimate \\(\\theta\\) 1.5 given term indicate likelihood edge 1.5 times higher every change term 1 unit. Conversely, coefficient estimate term -5.5 suggest likelihood edge 5.5 times less likely every unit change term. general, positive coefficients suggest given network feature denoted term common expect chance negative value suggests less common expect chance (given constraints placed network construction). magnitude coefficients provides indication much fewer given features see expect. explain works detail examples .\nlog odds logarithm odds ratio. odds ratio\nrefers probability event occurs divided \nprobability event occur (1 minus probability \noccurs). can written formally :\n\n\\(\\text{log}() = \\text{log} \\frac{(P())}{(1-P())}\\)\n\n\n\n\\(\\text{log}()\\) log odds\nevent \n\n\\((P())\\) probability \nevent occurring\n\n\\((1-(P())\\) probability \nevent occurring\n\nNegative log odds values indicate probability event\noccurring < 0.5 positive log odds values indicate \nprobability event occurring > 0.5. Log odds exactly\n0 probability event occurring 0.5.\n","code":""},{"path":"ERGM.html","id":"ERGMsInR","chapter":"Section 8 Exponential Random Graph Models","heading":"8.1 ERGMs in R","text":"general, analysis ERGMs R conducted three basic steps:First, asses general properties interest network using exploratory network statistics described Exploratory Network Analysis section document.Next, define network terms interest fit one ERGMs observed network assess results.Finally, assess goodness fit models assess diagnostic statistics model generating processes.goes well steps , can evaluate network theory property interest relation ERGM created.\nstatnet suite packages includes package called\nergm facilitates analysis ERGMs R \nadditional package called tergm provides terms \nmethods analyzing temporal networks using ERGMs. Networks need \nnetwork format analysed using \nstatnet suite packages.\nLet’s initialize statnet suite get started:many ways easiest describe ERGMs work example. next sections provide couple archaeological examples highlight ways ERGMs used archaeology. provide additional resources taking methods .","code":"\nlibrary(statnet) # initialize statnet library"},{"path":"ERGM.html","id":"CranborneChase","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2 Cranborne Chase Visibility Network Example","text":"start example described briefly Brughmans Peeples (2023) book Chapter 4, covered detail. Specifically, explore potential generative processes involved development intervisibility network among long barrows Cranborne Chase area southern England. example briefly described Brughmans Peeples (2023) book, may also want read follow along original article analyses first appeared (Brughmans Brandes 2017).Briefly, network consists set nodes represent long barrows edges among represent ground-truthed ties intervisbility pairs barrows. original data came work Chris Tilley (1994). data used Brughmans Brandes (2017) formally test notion put forth Tilley highly visible barrows “attracted” others time. network terms characterized “preferential attachment” process. Brughmans Brandes created ERGM model particular properties drawn Tilley’s theoretical model network development found networks simulated properties using ERGMs substantially similar properties observed network. Based , considered Tilley’s theoretical model plausible.original ERGM analysis published Brughmans Brandes conducted Java program designed ERGM analysis called PNet. replicate results additional analyses using slightly different methods assumptions R way demonstration. results differ slightly published results randomness inherent fitting ERGMs coefficient retain sign magnitude suggesting good replication important results.","code":""},{"path":"ERGM.html","id":"NetProperties","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2.1 Assessments of Network Properties","text":"Let’s start bringing Cranborne Chase network data (network object) looking general properties network object. follow along can download data clicking .network undirected, unweighted network object 32 nodes 49 edges. Let’s look properties network including density, mean degree, degree centralization, number isolates.fairly sparse network isolates low degree centralization.Let’s plot nodes scaled degree:network 3 components isolates. general many nodes similar degree centrality values nodes appear higher degree. can look histogram degree centrality assess distribution.","code":"\nload(\"data/cranborne.Rdata\")\ncranborne##  Network attributes:\n##   vertices = 32 \n##   directed = FALSE \n##   hyper = FALSE \n##   loops = FALSE \n##   multiple = FALSE \n##   bipartite = FALSE \n##   total edges= 49 \n##     missing edges= 0 \n##     non-missing edges= 49 \n## \n##  Vertex attribute names: \n##     vertex.names \n## \n## No edge attributes\nsna::gden(cranborne) # density## [1] 0.09879032\nmean(sna::degree(cranborne)) # mean degree## [1] 6.125\nsna::centralization(cranborne, g = 1, degree) # degree centralization## [1] 0.2043011\nlength(sna::isolates(cranborne)) # number of isolates## [1] 3\nset.seed(4367)\nplot(cranborne, vertex.cex = (sna::degree(cranborne) / 4) + 1)\nhist(sna::degree(cranborne),\n     breaks = 10,\n     main = \"Degree Distribution\",\n     xlab = \"Degree Centrality\")"},{"path":"ERGM.html","id":"fitting-models-with-ergm","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2.2 Fitting Models with ergm","text":"Now ’ve explored basic properties network, next step begin fit ERGMs observed network. first thing going fit simple model one term. ergm package “terms” refer specific constraints placed randomly generated networks (see ?ergm.terms list many built-terms). basic term included many models edges simply refers number edges network. ERGM single edges term conceptually equivalent typical GLM regression model predictor intercept.chunk code see form ergm model objects take R. Inside ergm call network left hand size cranborne followed ~ followed edges built-“term” ergm package. see , use multiple terms separate +. crated ergm model object explore output using summary() function.output number important features need explanation.summary output includes call/model formula used followed Maximum Likelihood Results. output focus includes estimates model term, standard error estimates, p-value associated term:First, example , get estimate edges -2.2107 conditional log odds two nodes edge (explained )Next, standard error coefficient estimate.also “Pr(>|z|) p-value associated particular term. p-value calculated function relative size coefficient estimate standard error.estimate (associated standard error p-value) indicates much change term one unit changes likelihood particular edge present. case, change one unit term edges refers addition exactly 1 edge network (\\(\\delta(g(y)) = 1\\)) coefficient estimate much addition 1 edge network changes likelihood particular edge:\\[\\begin{aligned}\n\\text{logit}(p(y)) & = \\theta \\times \\delta(g(y))\\\\\n& = -2.2107 \\times \\text{change number edges}\\\\\n& = -2.2107 \\times 1\\\\\n& = -2.2107\n\\end{aligned}\\]example, likelihood edge two particular nodes 2.2107 times less likely every additional increase number network 1 edge network whole. every edge added probability particular edge present decreases. negative coefficient means edge likely absent present (positive coefficient suggest opposite) thus, add edge elsewhere network even less likely target edge active. can calculate probability edge present taking inverse logit \\(\\theta\\):expect, number close density network edges term uses constraint (number edges function density):indicates trying predict given network state (given set present absent edges) information know network density, probability particular edge present roughly equal network density. coefficient statistically significant, means low probability (p-value) obtaining model terms random provides good better predictions observed model including edges term.Finally can see model fit statistics bottom AIC (Akaike Information Criterion) BIC (Bayesian Information Criterion). model fit statistics can used compare competing models lower values represent better fit model data. , Null deviance measure well network predicted model covariates vs. residual deviance measure well network predicted model covariates. Residual deviance lower Null deviance bigger gap two better. general, absolute values model fit terms matter rather provide means comparing multiple models predicting observations see .","code":"\nmod_null <- ergm(cranborne ~ edges)\nsummary(mod_null)## Call:\n## ergm(formula = cranborne ~ edges)\n## \n## Maximum Likelihood Results:\n## \n##       Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges  -2.2107     0.1505      0  -14.69   <1e-04 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 319.8  on 495  degrees of freedom\n##  \n## AIC: 321.8  BIC: 326  (Smaller is better. MC Std. Err. = 0)\nexp(-2.2107) / (1 + exp(-2.2107))## [1] 0.09879373\nsna::gden(cranborne)## [1] 0.09879032"},{"path":"ERGM.html","id":"ModelTheory","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2.3 Building a Model Based on Theory","text":"simple example built ERGM predicated nothing network density using edges term. outlined Brughmans Brandes (2017) specific features Cranborne Chase network development process theorized Tilley converted formal ERGM model using specific ergm.terms. Specifically, Tilley suggested long barrows tended clustered groups intervisibility primary concern , long barrows. , suggested long barrows tended clustered sets include straight paths multiple barrows visible single point. Finally, Tilley suggested barrows already highly visible tended attract new visibility connections time. capture theory network development formal terms, Brughmans Brandes (2017) create set terms match Tilley’s expectations. include following terms:edges - number active edges: term represents tendency long barrows visibility connections.triangle - number closed triangles: term represents clustering Tilley expects network networks many closed triangles often distinct clusters.threetrail - number paths trails 3 (threepath threetrail used equivalently ergm ) network: term meant capture Tilley’s visual pathways multiple barrows visible specific direction.altkstar - alternating stars: term used represent certain nodes high degree distribution representing prominent nodes network generated process preferential attachment.isolates - number isolates network: term capture tendency nodes isolate Tilley describes.visual representations network configurations Brughmans Brandes (2017):Brughmans Brandes present two versions model article. first excludes isolates term second includes . Let’s replicate results . Note using different software terms may defined slightly differently results may differ bit published results. , ERGMs include random simulation two runs model return results unless supply random seed. ergm call use control argument see .Let’s first go included terms. want first create model terms edges, triangle, threetrail, altkstar. terms can used without arguments altkstar term needs additional weight parameter lambda us define weight parameter fixed (see term descriptions details).\nERGMs can sometimes take quite bit time run involve\ngenerating lots estimates random variables using MCMC process.\norder control behavior MCMC sampling process, can\nuse control argument within ergm\nfunction. examples opted fairly large sample\nsize per chain relatively large interval samples. \nsee , help coefficient estimates\nmodel fit trade time. want simply run \nmodels examples quickly, simply remove three\narguments within control.ergm function call:\nMCMC.burnin, MCMC.interval, \nMCMC.samplesize.\nLet’s fit model look summary. Note run computer see additional verbose output console sampling process proceeds. eliminated avoid visual clutter:results show, three significant predictors: edges, triangle, threetrail altkstar significant (\\(\\alpha = 0.05\\)) just Brughmans Brandes (2017) found. Looking coefficients, negative edges term suggests edges likely absent present model expect given density. triangle positive coefficient suggesting triangles likely expect chance. Finally, threetrails slightly less common expect random network. difference small statistically significant.Brughmans Brandes (2017) generated similar results assessments goodness fit model (see discussion ) caused create second model additional term capture tendency nodes connected nodes (thus isolates).Let’s run second model look results:model obtain results mirror Brughmans Brandes (2017). see edges term tendency edges absent expect. triangle see strong tendency closed triangles network Tilley’s model predicted. however see tendency towards visual pathways beyond expect chance threetrail term suggests slight tendency away configurations. addition isolates term altkstar term significant positive suggesting tendency nodes higher degree . Finally, isolates negative suggesting tendency isolated nodes p-value bit higher put much interpretive weight coefficient estimate.","code":"\nmod1 <- ergm(\n  cranborne ~ edges + triangle + threetrail +\n    altkstar(lambda = 2, fixed = TRUE),\n  control = control.ergm(\n    MCMC.burnin = 1000,\n    MCMC.interval = 15000,\n    MCMC.samplesize = 25000,\n    seed = 34526\n  )\n)\nsummary(mod1)## Call:\n## ergm(formula = cranborne ~ edges + triangle + threetrail + altkstar(lambda = 2, \n##     fixed = TRUE), control = control.ergm(MCMC.burnin = 1000, \n##     MCMC.interval = 15000, MCMC.samplesize = 25000, seed = 34526))\n## \n## Monte Carlo Maximum Likelihood Results:\n## \n##            Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges      -3.74166    0.91423      0  -4.093   <1e-04 ***\n## triangle    1.59951    0.21921      0   7.297   <1e-04 ***\n## threetrail -0.04077    0.01622      0  -2.513    0.012 *  \n## altkstar.2  0.59694    0.39283      0   1.520    0.129    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 286.0  on 492  degrees of freedom\n##  \n## AIC: 294  BIC: 310.8  (Smaller is better. MC Std. Err. = 0.08471)\nmod2 <- ergm(\n  cranborne ~ edges + triangle + threetrail +\n    altkstar(2, fixed = TRUE) + isolates,\n  control = control.ergm(\n    MCMC.burnin = 1000,\n    MCMC.interval = 15000,\n    MCMC.samplesize = 25000,\n    seed = 1346\n  )\n)\nsummary(mod2)## Call:\n## ergm(formula = cranborne ~ edges + triangle + threetrail + altkstar(2, \n##     fixed = TRUE) + isolates, control = control.ergm(MCMC.burnin = 1000, \n##     MCMC.interval = 15000, MCMC.samplesize = 25000, seed = 1346))\n## \n## Monte Carlo Maximum Likelihood Results:\n## \n##            Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges      -7.60337    2.69813      0  -2.818  0.00483 ** \n## triangle    1.62452    0.20215      0   8.036  < 1e-04 ***\n## threetrail -0.05946    0.02256      0  -2.635  0.00841 ** \n## altkstar.2  1.92114    0.98390      0   1.953  0.05087 .  \n## isolates   -2.57763    1.61226      0  -1.599  0.10987    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 283.4  on 491  degrees of freedom\n##  \n## AIC: 293.4  BIC: 314.4  (Smaller is better. MC Std. Err. = 0.04119)"},{"path":"ERGM.html","id":"GOF","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2.4 Assessing Goodness-of-Fit","text":"compare model fit statistics can see AIC model 2 slightly lower model 1. , difference Null residual deviance slightly greater model 2. time, BIC model 2 slightly higher model 1. Overall suggests two models quite similar terms improvement model predictors don’t strong statistical argument terms alone picking one (thus probably makes sense evaluate fit statistics show theoretical arguments preferring one model ).take can use gof goodness--fit function ergm assess degree models provide reasonable descriptions observations. can start running gof function models. function provides visualizations statistics help assess degree model statistics, node degree, edge-wise shared partners, geodesic distance nodes preserved networks simulated ERGM. run function directed network, additionally get assessments -degree -degree.summary output model shows observed feature value given term min, max, mean value simulated networks. general, want mean values match closely relatively small ranges around . MC p-value (Markov Chain p-value) provides indication fit higher numbers generally indicate better fit. essentially proportion steps chain given term met certain criteria. general results suggest model terms generally provide better fit model 2 model 1 (Brughmans Brandes also suggested using somewhat different goodness--fit statistics directly calculated ergm).also instructive compare properties randomly generated networks model observed network properties weren’t directly included model. gof function can plotted directly provide information. Let’s look four plots provided models:plots solid black line represents values given property observed network box plots represent distribution values obtained randomly generated networks. plots show median model statistics quite similar observed models. general want see observed values fall within densest portion values randomly generated networks (.e., near middle box plots certainly within range). example , observed degree distribution edge-wise shared partners (number nodes specific number partners) quite similar simulated range values. Importantly, include terms degree edge-wise shared partners model still generated networks closely match observed terms properties. evidence good fit. minimum geodesic distance (length shortest paths) however, see models consistently -estimated geodesic distance nodes middling values. Overall, suggests fairly good (perfect) match simulated observed network properties despite properties directly included models. Importantly, interpretation network doesn’t hinge geodesic distance mismatch huge problem. model perfect results suggest model tested least approximates features observed network relevant theoretical model.","code":"\nmod1_gof <- gof(mod1)\nmod2_gof <- gof(mod2)\n\nmod1_gof$summary.model##                 obs    min     mean       max MC p-value\n## edges       49.0000  32.00  49.9100   74.0000       1.00\n## triangle    22.0000   5.00  24.2100  143.0000       0.80\n## threetrail 628.0000 224.00 689.5200 3028.0000       0.80\n## altkstar.2 102.7891  59.25 106.3128  206.5781       0.98\nmod2_gof$summary.model##                 obs     min    mean       max MC p-value\n## edges       49.0000  31.000  50.140   63.0000       0.86\n## triangle    22.0000   5.000  22.590   76.0000       0.84\n## threetrail 628.0000 226.000 654.230 1568.0000       0.98\n## altkstar.2 102.7891  58.875 106.187  150.7266       0.86\n## isolates     3.0000   0.000   2.780   11.0000       0.98\npar(mfrow = c(2, 2))\nplot(mod1_gof)\nplot(mod2_gof)"},{"path":"ERGM.html","id":"Diagnostics","chapter":"Section 8 Exponential Random Graph Models","heading":"8.2.5 Assessing Models and MCMC Diagnostics","text":"Another important consideration yet discussed need assess diagnostics model generating process evaluate operated expected. ergm package generates random networks using Markov Chain Monte Carlo (MCMC) process. MCMC means efficiently randomly sampling high-dimensional probability distribution. want ensure MCMC process explores parameter space fully generate problematic data temporally correlated estimates highly skewed distributions coefficient estimates. Problems like indication poor model specification (inappropriate inclusion exclusion relevant terms predicting network).order assess models, can use mcmc.diagnostics function. run model 2 look results. also call latticeExtra package helps make visual output look bit better.output particularly relevant parts include:sample statistic auto-correlation - measure correlation values MCMC chain term across number steps (lags) indicated. Ideally, want see low values Lag 0 example looks good respect.sample statistic burn-diagnostic (Geweke) - Burn-refers number points calculated MCMC starts recording points included coefficient estimates. burn-helps deal “start effects” can sometimes appear poor initial estimate parameter. Geweke statistics actually want obtain p-values close 1 , example satisfies.MCMC plots - plots presented show two plots term. plot left called trace plot displays every retained value MCMC sampling chain included estimate. plot, want see values roughly even distributions 0 obvious trends. second plot shows density estimates term simple density plot. want see roughly bell-shaped curves centered close 0, indicates good convergence model. example terms look good though triangle slightly skewed. particularly egregious working model make specific argument triangle term might choose run much longer MCMC chain improve fit. complex models may take many hours often good idea run initial models set longer runs overnight using computer.\nexample noted terms appeared look\ngood model diagnostics though term triangle\nproduced slightly skewed distribution long-tail randomly\ngenerated networks closed triangles mean \nobserved. might ?\n\nAlthough often interested transitivity properties\nnetworks rely triangles, number closed triads \nnetwork actually highly constrained lower-level features\nalready included model: specifically number nodes \ndensity. considerable experimental work demonstrates \nmajority variation triad configurations can explained\ntwo simple terms many networks (see Faust 2007, 2008, 2010).\ninclusion related terms can confound MCMC algorithm\ndesigned generate estimates model parameters sometimes lead \nexploration unlikely parameter combinations. uncommon\nERGM terms include dyadic triadic relationships. \nsection discuss model degeneracy\n(refers models fail converge) can done\n, including alternatives triangle model\nterm.\n","code":"\nlibrary(latticeExtra)\nmcmc.diagnostics(mod2)## Sample statistics summary:\n## \n## Iterations = 4691250:93750000\n## Thinning interval = 3750 \n## Number of chains = 1 \n## Sample size per chain = 23750 \n## \n## 1. Empirical mean and standard deviation for each variable,\n##    plus standard error of the mean:\n## \n##                 Mean      SD Naive SE Time-series SE\n## edges       0.588884   7.270  0.04717        0.05341\n## triangle    2.057432  13.549  0.08792        0.12730\n## threetrail 39.252379 277.517  1.80077        2.37599\n## altkstar.2  2.187350  23.019  0.14936        0.17658\n## isolates    0.002484   1.797  0.01166        0.01166\n## \n## 2. Quantiles for each variable:\n## \n##               2.5%     25%    50%    75%  97.5%\n## edges       -14.00   -4.00  1.000   5.00  15.00\n## triangle    -15.00   -7.00 -1.000   8.00  37.00\n## threetrail -385.00 -154.00  0.000 187.00 699.55\n## altkstar.2  -40.91  -13.45  1.492  17.15  49.18\n## isolates     -3.00   -1.00  0.000   1.00   4.00\n## \n## \n## Are sample statistics significantly different from observed?\n##                   edges     triangle   threetrail   altkstar.2    isolates\n## diff.      5.888842e-01 2.057432e+00 3.925238e+01 2.187350e+00 0.002484211\n## test stat. 1.102595e+01 1.616264e+01 1.652041e+01 1.238741e+01 0.213042093\n## P-val.     2.864748e-28 9.250718e-59 2.616016e-61 3.057549e-35 0.831294131\n##            Overall (Chi^2)\n## diff.                   NA\n## test stat.    4.955497e+02\n## P-val.       1.409253e-103\n## \n## Sample statistics cross-correlations:\n##                 edges    triangle threetrail altkstar.2    isolates\n## edges       1.0000000  0.70006251  0.8524932  0.9819884 -0.46616202\n## triangle    0.7000625  1.00000000  0.9173600  0.7880199 -0.00547061\n## threetrail  0.8524932  0.91736005  1.0000000  0.9235087 -0.12593569\n## altkstar.2  0.9819884  0.78801991  0.9235087  1.0000000 -0.31447708\n## isolates   -0.4661620 -0.00547061 -0.1259357 -0.3144771  1.00000000\n## \n## Sample statistics auto-correlation:\n## Chain 1 \n##                 edges   triangle threetrail  altkstar.2      isolates\n## Lag 0     1.000000000 1.00000000 1.00000000 1.000000000  1.0000000000\n## Lag 3750  0.085340699 0.31786885 0.21199338 0.117841859  0.0073520339\n## Lag 7500  0.033623075 0.13767396 0.09207368 0.048711928 -0.0041480619\n## Lag 11250 0.016956139 0.05867687 0.04091841 0.023084030  0.0009372223\n## Lag 15000 0.007187236 0.03343025 0.02176044 0.011433312 -0.0033657854\n## Lag 18750 0.002499737 0.01580210 0.01242620 0.004931155 -0.0080207497\n## \n## Sample statistics burn-in diagnostic (Geweke):\n## Chain 1 \n## \n## Fraction in 1st window = 0.1\n## Fraction in 2nd window = 0.5 \n## \n##      edges   triangle threetrail altkstar.2   isolates \n##    0.41483    1.28439    1.17775    0.67169   -0.01661 \n## \n## Individual P-values (lower = worse):\n##      edges   triangle threetrail altkstar.2   isolates \n##  0.6782670  0.1990056  0.2388968  0.5017826  0.9867500 \n## Joint P-value (lower = worse):  0.0832968 .## \n## MCMC diagnostics shown here are from the last round of simulation, prior to computation of final parameter estimates. Because the final estimates are refinements of those used for this simulation run, these diagnostics may understate model performance. To directly assess the performance of the final model on in-model statistics, please use the GOF command: gof(ergmFitObject, GOF=~model)."},{"path":"ERGM.html","id":"SimERGMs","chapter":"Section 8 Exponential Random Graph Models","heading":"8.3 Simulating Networks from ERGMs","text":"possible generate explore network simulated using particular ERGM using simulate function. Let’s generate random networks model 2 used look along original network.code simply run single simulate function model object, argument nsim representing number networks wish generate, seed random seed reproducability. output list() object containing multiple network format objects.simulations help us better understand model created. obvious similarities original network simulations also key differences. particular, random simulations created networks single large component whereas original network multiple components. likely explains mismatch goodness--fit statistics geodesic distance. perhaps deal including additional terms terms defined relation geographic location clustering, experiment another day.","code":"\nsim_nets <- simulate(mod2, nsim = 9, seed = 3464524)\n\npar(mfrow = c(3, 3)) # set up for multipanel plotting\nfor (i in 1:9) {\n  plot(sim_nets[[i]],\n       vertex.cex = (sna::degree(sim_nets[[i]]) / 4) + 1)\n}\npar(mfrow = c(1, 1)) # return to single panel\nplot(cranborne,\n     vertex.cex = (sna::degree(cranborne) / 4) + 1)"},{"path":"ERGM.html","id":"ERGMterms","chapter":"Section 8 Exponential Random Graph Models","heading":"8.4 Additional Info on ERGM Terms","text":"Cranborne Chase example , working published example hard part (thinking particular theory can conceptualized formal network model terms) done us. practice, choosing terms use can quite difficult confusing. particularly true multiple terms essentially thing different ways. section first walk common options covered provide advice go next.first example using Cibola technological similarity networks used several portions guide. data imported includes network object data frame contains attributes relating nodes network. load data assign attributes Cibola_n object. can download data follow along.attributes assign include:region - nominal regional designation node.pubarch - nominal identification type public architecture present settlement. Note model terms include NA data empty values include names like “none”d_mat - edge attribute defined distance matrix among settlements meters.many cases want use attributes nodes edges predictors ERGMs rather simply network structures. can done different ways example use nodematch term calculates coefficient nodes share values given attribute. can also set additional argument nodematch specifies coefficient unique value node attribute (diff = TRUE). Finally, use matrix geographic distances edges edgecov (edge co-variate) term. term expects square matrix n x n n number nodes network helps us assess degree distance settlements predictive presence absence edge.Let’s take look example using three terms:creates output just like example gives sense categorical co-variate ERGM terms work. example positive coefficient edges suggesting edges active . , positive coefficient nodematch.region indicating edges pairs sites region expected chance. skip edgecov.d_mat can see impact distance edges. negative coefficient (close zero: -2.323e-05)suggests slight longer distance connections shorter ones network (although tendency connections within regions also many connections regions). Finally, nodematch.pubarch variables value pubarch. term statistically significant nodematch.pubarch.none negative suggesting sites without public architecture fewer connections expect chance.examples basically cover common applications ergm terms. terms specific directed networks, weighted networks, bipartite networks, even multilayer networks basic procedures using covered examples . Everything else finding right model fit data (really hard part). magic bullet general suggest carefully read ERGM term descriptions consider different terms relate data network theories. efforts better spent model designed relation specific well-described network theory/hypothesis. suggest reading archaeological examples ERGMs cited document broader networks literature get sense possible diving ERGM project.","code":"\nload(\"data/Cibola_n.RData\")\n# Cibola_n network object\n# Cibola_attr - attribute data frame\n\n# add node attribute based on region\ncibola_n %v% \"region\" <- cibola_attr$Region\n# add node attribute based on public architecture\ncibola_n %v% \"pubarch\" <- cibola_attr$Great.Kiva\n\n# matrix of distances among settlements\nd_mat <- as.matrix(dist(cibola_attr[, 2:3]))\nmod_cibola <- ergm(cibola_n ~ edges + nodematch(\"region\") +\n                     nodematch(\"pubarch\", diff = TRUE) +\n                     edgecov(d_mat))\nsummary(mod_cibola)## Call:\n## ergm(formula = cibola_n ~ edges + nodematch(\"region\") + nodematch(\"pubarch\", \n##     diff = TRUE) + edgecov(d_mat))\n## \n## Maximum Likelihood Results:\n## \n##                                            Estimate Std. Error MCMC % z value\n## edges                                     1.196e+00  3.513e-01      0   3.405\n## nodematch.region                          1.299e+00  4.593e-01      0   2.828\n## nodematch.pubarch.Cicular Great Kiva      2.843e-01  4.439e-01      0   0.640\n## nodematch.pubarch.none                   -7.750e-01  2.763e-01      0  -2.805\n## nodematch.pubarch.Rectangular Great Kiva -6.913e-01  5.448e-01      0  -1.269\n## edgecov.d_mat                            -2.323e-05  3.847e-06      0  -6.039\n##                                          Pr(>|z|)    \n## edges                                    0.000662 ***\n## nodematch.region                         0.004688 ** \n## nodematch.pubarch.Cicular Great Kiva     0.521864    \n## nodematch.pubarch.none                   0.005026 ** \n## nodematch.pubarch.Rectangular Great Kiva 0.204441    \n## edgecov.d_mat                             < 1e-04 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 644.6  on 465  degrees of freedom\n##  Residual Deviance: 489.2  on 459  degrees of freedom\n##  \n## AIC: 501.2  BIC: 526.1  (Smaller is better. MC Std. Err. = 0)"},{"path":"ERGM.html","id":"Degeneracy","chapter":"Section 8 Exponential Random Graph Models","heading":"8.4.1 Avoiding Model Degeneracy and Poor Convergence","text":"Model degeneracy refers specified ERGM never converges. means term combination terms model created situation networks given properties can obtained. typically looks like happens R enter ergm call command line things appear going okay eventually get hung something like “Estimating equations within tolerance region. Iteration 2 60” nothing happens long time.described assessment MCMC diagnostics, can sometimes happen specified term essentially allow simulated networks approximate observed. classic example network terms edges triangle triadic closure terms.run model using Cranborne data using edges triangle term, never converge despite fact triangle term included successful model . suggests, poorly specified models just presence absence single term combination terms used.\nrun chunk code . promise, doesn’t go\nanywhere just waste time.\n, can place including terms cause model degeneracy? Luckily number additional terms designed deal exactly issue. include “geometrically weighted” terms already built right ergm package. example, term gwesp geometrically weighted shared partners measure triadic closure doesn’t rely specific count triangles, instead tendency towards closing individual triads network.Let’s try model substituting gwesp term place triangle.model converges get gwesp statistically significant predictor positive coefficient estimate just saw triangle complete model. Indeed include gwesp complete model get results largely mirror suggesting term playing similar role.numbers ’re providing gwesp term argument (0.25, fixed = TRUE). number specify -called decay parameter model whether parameter fixed allowed vary across steps MCMC process. details well beyond scope tutorial suffice say general advice select decay value produces best fit model given analysis. run model without fixed = TRUE model attempt estimate decay parameter get additional result output specifies coefficient decay term well. Keep mind essentially adding term model may harder take longer fit models.example:addition gwesp term, many additional terms listed fill similar roles help build models avoid degeneracy. information see Hunter Handcock (2006).","code":"\nmod_fail <- ergm(cranborne ~ edges + triangle)\nmod_win <- ergm(cranborne ~ edges + gwesp(0.25, fixed = TRUE),\n                control = control.ergm(seed = 2362))\nsummary(mod_win)## Call:\n## ergm(formula = cranborne ~ edges + gwesp(0.25, fixed = TRUE), \n##     control = control.ergm(seed = 2362))\n## \n## Monte Carlo Maximum Likelihood Results:\n## \n##                  Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges             -3.4856     0.3307      0 -10.539   <1e-04 ***\n## gwesp.fixed.0.25   1.1627     0.2596      0   4.479   <1e-04 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 289.1  on 494  degrees of freedom\n##  \n## AIC: 293.1  BIC: 301.5  (Smaller is better. MC Std. Err. = 0.2945)\nmod_win2 <-\n  ergm(\n    cranborne ~ edges + gwesp(0.25, fixed = TRUE) + threetrail +\n      altkstar(2, fixed = TRUE) + isolates,\n    control = control.ergm(seed = 1346)\n  )\nsummary(mod_win2)## Call:\n## ergm(formula = cranborne ~ edges + gwesp(0.25, fixed = TRUE) + \n##     threetrail + altkstar(2, fixed = TRUE) + isolates, control = control.ergm(seed = 1346))\n## \n## Monte Carlo Maximum Likelihood Results:\n## \n##                  Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges            -9.04117    3.36219      0  -2.689  0.00717 ** \n## gwesp.fixed.0.25  1.51929    0.36396      0   4.174  < 1e-04 ***\n## threetrail       -0.03945    0.02866      0  -1.376  0.16874    \n## altkstar.2        1.91799    1.22533      0   1.565  0.11752    \n## isolates         -3.58093    1.88523      0  -1.899  0.05750 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 284.6  on 491  degrees of freedom\n##  \n## AIC: 294.6  BIC: 315.6  (Smaller is better. MC Std. Err. = 0.4782)\nmod_nofix <- ergm(cranborne ~ edges + gwesp,\n                  control = control.ergm(seed = 23642))\nsummary(mod_nofix)## Call:\n## ergm(formula = cranborne ~ edges + gwesp, control = control.ergm(seed = 23642))\n## \n## Monte Carlo Maximum Likelihood Results:\n## \n##             Estimate Std. Error MCMC % z value Pr(>|z|)    \n## edges        -3.3989     0.3120      0 -10.892  < 1e-04 ***\n## gwesp         0.9357     0.2915      0   3.210  0.00133 ** \n## gwesp.decay   0.5738     0.3125      0   1.836  0.06636 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##      Null Deviance: 687.6  on 496  degrees of freedom\n##  Residual Deviance: 288.2  on 493  degrees of freedom\n##  \n## AIC: 294.2  BIC: 306.8  (Smaller is better. MC Std. Err. = 0.3811)"},{"path":"SpatialInteraction.html","id":"SpatialInteraction","chapter":"Section 9 Spatial Interaction Models","heading":"Section 9 Spatial Interaction Models","text":"Spatial Networks section document cover simple network models generating spatial networks based absolute distance, configurations locations, territories. one general class spatial network model described briefly Brughmans Peeples (2023) book cover detail specifics require considerably discussion. includes wide variety spatial interaction models gravity models, truncated power functions, radiation models, similar custom derivations approaches. general, spatial interaction model formal mathematical model used predict movement people (sorts entities) origins destinations. models typically use information relative sizes “attractiveness” origins destinations additional information volumes flows . models long popular geography, economics, fields things like predicting amount trade cities nations predicting improving location services given geographic extent. Statistical spatial interaction models used archaeology well empirical simulation studies (e.g., Bevan Wilson 2013; Evans et al. 2011; Gauthier 2020; Paliou Bevan 2016; Rihll Wilson 1987) though nearly impact fields. suggest considerable potential models, particular contexts independent information evaluating network flows across study area.section, briefly outline common spatial interaction models provide examples. additional detailed overview examples models several useful publications (see Evans et al. 2011; Rivers et al. 2011; Amati et al. 2018).","code":""},{"path":"SpatialInteraction.html","id":"GravityModel","chapter":"Section 9 Spatial Interaction Models","heading":"9.1 Simple Gravity Models","text":"’ll start simple gravity model. model built notion “mass” population different origins destinations creates attractive forces influenced space travel costs . model takes many forms simplest can written :\\[x_{ij} = cv_iv_jf(d_{ij})\\]\\(x_{ij}\\) number strength connection nodes \\(\\) \\(j\\)\\(c\\) proportionality constant (gravitational constant) balances units formula. purposes can largely ignore value changes absolute values relative values nodes.\\(v_i\\) \\(v_j\\) attributes nodes \\(\\) \\(j\\) contributing “mass” (attractiveness). population resource catchment area anything factor likely influences attractiveness node terms interaction focus network.\\(f(d_{ij})\\) cost “deterrence” function defining travel costs \\(\\) \\(j\\). Frequently, cost function specified using inverse power law exponential decay functions defined respectively equations :\\[f(d_{ij}) = \\frac{1}{(1+\\beta d{ij})^\\gamma} \\text{   } f(d_{ij}) = \\frac{1}{e^{\\beta d{ij}}}\\]\\(\\beta\\) scaling factor models sand \\(\\gamma\\) determines weight tail power law distribution.numerous different configurations simple gravity model literature. versions add exponents \\(V_i\\) \\(V_j\\) vary importance inflow outflow independently, versions use different derivations deterrence, many define inflows outflows using different sources empirical information additional terms scale units. Calculating models like relatively easy determining parameterize models typically hard part discuss .order demonstrate simple gravity models, ’re going use regional data set Late Intermediate periods Wankarani sites Bolivian Altiplano provided online Comparative Archaeology Database University Pittsburgh (McAndrews 2005). details database variables described link provided. data set variables use provides good example explore includes location size information sites.First, let’s read data create quick plot showing site locations points scaled site area (measure potential attractiveness outflow potential). select sites dating Late Intermediate period analysis. limit consideration habitation sites. Download data follow along download base map .plot shows, one site considerably larger others clusters large sites eastern portion study area.Now ’re going build small function called grav_mod includes 3 arguments:attract measure settlement attractiveness network. example use area measure attractiveness sending receiving site, though can varied.B \\(\\beta\\) parameter exponential decay cost function outlined .d matrix distances among nodes. Note something physical distance like travel time well. helps units don’t result large numbers keep output manageable (though actual absolute numbers don’t matter)Now let’s try example using Wankarani data. first example set B 1. ’ll take look results first, creating heat map gravity model every pair nodes using superheat package. plot site size estimated flow model axes transformed base-10 logarithms see variables relate. use packages scales provide exponential notation axis labels.plots illustrate, clusters estimated flows among nodes, surprising given sites form clusters. , plot comparing area flow shows roughly positive linear relationship two also variation nodes less flow expected based distance alone.Next, let’s plot network showing connections scaled colored based strength terms estimated flow nodes scaled based weighted degree (total volume flow incident node). blue colored ties weaker yellow colored ties stronger. sake visual clarity omit 25% weakest edges.plot shows, areas characterized higher lower flow throughout study area. largest site study area (shown first map ) characterized high weighted degree smaller sites also high weighted degree, especially eastern half study area.Let’s now take look data , time set B \\(\\beta\\) 0.1.lower B \\(\\beta\\) parameter get stronger linear relationship site area flow. , look network, see even degree distribution (though still nodes higher degree) distributed edge weights across network, though high values still. concentrated eastern cluster.","code":"\nwankarani <- read.csv(\"data/Wankarani_siteinfo.csv\")\nwankarani <- wankarani[which(wankarani$Period == \"Late Intermediate\"), ]\nwankarani <- wankarani[which(wankarani$Type == \"habitation\"), ]\nload(\"data/bolivia.Rdata\")\n\nlibrary(ggmap)\nlibrary(sf)\n\n# Convert attribute location data to sf coordinates and change\n# map projection\nlocations_sf <-\n  st_as_sf(wankarani, coords = c(\"Easting\", \"Northing\"), crs = 32721)\nloc_trans <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(loc_trans)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n\n# Plot original data on map\nggmap(base_bolivia, darken = 0.35) +\n  geom_point(\n    data = xy,\n    aes(x, y, size = wankarani$Area),\n    color = \"red\",\n    alpha = 0.8,\n    show.legend = FALSE\n  ) +\n  theme_void()\ngrav_mod <- function(attract, B, d) {\n  res <- matrix(0, length(attract), length(attract))\n  \n  for (i in seq_len(length(attract))) {\n    for (j in seq_len(length(attract))) {\n      res[i, j] <-\n        attract[i] * attract[j] * exp(-B * d[i,j])\n    }\n  }\n  diag(res) <- 0\n  return(res)\n}\n# First calculate a distance matrix. We divide by\n# 1000 so results are in kilometers.\nd_mat <- as.matrix(dist(wankarani[, 5:6])) / 1000\n\ntest1 <-\n  grav_mod(attract = wankarani$Area,\n           B = 1,\n           d = d_mat)\n\nlibrary(superheat)\nsuperheat(test1)\nlibrary(scales)\ndf <- data.frame(Flow = rowSums(test1), Area = wankarani$Area)\n\nggplot(data = df) +\n  geom_point(aes(x = Area, y = Flow)) +\n  scale_x_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  scale_y_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  theme_bw()\nlibrary(statnet)##                Installed ReposVer Built  \n## ergm           \"4.3.2\"   \"4.4.0\"  \"4.2.2\"\n## network        \"1.18.0\"  \"1.18.1\" \"4.2.2\"\n## networkDynamic \"0.11.2\"  \"0.11.3\" \"4.2.0\"\n## sna            \"2.7\"     \"2.7-1\"  \"4.2.1\"\n## statnet.common \"4.7.0\"   \"4.8.0\"  \"4.2.1\"\nlibrary(igraph)\nlibrary(ggraph)\n\nsel_edges <- event2dichot(test1, method = \"quantile\", thresh = 0.25)\ntest1_plot <- test1 * sel_edges\n\nnet <-\n  graph_from_adjacency_matrix(test1_plot, mode = \"undirected\",\n                              weighted = TRUE)\n\n# Extract edge list from network object\nedgelist <- get.edgelist(net)\n\n# Create data frame of beginning and ending points of edges\nedges <- data.frame(xy[edgelist[, 1], ], xy[edgelist[, 2], ])\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Calculate weighted degree\ndg_grav <- rowSums(test1) / 10000\n\n# Plot data on map\nggmap(base_bolivia, darken = 0.35) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2,\n      col = log(E(net)$weight),\n      alpha = log(E(net)$weight)),\n      show.legend = FALSE\n    ) +\n  scale_alpha_continuous(range = c(0, 0.5)) +\n  scale_color_viridis() +\n  geom_point(\n    data = xy,\n    aes(x, y, size = dg_grav),\n    alpha = 0.8,\n    color = \"red\",\n    show.legend = FALSE\n  ) +\n  theme_void() \n# First calculate a distance matrix. We divide by\n# 1000 so results are in kilometers.\nd_mat <- as.matrix(dist(wankarani[, 5:6])) / 1000\n\ntest2 <-\n  grav_mod(\n    attract = wankarani$Area,\n    B = 0.1,\n    d = d_mat\n  )\n\nsuperheat(test2)\ndf <- data.frame(Flow = rowSums(test2), Area = wankarani$Area)\n\nggplot(data = df) +\n  geom_point(aes(x = Area, y = Flow)) +\n  scale_x_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  scale_y_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  theme_bw()\nsel_edges <- event2dichot(test2, method = \"quantile\", thresh = 0.25)\ntest2_plot <- test2 * sel_edges\n\nnet2 <-\n  graph_from_adjacency_matrix(test2_plot, mode = \"undirected\",\n                              weighted = TRUE)\n\n# Extract edge list from network object\nedgelist <- get.edgelist(net2)\n\n# Create data frame of beginning and ending points of edges\nedges <- data.frame(xy[edgelist[, 1], ], xy[edgelist[, 2], ])\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Calculate weighted degree\ndg <- rowSums(test2) / 10000\n\n# Plot data on map\nggmap(base_bolivia, darken = 0.35) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2,\n      col = log(E(net2)$weight),\n      alpha = log(E(net2)$weight)),\n      show.legend = FALSE\n    ) +\n  scale_alpha_continuous(range = c(0, 0.5)) +\n  scale_color_viridis() +\n  geom_point(\n    data = xy,\n    aes(x, y, size = dg),\n    alpha = 0.8,\n    color = \"red\",\n    show.legend = FALSE\n  ) +\n  theme_void() "},{"path":"SpatialInteraction.html","id":"ParameterizeGravity","chapter":"Section 9 Spatial Interaction Models","heading":"9.1.1 Parameterizing the Gravity Model","text":"simple model uses just single parameter \\(\\beta\\) largely based empirical information distance among settlements sizes. basic assumption larger sizes “attract” flow also flow provide sites. Distance also important \\(\\beta\\) parameter determines decay rate distance plot illustrates.see plot , decay rate varies different values \\(\\beta\\) also relation distance points. , select appropriate \\(\\beta\\) model like ? ways address question depending data availability nature issue networks used address. First, independent measure network flow among sites? example, perhaps take information number diversity trade wares recovered site. might expect sites greater flow higher numbers diverse trade ware assemblages. evaluate proposition using regression models determine \\(\\beta\\) provides best fit data theory. Often, however, working simple gravity models somewhat limited data make direct comparisons. possible theoretical expectation shape decay curve shown (note distances also things like cost-distance perhaps notion maximal travel times caloric budget movement) can certainly factor model. see , however, alternatives simple gravity model provide additional avenues evaluating model fit.","code":"\nbrk <- seq(0.01, 1, by = 0.01)\nout <- as.data.frame(matrix(0, length(brk), 6))\nout[, 1] <- brk\n\nfor (i in seq_len(length(brk))) {\n  out[i, 2] <- exp(-brk[i])\n  out[i, 3] <- exp(-brk[i] * 2)\n  out[i, 4] <- exp(-brk[i] * 5)\n  out[i, 5] <- exp(-brk[i] * 10)\n  out[i, 6] <- exp(-brk[i] * 20)\n}\n\ncolnames(out) <- c(\"beta\", \"D=1\", \"D=2\", \"D=5\", \"D=10\", \"D=20\")\n\nlibrary(reshape2)\ndf <- melt(out[, 2:6])\ndf$beta <- rep(brk, 5)\n\nggplot(data = df) +\n  geom_line(aes(x = beta, y = value, color = variable)) +\n  ylab(\"Decay\") +\n  xlab(expression( ~ beta)) +\n  theme_bw()"},{"path":"SpatialInteraction.html","id":"RihllWilson","chapter":"Section 9 Spatial Interaction Models","heading":"9.2 The Rihll and Wilson “Retail” Model","text":"One popular extensions gravity model archaeology published Rihll Wilson 1987 study Greek city states 9th 8th centuries B.C. used spatial interaction model sometimes called “retail” model. approach originally designed assessing likely flows resources retail shops can lead shop growth/increased income establishment small number super-centers receive large share overall available flow (often expense smaller shops). thinking model settlement context, “flows” people resources growth highly central nodes network used approximate development settlement hierarchy growth large settlement centers.One big advantages model requires locations origins destinations measure cost movement among sites. , iterative approach used model growth decline nodes based configurations cost space couple user provided parameters. Versions model used number archaeological studies (e.g., Bevan Wilson 2013; Evans Rivers 2016; Filet 2017; Rihll Wilson 1987). present version model inspired recent work scholars. code based part R function created part ISAAKiel Summer School program.Let’s first formally describe Rihll Wilson model. model interaction \\(T_{ij}\\) among set sites \\(k\\) can represented :\\[T_{ij} = \\frac{O_iW_j^\\alpha e^{-\\beta c_{ij}}}{\\Sigma_k W_k^\\alpha e^{-\\beta c_{jk}}}\\]\\(T_{ij}\\) matrix flows interaction nodes \\(\\) \\(j\\) (may may set)\\(O_i\\) estimated weight flow interaction origins \\(\\)\\(W_j\\) estimated weight flow interaction destinations \\(j\\). archaeological applications, used represent measurement settlement size.\\(\\alpha\\) parameter defines importance resource flow destinations. Numbers greater 1 essentially model increasing returns scale every unit flow.\\(e^{-\\beta c_{ij}}\\) “deterrence” function \\(e\\) exponential (\\(exp(-\\beta c_{ij})\\)), \\(c_ij\\) measure cost travel nodes \\(\\) \\(j\\) \\(\\beta\\) decay parameter describes rate decay interaction increasing distance.\\(\\Sigma_k W_k^\\alpha e^{-\\beta c_{jk}}\\) sum nodes \\(k\\) expression using \\(W_j\\), \\(\\alpha\\), deterrence function terms described .case (many archaeological examples) start simple naive assumption flow setting values \\(O\\) \\(W\\) equal 1. goal, indeed, estimate \\(W\\) nodes iteratively. order calculation \\(T_{ij}\\) calculate two new values \\(D_j\\) \\(\\Delta W_j\\) defined :\\[\\begin{aligned} D_j & = \\Sigma_i T_{ij}\\\\\n\\\\\n\\Delta W_j & = \\epsilon(D_j - KW_j) \\end{aligned}\\]\\(D_j\\) vector values defined sum weights incident given node (column sums \\(T_{ij}\\))\\(\\Delta W_j\\) change values \\(W\\) (estimated settlement size)\\(\\epsilon\\) control parameter determines quickly \\(W\\) can change iterative step.\\(K\\) factor used convert size \\(W\\) sum flows \\(D_j\\)purposes examples , set \\(K\\) 1 assume sum flows size equal units set \\(\\epsilon\\) 0.01 model converge rapidly.way example, use original Greek city states data used Rihll Wilson (1987) put online Tim Evans based work using data related spatial interaction models. Download data follow along download Greece basemap .Let’s first map Greek city states data.code , define vector initial values \\(O_i\\) \\(W_j\\) setting value 1 every site. define initial \\(\\alpha = 1.05\\) (suggest flows provide slight increasing returns) \\(\\beta = 0.1\\) (low decay rate long distance connections retain importance). code iteratively calculates values \\(T_{ij}\\) sum weights stops changing low threshold number time steps. chunk code calculate \\(T_{ij}\\) plot histogram \\(W_j\\) final state model.shows, Rihll Wilson model generates flow weights heavy tailed distribution parameters. means small number nodes receiving lots flow receiving little.order look geographically, Rihll Wilson defined call “Terminal Sites”. Terminal sites network nodes total flow inputs site \\(Wj\\) bigger largest flow site. Let’s define terminal sites model run examine .Interesting, terminal sites include many historically important larger centers (Athens, Thebes, Megara), despite fact included information size model.Now let’s map . Points scaled based weight inflow terminal sites colored blue.map illustrates, terminal sites roughly evenly distributed across study area rather clustered together. Now, let’s see happens vary parameters \\(\\alpha\\) \\(\\beta\\).next map, set \\(alpha = 1.15\\) leave \\(\\beta\\) . make easier calculate everything, ’re going call R script using source() includes full function outputs \\(W_j\\), \\(T_{ij}\\), number iterations, logical vector indicating nodes terminals.Increasing \\(\\alpha\\) increases importance inflow end fewer terminal sites. Notably, still retaining many large historically important cities despite including information site size model.Now let’s set \\(\\alpha = 1.05\\) increase \\(\\beta = 0.35\\):map illustrates, increasing \\(\\beta\\) increases distance decay meaning local interactions important leading even distribution \\(W_j\\) values terminal sites (somewhat spatially clustered).","code":"\nlibrary(sf)\nlibrary(ggmap)\nload(\"data/greece.Rdata\")\n\ndat <- read.csv(file = \"data/Rihll_Wilson.csv\")\nlocs <-\n  st_as_sf(dat,\n           coords = c(\"Longitude_E\", \"Latitude_N\"),\n           crs = 4326)\n\nggmap(map) +\n  geom_point(data = dat, aes(x = Longitude_E, y = Latitude_N)) +\n  theme_void()\n# Set model parameters and initial variable states\nOi <- rep(1, nrow(dat))\nWj <- rep(1, nrow(dat))\nalpha <- 1.05\nbeta <- 0.1\neps <- 0.01\nK <- 1\n\n# Define distance among points in kilometers. Because our\n# points are in geographic coordinates we use the distm\n# function. See the section on Spatial Networks for more.\nlibrary(geosphere)\nd <- as.matrix(distm(dat[, c(7, 6)])) / 1000\n\n# Dj is initial set as a vector of 1s like Wj\nDj <- Wj\n\n# Create objects for keeping track of the number\n# of iterations and the conditions required to end\n# the loop.\nend_condition <- 1\niter <- 0\n\n# Define the deterrence function as a exponential\ndet <- exp(-beta * d)\n\n# Create while loop that will continue to iterate Tij\n# until 10,000 iterations or until the end_condition\n# object is less than the threshold indicated.\nwhile (!(end_condition < 1e-5) & iter < 10000) {\n  # Set Wj to Dj\n  Wj <- Dj\n  # Calculate Tij as indicated above\n  Tij <-\n    apply(det * Oi %o% Wj ^ alpha, 2, '/',\n          (Wj ^ alpha %*% det))\n  # Calculate change in W using equation above\n  delta_W <- eps * (colSums(Tij) - (K * Wj))\n  \n  # Calculate new Dj\n  Dj <- delta_W + Wj\n  \n  # Add to iterator and check for end conditions\n  iter <- iter  + 1\n  end_condition <- sum((Dj - Wj) ^ 2)\n}\n\nhist(Wj, breaks = 15)\nterminal_sites <- NULL\nfor (i in 1:109) terminal_sites[i] <- sum(Tij[-i, i]) > max(Tij[i, ])\n\nknitr::kable(dat[terminal_sites,])\nggmap(map) +\n  geom_point(\n    data = dat,\n    aes(\n      x = Longitude_E,\n      y = Latitude_N,\n      size = Wj,\n      color = terminal_sites\n    ),\n    show.legend = FALSE\n  ) +\n  theme_void()\nsource(\"scripts/rihll_wilson.R\")\n\nrw2 <- rihll_wilson(alpha = 1.15, beta = 0.1, dist_mat = d)\n\nggmap(map) +\n  geom_point(\n    data = dat,\n    aes(\n      x = Longitude_E,\n      y = Latitude_N,\n      size = rw2$Wj,\n      color = rw2$terminals\n    ),\n    show.legend = FALSE\n  ) +\n  theme_void()\nknitr::kable(dat[rw2$terminals,])\nrw3 <- rihll_wilson(alpha = 1.05, beta = 0.35, dist_mat = d)\n\nggmap(map) +\n  geom_point(\n    data = dat,\n    aes(\n      x = Longitude_E,\n      y = Latitude_N,\n      size = rw3$Wj,\n      color = rw3$terminals\n    ),\n    show.legend = FALSE\n  ) +\n  theme_void()\nknitr::kable(dat[rw3$terminals,])"},{"path":"SpatialInteraction.html","id":"ParameterizingRetail","chapter":"Section 9 Spatial Interaction Models","heading":"9.2.1 Parameterizing the Retail Model","text":"might select appropriate values \\(\\alpha\\) \\(\\beta\\) model? approach Rihll Wilson many subsequent researchers taken (see Bevan Wilson 2013; Filet 2017) use knowledge archaeological record regional settlement patterns select model consistent knowledge. model creates fewer highly central nodes depending set parameters. noted , terminal nodes defined consistently include historically important large sites like Athens suggesting model likely something reasonable. One potential approach run comparisons plausible range values \\(\\alpha\\) \\(\\beta\\) evaluate relationships archaeological knowledge settlement hierarchy sites/places defined terminal sites highly central places model.order test broader range parameter values impact number terminal sites, created function takes parameters, data, distance matrix outputs just number terminals.Let’s run range plausible parameter values:\nattempt run note takes quite \ncomplete.\ncase want see data don’t want wait chunk run, created Rdata object output. Let’s load data plot heat map/tile plot:plot shows low values \\(\\alpha\\) \\(\\beta\\) tend generate networks lots terminals relationship parameters linear. Based knowledge archaeological record, make argument evaluating particular combination parameters certainly single way make decision. see expansions approach attempts deal incomplete survey data kinds considerations settlement prominence, see published example Bevan Wilson (2013).","code":"\nsource(\"scripts/terminals_by_par.R\")\n\nalpha_ls <- seq(0.90, 1.25, by = 0.01)\nbeta_ls <- seq(0.05, 0.40, by = 0.01)\n\nres <- matrix(NA, length(alpha_ls), length(beta_ls))\nrow.names(res) <- alpha_ls\ncolnames(res) <- beta_ls\n\nfor (i in seq_len(length(alpha_ls))) {\n  for (j in seq_len(length(beta_ls))) {\n    res[i, j] <-\n      terminals_by_par(\n        alpha = alpha_ls[i],\n        beta = beta_ls[j],\n        dist_mat = d\n      )\n  }\n}\nload(file = \"data/retail_pars.Rdata\")\n\nlibrary(reshape2)\nlibrary(ggraph)## Warning: package 'ggraph' was built under R version 4.2.3\nres_df <- melt(res)\n\nggplot(data = res_df) +\n  geom_tile(aes(x = Var2, y = Var1, fill = value)) +\n  scale_fill_viridis(option = \"turbo\") +\n  xlab(expression( ~ beta)) +\n  ylab(expression( ~ alpha)) +\n  theme_bw()"},{"path":"SpatialInteraction.html","id":"TruncatedPower","chapter":"Section 9 Spatial Interaction Models","heading":"9.3 Truncated Power Functions","text":"Another similar spatial interaction model used study Menze Ur (2012) exploration networks northern Mesopotamia. model quite similar simple gravity model saw couple additional parameters constraints. leave details approach published article briefly describe model . truncated power function requires information settlement location, measure size “attraction,” three parameter values. Edge interaction \\(E_{ij}\\) model can formally defined :\\[E_{ij}(\\alpha,\\beta,\\gamma) = V_i^\\gamma V_j^\\gamma d_{ij}^{-\\alpha} e^{(-d_{ij}/\\beta)}\\]\\(V\\) measure attractiveness node \\(\\) \\(j\\), typically defined terms settlement size.\\(d_{ij}\\) distance nodes \\(\\) \\(j\\). , can use measures distance simple Euclidean distances.\\(\\alpha\\) constraint distance nodes.\\(\\beta\\) physical distance across distance decay considered (defined units \\(d\\)).\\(\\gamma\\) used define importance \\(V\\) interaction values 1 suggest increasing returns scale.model output \\(E_{ij}\\) , according Menze Ur, meant approximate movement people among nodes across landscape. order evaluate function, replicate results Menze Ur paper one small change. drop bottom 50% smallest sites consideration due large sample size keep run times manageable (certainly changed code ). use replication data set provided Menze Ur online .Let’s read data, omit rows without site volume estimates, remove lowest 50% sites terms volume values. plot sites points scaled site volume. Download data follow along.implement truncated power approach rolled function called truncated_power. use values selected optimal Menze Ur (2012) paper.\nNote block takes several minutes run.\ncan now plot sites , time points scaled based total volume flow incident node.compare plot figure 8 Menze Ur (2012) see highly central sites locations suggesting ’ve reasonably approximated results even though using slightly different sample. , next plot shows, remove sites isolated sample (due us removing bottom 50% sites) also see strong linear correlation log site volume log measure interaction.go parameterizing truncated power function much way saw models (.e., testing values evaluating results archaeological pattern). Indeed Menze Ur slight twist ’ve seen far. case, lucky enough remotely sensed data actual trails among sites portion study area. selected model parameters testing range values parameters selecting set produced closest match site site network edges orientations actual observed trails (methodological details ’m glossing refer article ). illustrates, many potential ways select model parameters based empirical information.","code":"\nmesop <- read.csv(\"data/menze_ur_sites.csv\")\nmesop <- mesop[-which(is.na(mesop$volume)),]\nmesop <- mesop[which(mesop$volume > quantile(mesop$volume, 0.5)),]\n\nggplot(mesop) +\n  geom_point(aes(x = x, y = y, size = volume),\n             show.legend = FALSE) +\n  scale_size_continuous(range = c(1, 3)) +\n  theme_void()\nd <- as.matrix(dist(mesop[, 1:2])) / 1000\n\ntruncated_power <- function (V, d, a, y, B) {\n  temp <- matrix(0, nrow(d), ncol(d))\n  for (i in seq_len(nrow(d))) {\n    for (j in seq_len(ncol(d))) {\n      temp[i, j] <- V[i] ^ y * V[j] ^ y * d[i, j] ^ -a * exp(-d[i, j] / B)\n      if (temp[i, j] == Inf) {\n        temp[i, j] <- 0\n      }\n    }\n  }\n  return(temp)\n}\n\nres_mat <- truncated_power(V = mesop$volume, d = d, a = 1, y = 1, B = 4)\nedge_flow <- rowSums(res_mat)\n\nggplot(mesop) +\n  geom_point(aes(\n    x = x,\n    y = y,\n    size = edge_flow,\n    alpha = edge_flow\n  ),\n  show.legend = FALSE) +\n  scale_size_continuous(range = c(1, 3)) +\n  theme_void()\nrem_low <- which(edge_flow > quantile(edge_flow, 0.01))\n\nlibrary(ggplot2)\nlibrary(scales)\ndf <- data.frame(Volume = mesop$volume[rem_low], Interaction = edge_flow[rem_low])\n\nggplot(data = df) +\n  geom_point(aes(x = Volume, y = Interaction)) +\n  scale_x_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  scale_y_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  theme_bw()"},{"path":"SpatialInteraction.html","id":"RadiationModels","chapter":"Section 9 Spatial Interaction Models","heading":"9.4 Radiation Models","text":"2012 Filippo Simini colleagues (Simini et al. 2012) presented new model, designed specifically model human geographic mobility called radiation model. model created explicitly alternative various gravity models , certain cases, demonstrated generate improved empirical predictions human population movement origins destinations. model shares basic features gravity models importantly, approach includes parameters . Instead, model uses simply measures population set sites distances . required model relatively simple likely applied many archaeological cases. Let’s take look formally defined:\\[T_{ij} = T_i \\frac{m_in_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})}\\]\\(T_i\\) total number “commuters” migrating individuals node \\(\\).\\(m_i\\) \\(n_j\\) population estimates nodes \\(\\) \\(j\\) respectively.\\(s_{ij}\\) total population circle centered node \\(\\) touching node \\(j\\) excluding populations \\(\\) \\(j\\).defined function calculating radiation among set sites using just two inputs:pop vector population values.d_mat distance matrix among nodes.script containing function can also downloaded hereIn order test model, use Wankarani settlement data used simple gravity model. use site area divided 500 proxy population . limit sample Late Intermediate period sites habitations. Download data follow along.Now let’s plot resulting network node scaled total incident flow (row sums output function ). plot network edges weights indicated color (blue indicates low weight yellow indicates high weight).map shows clusters higher lower edge weights variation total weighted degree (higher values east). results similar, identical output simple gravity model.aware published examples use radiation models archaeological cases, certainly potential (see Evans 2016).","code":"\nradiation <- function(pop, d_mat) {\n  ## create square matrix with rows and columns for every site\n  out <-\n    matrix(0, length(pop), length(pop))\n  for (i in seq_len(length(pop))) {\n    #  start loop on rows\n    for (j in seq_len(length(pop))) {\n      # start loop on columns\n      if (i == j)\n        next()\n      # skip diagonal of matrix\n      m <- pop[i] # set population value for site i\n      n <- pop[j] # set population value for site j\n      # find radius as distance between sites i and j\n      r_ij <-\n        d_mat[i, j]\n      # find all sites within the distance from i to j centered on i\n      sel_circle <-\n        which(d_mat[i, ] <= r_ij)\n      # remove the site i and j from list\n      sel_circle <-\n        sel_circle[-which(sel_circle %in% c(i, j))]\n      s <- sum(pop[sel_circle]) # sum population within radius\n      # calculate T_i and output to matrix\n      temp <-\n        pop[i] * ((m * n) / ((m + s) * (m + n + s)))\n      if (is.na(temp)) temp <- 0\n      out[i, j] <- temp\n    }\n  }\n  return(out)\n}\nwankarani <- read.csv(\"data/Wankarani_siteinfo.csv\")\nwankarani <- wankarani[which(wankarani$Period == \"Late Intermediate\"), ]\nwankarani <- wankarani[which(wankarani$Type == \"habitation\"), ]\n\nd <- as.matrix(dist(wankarani[, 5:6]))\n\nrad_test <- radiation(pop = wankarani$Area / 500, d_mat = d)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(sf)\nlibrary(ggmap)\n\nload(\"data/bolivia.Rdata\")\n\nlocations_sf <-\n  st_as_sf(wankarani, coords = c(\"Easting\", \"Northing\"), crs = 32721)\nloc_trans <- st_transform(locations_sf, crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(loc_trans)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"lon\", \"lat\"))\n\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n\nnet <-\n  graph_from_adjacency_matrix(rad_test, mode = \"undirected\",\n                              weighted = TRUE)\n\n# Extract edge list from network object\nedgelist <- get.edgelist(net)\n\n# Create data frame of beginning and ending points of edges\nedges <-\n  data.frame(xy[edgelist[, 1], ],\n             xy[edgelist[, 2], ])\ncolnames(edges) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\n\n# Calculate weighted degree\ndg <- rowSums(rad_test)\n\n# Plot data on map\nggmap(base_bolivia, darken = 0.35) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2,\n      col = log(E(net)$weight),\n      alpha = log(E(net)$weight)\n    ),\n    show.legend = FALSE\n  ) +\n  scale_alpha_continuous(range = c(0, 0.5)) +\n  scale_color_viridis() +\n  geom_point(\n    data = xy,\n    aes(x, y, size = dg),\n    alpha = 0.8,\n    color = \"red\",\n    show.legend = FALSE\n  ) +\n  theme_void() \ndg_grav <-  rowSums(grav_mod(\n  attract = wankarani$Area / 1000,\n  B = 1,\n  d = d_mat\n))\n\ndg_rad <- rowSums(rad_test)\n\nlibrary(ggplot2)\nlibrary(scales)\ndf <-\n  data.frame(Radiation = dg_rad, Gravity = dg_grav)\n\nggplot(data = df) +\n  geom_point(aes(x = Radiation, y = Gravity)) +\n  scale_x_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  scale_y_log10(\n    breaks = trans_breaks(\"log10\", function(x)\n      10 ^ x),\n    labels = trans_format(\"log10\", math_format(10 ^ .x))\n  ) +\n  theme_bw()"},{"path":"SpatialInteraction.html","id":"OtherModels","chapter":"Section 9 Spatial Interaction Models","heading":"9.5 Other Spatial Interaction Models","text":"many spatial interaction models haven’t covered . fairly similar take information site size, perhaps relevant archaeological information, user selected parameters model flows across edges sometimes iteratively predict sizes nodes, weights flows, . common models haven’t covered include XTENT model (Renfrew Level 1979; see Ducke Suchowska 2021 example code GRASS GIS) various derivations MaxEnt (maximum entropy) models. Another approach merits mention ariadne model designed Tim Evans used collaboration Ray Rivers, Carl Knappett, others. model provides means predicting site features estimating optimal networks based location general size information (archaeological features). model features make particularly useful generating directed spatial networks (see Evans et al. 2011). Although basic R implementation ariadne model developed ISAAKiel team available computational constraints make function unfeasible R small networks. Instead, interested applying ariadne model, suggest use original Java program created Tim Evans available .","code":""},{"path":"Affiliation.html","id":"Affiliation","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Section 10 Affiliation Data and Co-Association","text":"Many material cultural networks archaeologists generated recent studies based, least part, affiliation data. affiliation network particular form network defined terms often called “actors” “events.” Typically, data used generate bipartite (two-mode) network one set nodes represents set social entities (individuals, groups, etc.) second set nodes represent set features events can common attend. example, classic affiliation data set refereed Deep South case study represents data group women southern town social events participated (Davis et al. 1941). affiliation network defined connecting people events case based notion people attended events together opportunities interact, perhaps co-attendance reflection social relationships (see Breiger 1974). Similarly, events many attendees also thought strongly connected events different rosters participants. bipartite network created connecting two classes nodes often projected distinct one-mode networks person--person event--event relationships analyses.Although always explicitly discussed, affiliation network framework mirrors many archaeological network constructions sites/regions/contexts connected via materials present contexts. example, sites may stand “persons” network artifacts categories “events” underlying reasoning inhabitants sites share categories artifacts likely interacted inhabitants sites different materials. archaeological examples data used (e.g., Coward 2013; Golitko et al. 2012; Mizoguchi 2013; Mills et al. 2013, 2015, etc.) affiliation data projected single one-mode network focused sites/contexts network used formal analyses. , course, path forward. examples archaeologists conducting direct analyses two-mode data (e.g., Blair 2015, 2017; Ladefoged et al. 2019, etc.). consideration material networks affiliation networks also opens possibility many additional methods yet rare archaeological network research. section, outline approaches may use archaeologists continue experiment affiliation data.","code":""},{"path":"Affiliation.html","id":"AnalyzingTwoMode","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.1 Analyzing Two-Mode Networks","text":"examples using Cibola data set used throughout document. specific data use consist set sites first mode set ceramic technological clusters second mode. underlying assumption sites share ceramic technological clusters strongly connected sites share fewer. , ceramic technological clusters frequently co-associated site assemblages closely connected frequently co-occur. Download data follow along.Let’s read data create simple two-mode network visualization start reading Cibola incidence matrix. using igraph package examples initialize well ggraph package plotting:","code":"\nlibrary(igraph)\nlibrary(ggraph)\n\n# Read in two-way table of sites and ceramic technological clusters\ncibola_clust <- read.csv(file = \"data/Cibola_clust.csv\",\n                         header = TRUE,\n                         row.names = 1)\n# Create network from incidence matrix based on presence/absence of\n# a cluster at a site\ncibola_inc <- igraph::graph_from_incidence_matrix(cibola_clust,\n                                                  directed = FALSE)\n# Plot as two-mode network\nset.seed(4643)\nggraph(cibola_inc) +\n  geom_edge_link(aes(size = 0.5), color = \"gray\", show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(cibola_inc)$type),\n                      size = 4),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()"},{"path":"Affiliation.html","id":"TraditionalMetrics","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.1.1 Using Traditional Network Metrics","text":"several possible approaches analyzing two-mode network data. Perhaps simplest approach analyze two-mode data using typical one-mode metrics like ’ve already seen throughout guide. Essentially, akin treating modes equivalent evaluating relative positions structures node classes. send bipartite network object typical network measures outlined Exploratory Analysis section, get results returned one-mode network. example, apply two measures centrality plot results.method useful interested determining relative centrality classes nodes, particular numbers nodes mode similar. example , degree betweenness centrality mode made ceramic technological clusters (blue) seems include central nodes, exceptions. Importantly, however, imbalance size mode important consider potential impact differences.","code":"\ndg_bi <- igraph::degree(cibola_inc)\nbw_bi <- igraph::betweenness(cibola_inc)\n\n# Plot as two-mode network with size by centrality\nset.seed(4643)\nggraph(cibola_inc) +\n  geom_edge_link(aes(size = 0.5), color = \"gray\", show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(cibola_inc)$type),\n                      size = dg_bi),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  ggtitle(\"Node Size by Degree\") +\n  theme_graph()\nset.seed(4643)\nggraph(cibola_inc) +\n  geom_edge_link(aes(size = 0.5), color = \"gray\", show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(cibola_inc)$type),\n                      size = bw_bi),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  ggtitle(\"Node Size by Betweenness\") +\n  theme_graph()"},{"path":"Affiliation.html","id":"TwoModeMetrics","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.1.2 Using Two-Mode Specific Network Metrics","text":"addition traditional approach calculating network metrics bipartite networks using one-mode metrics ’ve previously used, also methods designed specifically work two-mode network data. Unfortunately, metrics incorporated robust currently maintained packages R. Many approaches represent simply normalizations existing network metrics, however, possible create custom versions without much trouble.","code":""},{"path":"Affiliation.html","id":"density","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Density","text":"example, interested network density, doesn’t make sense simply use regular density measures assumes node can connected node. two-mode network, nodes can connected classes. Thus, obtain appropriate two-mode density, need divide density factor defined :\\[\\frac{n_1n_2}{(n_1+n_2)(n_1+n_2-1)}\\]\n\\(n_1\\) \\(n_2\\) represent number nodes modes 1 2 respectively.Let’s give try first calculating density traditional (den_init) way correcting (den_corr). Note divide initial density 2 want density counted based connections one direction.example shows, initial density estimate quite low 0.145 correct node class, get quite dense network 0.768. makes sense given many active edges see figures . high centrality suggests nodes mode 1 connections nodes mode 2.","code":"\n# edge density divided by 2 because we only want edges counted in one direction\nden_init <- edge_density(cibola_inc) / 2\nden_init## [1] 0.145122\n# number of nodes in first mode\nn1 <- length(which(V(cibola_inc)$type == FALSE))\nn1## [1] 31\n# number of nodes in second mode\nn2 <- length(which(V(cibola_inc)$type == TRUE))\nn2## [1] 10\nden_corr <- den_init / ((n1 * n2) / ((n1 + n2) * (n1 + n2 - 1)))\nden_corr## [1] 0.7677419"},{"path":"Affiliation.html","id":"degree-centrality","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Degree Centrality","text":"Let’s take look degree centrality next. saw previous section possible calculate degree centrality using traditional metric simply plotting . plot shown previously, “Technological Cluster” nodes shown blue much higher degree sites. isn’t surprising given 31 sites 10 ceramic clusters high two-mode density. words, theoretically possible degree technological cluster nodes 3 times higher sites isn’t surprising observed values higher mode two. One easy way deal degree two-mode network normalize size opposite node class. example, degree centrality one-mode networks can normalized :\\[d_i^* = \\frac{d_i}{n-1}\\]\\(d_i\\) original degree node \\(\\) \\(n\\) number nodes network.two-mode networks, standardization take following form:\\[\\begin{aligned}\nd^*_{} =& \\frac{d_{}}{n_2} \\text{, } \\V_1 \\\\\nd^*_{j} =& \\frac {d_{j}}{n_1} \\text{, } j \\V_2\n\\end{aligned}\\]\\(d_{}\\) degree node \\(\\) mode \\(V_1\\)\\(d_{j}\\) degree node \\(j\\) mode \\(V_2\\)\\(n_1\\) number nodes mode \\(1\\)\\(n_2\\) number nodes mode \\(2\\)Let’s give try Cibola ceramic technological clusters data. roll function convenience:shows, normalization nodes similar degree values couple low degree nodes. plot normalized degree distributions one-mode method two-mode normalization density plots, difference even obvious.Indeed, one-mode metric suggests nodes low degree whereas two-mode metric suggests nodes high degree. demonstrates important modify traditional network metrics two-mode use case assess distributional features like .","code":"\ndegree_twomode <- function(net) {\n  n1 <- length(which(V(net)$type == FALSE))\n  n2 <- length(which(V(net)$type == TRUE))\n  temp_dg <- igraph::degree(net, mode = \"in\")\n  dg_n1 <- temp_dg[which(V(net)$type == FALSE)] / n2\n  dg_n2 <- temp_dg[which(V(net)$type == TRUE)] / n1\n  return(c(dg_n1, dg_n2))\n}\n\ndg_tm <- degree_twomode(cibola_inc)\ndg_tm##          Apache Creek               Atsinna           Baca Pueblo \n##             0.8000000             0.6000000             0.8000000 \n##          Casa Malpais               Cienega          Coyote Creek \n##             0.9000000             0.8000000             0.9000000 \n##          Foote Canyon          Garcia Ranch          Heshotauthla \n##             1.0000000             0.7000000             0.7000000 \n##               Hinkson          Hooper Ranch       Horse Camp Mill \n##             1.0000000             0.8000000             0.9000000 \n##         Hubble Corner               Jarlosa          Los Gigantes \n##             0.8000000             0.6000000             0.5000000 \n##  Mineral Creek Pueblo               Mirabal            Ojo Bonito \n##             0.9000000             0.7000000             0.6000000 \n##       Pescado Cluster           Platt Ranch Pueblo de los Muertos \n##             0.7000000             0.8000000             0.6000000 \n##       Rudd Creek Ruin              Scribe S             Spier 170 \n##             0.9000000             0.6000000             0.6000000 \n##       Techado Springs                Tinaja          Tri-R Pueblo \n##             1.0000000             0.7000000             0.9000000 \n##                 UG481                 UG494              WS Ranch \n##             1.0000000             0.8000000             0.9000000 \n##           Yellowhouse                Clust1                Clust2 \n##             0.3000000             0.6129032             1.0000000 \n##                Clust3                Clust4                Clust5 \n##             1.0000000             0.9032258             0.7741935 \n##                Clust6                Clust7                Clust8 \n##             0.9354839             0.9032258             0.5161290 \n##                Clust9               Clust10 \n##             0.6774194             0.3548387\n# Plot as two-mode network with size by centrality\nset.seed(4643)\nggraph(cibola_inc) +\n  geom_edge_link(aes(size = 0.5), color = \"gray\", show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(cibola_inc)$type),\n                      size = dg_tm),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  ggtitle(\"Node Size by Two-Mode Normalized Degree\") +\n  theme_graph()\ndg_orig <- igraph::degree(cibola_inc, mode = \"in\", normalized = TRUE)\n\ndg_all <- c(dg_orig, dg_tm)\ndg_lab <- c(rep(\"one-mode degree\", 41), rep(\"two-mode degree\", 41))\n\ndf <- data.frame(dg = dg_all, group = dg_lab)\n\nggplot(df) +\n  geom_density(aes(x = dg, fill = group), alpha = 0.5) +\n  xlim(range = c(0, 1)) +\n  theme_bw()"},{"path":"Affiliation.html","id":"betweenness-centrality","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Betweenness Centrality","text":"Let’s now try betweenness centrality. normalization betweenness bit complicated involves shortest paths rather just counts nodes. one mode networks, betweenness typically normalized dividing results \\((n-1)(n-2)\\). case two-mode networks following equations used:\\[\\begin{aligned}\nb_{v_1\\text{max}} = & \\frac{1}{2}[n_2^2 (s+1)^2 + n_2 (s+1) (2t-s-1)-t(2s-t+3))] \\\\\nb_{v_2\\text{max}} = & \\frac{1}{2}[n_1^2 (p+1)^2 + n_1 (p+1) (2r-p-1)-t(2p-r+3))]\n\\end{aligned}\n\\]\\[\\begin{aligned}\ns =& (n_1 - 1) \\text { div } n_2 \\\\\nt =& (n_1 - 1) \\text{ mod } n_2 \\\\\np =& (n_2 - 1) \\text { div } n_1 \\\\\nr =& (n_1 - 1) \\text { mod } n_2\n\\end{aligned}\\]\\(b_{v_1\\text{max}}\\) theoretical maximum betweenness mode 1 \\(b_{v_2\\text{max}}\\) mode 2\\(n_1\\) \\(n_2\\) number nodes modes 1 2 respectively\\(\\text {div}\\) refers integer division numbers past decimal point dropped division operation\\(\\text {mod}\\) refers modulo numbers beyond decimal point retained division operationUsing equations can calculate normalized betweenness two-modes :\\[\\begin{aligned}\nb^*_i =& \\frac{b_i}b_{v_1\\text{max}} \\text {, } \\V_1\\\\\nb^*_j =& \\frac{b_j}b_{v_2\\text{max}} \\text {, } j \\V_2\n\\end{aligned}\\]following chunk code, roll equations function calculate two-mode betweenness plot . sake convenience, placed functions two-mode centrality created script can download .plot suggests normalized betweenness quite similar original one-mode measure particular network, necessarily always case.similar normalization factors centrality measures published network literature (see document Borgatti examples) implemented R yet. useful project future (perhaps add eventually. Want help?).","code":"\nbetweenness_twomode <- function(net) {\n  n1 <- length(which(V(net)$type == FALSE))\n  n2 <- length(which(V(net)$type == TRUE))\n  temp_bw <- igraph::betweenness(net, directed = FALSE)\n  s_v <- round((n1 - 1) / n2, 0)\n  t_v <- (n1 - 1) %% n2\n  p_v <- round((n2 - 1) / n1, 0)\n  r_v <- (n1 - 1) %% n2\n  bw_v1 <-\n    0.5 * (n2^2 * (s_v + 1)^2 + n2 * (s_v + 1) *\n            (2 * t_v - s_v - 1) - t_v * (2 * s_v - t_v + 3))\n  bw_v2 <- \n    0.5 * (n1^2 * (p_v +1)^2 + n1 * (p_v +1) * (2 * r_v - p_v - 1) *\n             r_v * (2 * p_v - r_v + 3))\n  bw_n1 <- temp_bw[which(V(net)$type == FALSE)] / bw_v2\n  bw_n2 <- temp_bw[which(V(net)$type == TRUE)] / bw_v1\n  return(c(bw_n1, bw_n2))\n}\n\nbw_tm <- betweenness_twomode(cibola_inc)\nbw_tm##          Apache Creek               Atsinna           Baca Pueblo \n##          0.0070822286          0.0025896615          0.0093451935 \n##          Casa Malpais               Cienega          Coyote Creek \n##          0.0099600613          0.0100144209          0.0125792905 \n##          Foote Canyon          Garcia Ranch          Heshotauthla \n##          0.0161688627          0.0042695215          0.0040337432 \n##               Hinkson          Hooper Ranch       Horse Camp Mill \n##          0.0161688627          0.0070822286          0.0099600613 \n##         Hubble Corner               Jarlosa          Los Gigantes \n##          0.0102638260          0.0025896615          0.0017552743 \n##  Mineral Creek Pueblo               Mirabal            Ojo Bonito \n##          0.0125792905          0.0040337432          0.0025896615 \n##       Pescado Cluster           Platt Ranch Pueblo de los Muertos \n##          0.0051844595          0.0070822286          0.0025896615 \n##       Rudd Creek Ruin              Scribe S             Spier 170 \n##          0.0133076983          0.0022732239          0.0030177883 \n##       Techado Springs                Tinaja          Tri-R Pueblo \n##          0.0161688627          0.0040337432          0.0099600613 \n##                 UG481                 UG494              WS Ranch \n##          0.0161688627          0.0070822286          0.0133076983 \n##           Yellowhouse                Clust1                Clust2 \n##          0.0002542476          0.0348523775          0.1297623337 \n##                Clust3                Clust4                Clust5 \n##          0.1297623337          0.0927886415          0.0634360762 \n##                Clust6                Clust7                Clust8 \n##          0.1134973990          0.0960766642          0.0224202375 \n##                Clust9               Clust10 \n##          0.0529783153          0.0102589547\n# Plot as two-mode network with size by centrality\nset.seed(4643)\nggraph(cibola_inc) +\n  geom_edge_link(aes(size = 0.5), color = \"gray\", show.legend = FALSE) +\n  geom_node_point(aes(color = as.factor(V(cibola_inc)$type),\n                      size = bw_tm),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  ggtitle(\"Node Size by Two-Mode Normalized Betweenness\") +\n  theme_graph()"},{"path":"Affiliation.html","id":"ProjectingTwoMode","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.1.3 Projecting Two-Mode Networks Before Analysis","text":"Another common approach analysis two-mode networks project two separate one-mode networks analyze one modes using traditional one-mode metrics. already seen approach several examples throughout guide. Indeed, common approach archaeological network studies taken. describe Network Data Formats section, several ways projecting incidence matrix one-mode networks. includes matrix multiplication method counts numbers co-occurrences already described coverage two-mode networks well various similarity metrics producing weighted networks based measures Brainerd-Robinson similarity, \\(\\chi\\)-square distance, Jaccard similarity, many others discussed similarity networks section. Although networks often explicitly described terms affiliation networks, much fit definition. section, offer slightly expanded discussion methods highlight important issues affiliation data specifically.","code":""},{"path":"Affiliation.html","id":"matrix-multiplication","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Matrix Multiplication","text":"prevsiously described one common ways generating one mode projections two-mode data matrix multiplication. Specifically, multiply matrix \\(\\) transpose matrix \\(^T\\), get square matrix number rows columns equal rows original matrix cell representing number intersections two modes (diagonal matrix representing number opposite mode categories present mode consideration). Let’s take look process formally:\\[\\begin{equation}\n \\cdot ^T =\n\\begin{pmatrix}\n& b \\\\\nc & d\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\n& c \\\\\nb & d\n\\end{pmatrix} =\n\\begin{pmatrix}\naa + bb & ac+bd \\\\\nca +db & cc + dd\n\\end{pmatrix}\n\\end{equation}\\]assume original matrix contains 0s 1s end intersection two network modes diagonal describe .couple ways conduct procedure R. Previously used %*% operator matrix multiplication t() transpose function calculate matrix multiplied transpose, also possible use R built-function called crossprod thing. Indeed, working large matrices, can computationally expensive, crossprod function considerably faster. chunk calculate square matrix cibola_clust data set using methods subtract results ensure identical.Another important feature one-mode network generated way can treated weighted network simply including weighted = TRUE argument call. example:produces hairball fairly hard visually interpret. try ameliorate can borrow function previously created two-mode networks discussion Network Data section consider ceramic cluster present site makes least 20% assemblage. Let’s try :lot easier interpret. ’ve got one cluster quite strong ties second cluster characterized weaker ties relatively week ties clusters. Notably, pattern similar pattern seen Brainerd-Robinson similarity matrices generated using data isn’t surprising.","code":"\nmat1 <- as.matrix(cibola_clust)\nmat1 <- ifelse(mat1 > 0, 1, 0)\n\nres1 <- mat1 %*% t(mat1)\n\n# this does the same as the above\nres2 <- crossprod(t(mat1))\n\n# Check to see if they are identical\nmax(res1-res2)## [1] 0\ndiag(res1) <- 0\ncibola_onemode <- graph_from_adjacency_matrix(res1, weighted = TRUE)\n\nset.seed(4643)\nggraph(cibola_onemode) +\n  geom_edge_link(aes(alpha = weight, color = weight),\n                 width = 1, show.legend = FALSE) +\n  scale_edge_alpha_continuous(range = c(0, 0.5)) +\n  scale_edge_color_continuous() + \n  geom_node_point(aes(size = igraph::degree(cibola_onemode)),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()\ntwo_mode <- function(x, thresh = 0.2) {\n  # Create matrix of proportions from x input into function\n  temp <- prop.table(as.matrix(x), 1)\n  # Define anything with greater than or equal to threshold as\n  # present (1)\n  temp[temp >= thresh] <- 1\n  # Define all other cells as absent (0)\n  temp[temp < 1] <- 0\n  # Return the new binarized table as output of the function\n  return(temp)\n}\n\nmat_new <- two_mode(cibola_clust, thresh = 0.2)\n\nres3 <- crossprod(t(mat_new))\n\ncibola_om_reduced <- graph_from_adjacency_matrix(res3, weighted = TRUE)\n\nset.seed(4643)\nggraph(cibola_om_reduced) +\n  geom_edge_link(aes(alpha = weight, color = weight),\n                 width = 1, show.legend = FALSE) +\n  scale_edge_alpha_continuous(range = c(0.1, 1)) +\n  scale_edge_color_gradient() +\n  geom_node_point(aes(size = igraph::degree(cibola_om_reduced)),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()"},{"path":"Affiliation.html","id":"weighted-matrix-projection","chapter":"Section 10 Affiliation Data and Co-Association","heading":"Weighted Matrix Projection","text":"already described several similarity metrics detail similarity networks section document. section, want offer one additional approach developed Newman (2001) defining connections scientific collaboration networks. Newman wanted extend procedure assessing co-occurrence take account number collaborators involved collaboration. Specifically, posited fewer collaborators, connection pair co-authors stronger many co-authors. equivalently think terms material culture suggest sites contexts shared rare categories strongly connected sites/contexts shared common categories. Using logic, Newman created new weighting scheme co-occurrence networks weight connection nodes \\(\\) \\(j\\) defined terms number cross-mode connections node. words:\\[w_{ij} = \\Sigma_p \\frac{1}{N_p-1}\\]\\(N_p\\) number connections mode 1 mode 2 node \\(p\\) \\(w_{ij}\\) weight connection \\(\\) \\(j\\).\nNewman method weighting bipartite networks \nimplemented R package called tnet. package \nuseful functions analysis bipartite, weighted, \nlongitudinal networks worth investigating (see\n?tnet). Unfortunately, longer actively\nmaintained.\nLet’s take look Newman’s method using tnet package. package expects simple two-column edge list integers node identifiers can generate using igraph get.edgelist function including names = FALSE argument:expected, get another hairball , let’s take look edge weights projection versus original matrix multiplication projection:shows, edge weights highly correlated \\(r^2 = 0.95\\) also subtle differences distinguish two projection methods. Via experimentation found Newman model particularly useful situations mix common rare artifact (mode 2) categories produces networks account relative frequency via context--context co-associations.","code":"\nlibrary(tnet)\n\ntm_el <- get.edgelist(cibola_inc, names = FALSE)\nhead(tm_el)##      [,1] [,2]\n## [1,]    1   32\n## [2,]    1   33\n## [3,]    1   34\n## [4,]    1   35\n## [5,]    1   36\n## [6,]    1   37\nproj_newman <- as.matrix(projecting_tm(tm_el, method = \"Newman\"))\n\nproj_net <- graph_from_edgelist(proj_newman[, 1:2])\nE(proj_net)$weight <- proj_newman[, 3]\nV(proj_net)$name <- row.names(cibola_clust)\n\nset.seed(4643)\nggraph(proj_net) +\n  geom_edge_link(aes(color = weight),\n                 width = 1, show.legend = FALSE) +\n  scale_edge_alpha_continuous(range = c(0, 0.5)) +\n  scale_edge_color_continuous() +\n  geom_node_point(aes(size = igraph::degree(proj_net)),\n                  show.legend = FALSE) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()\ncor(E(proj_net)$weight, E(cibola_onemode)$weight)^2## [1] 0.9454047\nplot(E(proj_net)$weight, E(cibola_onemode)$weight, pch = 16, col = \"blue\",\n     xlab = \"Newman Weights\", ylab = \"Matrix Multiplication Weights\")"},{"path":"Affiliation.html","id":"CorrespondenceAnalysis","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.2 Correspondence Analysis","text":"Another method proven useful exploring affiliation data archaeological many contexts correspondence analysis. Correspondence analysis method dimension reduction based decomposition \\(chi\\)-square statistic allows projection rows columns incidence matrix low dimensional space (see Peeples Schachner 2012). Correspondence analysis works either count presence/absence data. technical details approach beyond scope document (see Peeples Schachner 2012), generally correspondence analysis can used plot row column cases incidence matrix single bi-plot spatial configuration points related degree co-association among (though perfect representation co-association). Correspondence analysis frequently used frequency seriation archaeology can also useful analysis focused co-association including spatial analyses (Alberti 2017). Correspondence analysis also previously used Giomi Peeples (2019) investigating assemblages materials recovered discrete excavation contexts within Pueblo Bonito Chacoan Great House complex. explicitly compare correspondence analysis related co-association methods describe construct networks co-association among artifact categories.\nConducting correspondence analysis visualizing R \ntypically done using ca package. package \nplotting function within creates bi-plots mode (rows\ncolumns incidence matrix) displayed different shapes\ncolors. See ?ca() function help \ninformation. Although use , anacor\npackage provides additional extensions correspondence analysis\nmethods (alternative axis scaling methods) may also \nuseful.\nLet’s start applying ca function cibola_clust incidence matrix data set:plot clearly shows associations certain clusters sets sites. familiar sites used may also notice clear geographic clusters well. addition , dimensions contain percentages labels. indicates amount variation underlying incidence matrix dimension represents. Correspondence analysis designed first dimension accounts variation 1 dimension less number categories present.","code":"\nlibrary(ca)\n\nca_cibola <- ca(cibola_clust)\nplot(ca_cibola)"},{"path":"Affiliation.html","id":"CAViz","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.2.1 Network Visuals Using Correspondence Analysis","text":"Correspondence analysis frequently used plotting affiliation data like sociology, particular using layouts generated CA plot networks edges generated using mode projection described (see Borgatti Halgin 2014; Faust 2005). chunk code plot reduced Cibola one-mode network edges well one mode projection columns using positions correspondence analysis axes point locations.plot illustrates, considerable information co-associations two modes incidence matrix visuals like . suggest visualizations like potential avenue worth perusing future archaeological network investigations incidence matrix data sets.","code":"\n# Create network object using crossprod function\ncol_net <- graph_from_adjacency_matrix(crossprod(as.matrix(cibola_clust)),\n                                       weighted = TRUE,\n                                       mode = \"undirected\",\n                                       diag = FALSE)\n\n# Combine both edge lists into a single frame\nel_com <-  rbind(get.edgelist(cibola_om_reduced), get.edgelist(col_net))\n\n# Define composite network object and add Edge and Vertex attributes\nnet2 <- graph_from_edgelist(el_com, directed = FALSE)\nE(net2)$weight <- c(E(cibola_om_reduced)$weight, E(col_net)$weight)\nE(net2)$mode <- c(rep(\"blue\", ecount(cibola_om_reduced)),\n                  rep(\"red\", ecount(col_net)))\nV(net2)$mode2 <- c(rep(\"blue\", vcount(cibola_om_reduced)),\n                   rep(\"red\", vcount(col_net)))\nV(net2)$name <- c(row.names(cibola_clust), colnames(cibola_clust))\n\n# Create object containing row and column coordinates from correspondence\n# analysis results\nxy <- rbind(ca_cibola$rowcoord[, 1:2], ca_cibola$colcoord[, 1:2])\n\n# Plot the results color coding by mode\nset.seed(4643)\nggraph(net2, layout = \"manual\",\n       x = xy[, 1],\n       y = xy[, 2]) +\n  geom_edge_link0(aes(alpha = weight, color  = E(net2)$mode),\n                 show.legend = FALSE) +\n  scale_edge_color_manual(values = c(\"blue\", \"red\")) +\n  geom_node_point(aes(color = mode2, shape = mode2), \n                  size = 3,\n                  show.legend = FALSE) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_shape_manual(values = c(16, 17)) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_bw()"},{"path":"Affiliation.html","id":"MeasuringCoassociation","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.3 Measuring Co-association","text":"Giomi Peeples (2019) presented network analysis focused intra-site variability Chacoan Great House complex Pueblo Bonito. analysis, used correspondence analysis shown addition method assessing co-occurrence two-way tables first published Kintigh (2006). method calculates expected co-occurrence every pair objects assemblage based total number contexts considered number contexts contain type object (can think types objects contexts two modes two-mode network). method relies presence/absence can applied many contexts even sketchy information archaeological context inventories available. Giomi Peeples present measure co-association \\(C_{ab}\\) object types \\(\\) \\(b\\) defined :\\[C_{ab}=\\frac{o_{ab}-Np_{ab}}{\\sqrt{Np_{ab}(1-p_{ab})}}\\]\\(o_{ab}\\) = observed number co-occurrences object classes \\(\\) \\(b\\).\\(N\\) = total number assemblages\\(p_{ab}\\) = expected proportion co-occurrences object classes \\(\\) \\(b\\) defined proportion assemblages \\(\\) occurs times proportion assemblages \\(b\\) occurs.measure provides index number co-occurrences observed relation expected given overall frequency object class Z-standardized units. means value 3 means two object classes co-occur approximately 3 standard deviations expect given frequency occurrence object classes number contexts data. Similarly value -2 means two object classes 2 standard deviations less associated expected given frequency occurrence.function used Giomi Peeples (2019) also available GitHub .test approach ’re going use partial inventory artifacts site west-central New Mexico called Techado Springs (Smith et al. 2009). extensively excavated settlement 500 rooms artifact inventory data 198 rooms. example , ’re using 9 categories features/objects encountered rooms, related ceramic production process. can download artifact data follow along.Looking first columns output cooccur function can see particularly high low values. example, polishing stones pukis (tools used supporting vessels forming ) much less associated expected chance (-5.15). side, ceramic drying features un-fired vessels much associated expect chance (3.69). also several NaN NA indicating two categories never co-occur data set.Next, let’s plot returned values histogram:","code":"\n## Co-occurrence assessment script\n## This function expects a binary data frame object that contains only 1s and 0s with the contexts under consideration as rows and the \n## categories as columns and each cell represents the presence or absence of a particular category in a particular context\n\ncooccur <- function(x) {\n  \n  # calculate the proportional occurrence of each artifact class\n  nm.p <- colSums(x)/nrow(x) \n  \n  # calculated observed co-occurrences through matrix multiplication\n  obs <- t(as.matrix(x)) %*% (as.matrix(x)) \n  diag(obs) <- 0\n  \n  # create matrix of expected values based on proportional occurrence \n  expect <- matrix(0,nrow(obs),ncol(obs)) \n  for (i in 1:nrow(obs)) {\n    for (j in 1:ncol(obs)) {\n      expect[i,j] <- (nm.p[i]*nm.p[j])*nrow(x)}} \n  \n  # convert expected count to expected proportion\n  p <- expect/nrow(x)\n  \n  # calculate final matrix of scores and output\n  out <- (obs-expect)/(sqrt(expect*(1-p))) \n  diag(out) <- 0\n  return(out)}\ntec <- read.csv(\"data/Techado_artifacts.csv\", header = TRUE, row.names = 1)\ntec <- tec[which(rowSums(tec) > 0), ]\n\nout <- cooccur(tec)\n\n# see first few columns\nout[,1:4]##                   CeramicDryFeature CeramicVessel        Puki   PaintCup\n## CeramicDryFeature         0.0000000     3.9785881  2.25632854  1.5877018\n## CeramicVessel             3.9785881     0.0000000 -1.38858632 -0.2800886\n## Puki                      2.2563285    -1.3885863  0.00000000 -0.9061016\n## PaintCup                  1.5877018    -0.2800886 -0.90610162  0.0000000\n## PolishingStone           -1.0575847           NaN -5.15060380  1.3732138\n## RawClay                  -0.8651613    -1.5384481 -1.43135460 -1.3739322\n## Scoop                     0.7167460    -1.4775196 -1.59036373  0.6854396\n## CeramicScrapper           0.2165159     0.2621044 -0.01569124  2.1188426\n## UnfiredVessel             3.6918908     8.3227556  1.04664169  1.9422423\nhist(out, breaks = 10, xlab = \"C_p\")"},{"path":"Affiliation.html","id":"COViz","chapter":"Section 10 Affiliation Data and Co-Association","heading":"10.3.1 Alternative Methods for Visualizing Co-associations","text":"Another way can visualize data using network graph described Giomi Peeples (2019). First, dichotomize output created . going use absolute threshold define edge (connection) pair object classes associated 2 standard deviations greater expected chance. nothing special 2 SD threshold practice good idea try range values compare results.plot shows strongest co-associations among categories provides nice distillation important relationships one mode data. also possible reverse explore connections among rooms virtue co-associations assemblages. Let’s give try using t() transpose function reverse matrix analysis. plot defined clusters among nodes using Louvain clustering method color coded evaluate potential community structure results.Hmm… appear clusters… interesting. lot things likely want including going back original data looking commonalities among rooms group together terms strong similarities ceramic production tools features. example, Giomi Peeples (2019) explore relationships cluster/clique membership room inventories make behavioral interpretations common assemblages drawing ethnographic examples.brief example illustrates, co-association methods like natural fit network methods argue archaeologists explore similar approaches future.","code":"\nnet_dat <- out\nnet_dat <- ifelse(net_dat < 2, 0, net_dat)\nnet_dat[is.na(net_dat)] <- 0\n\nnet_c <- graph_from_adjacency_matrix(net_dat,\n                                     mode = \"undirected\",\n                                     weighted = TRUE)\nV(net_c)$name <- colnames(tec)\n\nset.seed(4643)\nggraph(net_c) +\n  geom_edge_link(aes(width = weight)) +\n  scale_edge_width_continuous(range = c(0.5, 1.5)) +\n  geom_node_point(size = 3, color = \"red\") +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()\nnet_dat <- cooccur(t(tec))\nnet_dat <- ifelse(net_dat > 2, 1, 0)\nnet_dat[is.na(net_dat)] <- 0\n\nnet_r <- graph_from_adjacency_matrix(net_dat, mode = \"undirected\")\nV(net_r)$name <- row.names(tec)\n\ngroup <- cluster_louvain(net_r)$memberships[1, ]\n\nset.seed(4532)\nggraph(net_r, layout = \"fr\") +\n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(color = as.factor(group)),\n                  size = 3,\n                  show.legend = FALSE) +\n  scale_color_discrete(\"Set2\") +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  theme_graph()"},{"path":"NetworkDiffusion.html","id":"NetworkDiffusion","chapter":"Section 11 Network Diffusion","heading":"Section 11 Network Diffusion","text":"social behavioral sciences, network models empirical networks frequently used investigate diffusion processes. Diffusion contexts refers spread social biological contagions (diseases, technological innovations, memes, rumors, etc.) among individuals larger groups given social context. Work realm shown social networks different topological properties can lead different kinds diffusion trajectories terms speed completeness contagions spread. section, introduce simple network diffusion models demonstrate can used common forms archaeological network data address general archaeological questions.","code":""},{"path":"NetworkDiffusion.html","id":"DiffusionProcesses","chapter":"Section 11 Network Diffusion","heading":"11.1 Diffusion Processes","text":"Network diffusion processes frequently investigated using simulation methods. Specifically, researcher starts network either generated based empirical data modeled generative process (like random small world network) introduces social contagion sort one nodes network. network walked series time steps (represent hours, days, years whatever length time appropriate given question) contagion spreads node node probability based configuration strength connections among nodes potentially features susceptibility given node based non-network attributes. simulations can repeated many times given network configuration nature diffusion process can examined resulting data might include estimates rate infection/adoption, proportion nodes take contagion across time step, order nodes infected/adopt among many possibilities. Typically, researchers interested identifying specific features infection/adoption curve, specific directions spread, aggregate features diffusion process compare empirical information theoretical expectations. example, empirical research diffusion technological innovations shown adoption rates often characterized S-shaped curve adoption rates initially slow innovation reaches threshold, followed rapid adoption eventually leveling adoption rate reaches saturation within given population. Using network simulation described , possible compare different network configurations relate expectations.","code":""},{"path":"NetworkDiffusion.html","id":"SimNetworkR","chapter":"Section 11 Network Diffusion","heading":"11.2 Simulating Network Diffusion in R","text":"section introduce basic methods simulating network diffusion process empirical model based network configurations R.\nanalyses , largely rely package called\nnetdiffuseR includes built-functions \nsimulating many common topological forms networks random \nsmall-world networks also allows us estimate diffusion rates \ndirections across nodes across time steps. Importantly, package\nallows consideration empirical simulated networks \nstarting point.\nLet’s get started initializing library exploring primary function within package called rdiffnet. function can take number arguments specify nature network created diffusion process simulated network. arguments include:n - number nodes include network. supply seed.graph argument needed.t - number time steps consider.seed.graph - optional argument lets supply empirical network form adjacency matrix serve initial network configuration.seed.nodes - argument can set either marginal, central, random refers positions initial nodes “infected” “adopters” network model. options select nodes either lowest degree, highest degree, randomly respectively. Alternatively, can supply vector node numbers representing nodes adopters time step 1.seed.p.adopt - proportion nodes initial adopters/infected.rgraph.args - argument includes arguments passed rgraph function define parameters random graph created (relevant).rewire - logical argument expects TRUE FALSE. TRUE time step number edges reassigned random based additional options passed rewire.args argument. Note argument TRUE default.rewire.args - argument used send options rewire_graph function rewires certain number edges step. general relevant option p proportion edges rewired.threshold.dist - argument expects either function vector length n defines adoption threshold (susceptibility) node.exposure.args - argument contains options passed exposure function defines adoption rates various kinds network edge weighting schema.see , need use arguments every network simulation. Reading documentation rdiffnet package provides additional details options described briefly .One important concept needs formally defined move network threshold (defined relationship \\(\\tau\\) threshold.dist). can formally written :\\[\n    a_i = \\left\\{\\begin{array}{ll}\n    1 &\\mbox{} \\tau_i\\leq E_i \\\\\n    0 & \\mbox{Otherwise}\n    \\end{array}\\right. \\qquad\n    E_i \\equiv \\frac{\\sum_{j\\neq }\\mathbf{X}_{ij}a_j}{\\sum_{j\\neq }\\mathbf{X}_{ij}}\n  \\]\\(\\tau\\) proportion neighbors need adopters target adopt.\\(E_i\\) exposure \\(\\mathbf{X}\\) adjacency matrix network.words, node \\(\\) adopt given time step exposure greater equal \\(\\tau\\).","code":""},{"path":"NetworkDiffusion.html","id":"DiffuseSimulatedNetworks","chapter":"Section 11 Network Diffusion","heading":"11.2.1 Simulated Networks","text":"start simple random small-world network simulation show function works. Let’s run code ’ll explain happening:example, created random network 1000 nodes small world structure. examine network across 20 time steps. send value 0.1 rgraph.args argument meaning proportion ties rewired random graph generate “small-world” structure (see rgaph_ws info) initial network configuration. set initial adopters network 0.001 single node 1000 node network. Finally, set threshold.dist random uniform number (using runif function) 0.1 0.5 meaning node adopt contagion given time step 10% 50% ’s neighbors adopted. Note set value rewire default TRUE small proportion edges rewired time step.summary output provides information number adopters cumulative adoption percent time step. also information hazard rate, probability given node infected/adopt step. Moran’s measure autocorrelation sued indicate whether infected nodes/adopters concentrated among neighbors network (nodes share edge). surprisingly, see across first time step.netdiffuseR package also built functions plotting. First, let’s plot simulated network different time steps see distributions adopters non-adopters. plot 1st, 10th, 15th time steps:can also plot adoption curve across time steps using plot_adopters function:results show classic S-shaped curve cumulative adoption parameters ’ve provided adoption first slow, followed period rapid adoption, gradual slowdown adoptions reaches saturation.can also plot network shows time step node adopted contagion:Using rdiffnet function altering arguments, can experiment different configurations parameters change rate completeness adoption. example, chunk code replicate model exactly except allow nodes higher threshold required adoption (70% nodes max instead 50%). Let’s see changes results:shows, changing simple parameter allow higher adoption threshold nodes, longer get saturation within 20 time steps see generally slower rate adoption.also explore alternate graph generation models using approach. example , generate scale-free network using rgraph_ba function (ba Barabasi Albert defined model). set parameter m = 4 means 4 edges created node initial network. leave parameters initial example.figures show, scale-free network model generates adoption curve slow grow shows rapid cascade across network quick saturation just time steps. suggests, different forms network topology likely lead different kinds adoption/infection processes. potentially use curves assessments rates uptakes empirical analyses determine sorts network generative process less plausible given data.","code":"\nlibrary(netdiffuseR)\n\nset.seed(4436)\nnet_test1 <- rdiffnet(\n  n = 1000,\n  t = 20,\n  seed.nodes = \"random\",\n  seed.p.adopt = 0.001,\n  seed.graph = \"small-world\",\n  rgraph.args = list(p = 0.1),\n  threshold.dist = function (x) runif(1, 0.1, 0.5)\n)\n\nsummary(net_test1)## Diffusion network summary statistics\n## Name     : A diffusion network\n## Behavior : Random contagion\n## -----------------------------------------------------------------------------\n##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  \n## -------- ---------- ---------------- ------------- --------- ---------------- \n##        1          1         1 (0.00)             -      0.00 -0.00 (0.00)     \n##        2          4         5 (0.00)          0.00      0.00  0.10 (0.01) *** \n##        3          6        11 (0.01)          0.01      0.00  0.16 (0.01) *** \n##        4          9        20 (0.02)          0.01      0.00  0.18 (0.01) *** \n##        5         13        33 (0.03)          0.01      0.00  0.18 (0.01) *** \n##        6         25        58 (0.06)          0.03      0.00  0.20 (0.01) *** \n##        7         39        97 (0.10)          0.04      0.00  0.24 (0.01) *** \n##        8         71       168 (0.17)          0.08      0.00  0.19 (0.01) *** \n##        9        124       292 (0.29)          0.15      0.00  0.20 (0.01) *** \n##       10        167       459 (0.46)          0.24      0.00  0.21 (0.01) *** \n##       11        197       656 (0.66)          0.36      0.00  0.18 (0.01) *** \n##       12        186       842 (0.84)          0.54      0.00  0.16 (0.01) *** \n##       13        111       953 (0.95)          0.70      0.00  0.10 (0.01) *** \n##       14         41       994 (0.99)          0.87      0.00  0.03 (0.01) *** \n##       15          6      1000 (1.00)          1.00      0.00               -  \n##       16          0      1000 (1.00)          0.00      0.00               -  \n##       17          0      1000 (1.00)          0.00      0.00               -  \n##       18          0      1000 (1.00)          0.00      0.00               -  \n##       19          0      1000 (1.00)          0.00      0.00               -  \n##       20          0      1000 (1.00)          0.00      0.00               -  \n## -----------------------------------------------------------------------------\n##  Left censoring  : 0.00 (1)\n##  Right centoring : 0.00 (0)\n##  # of nodes      : 1000\n## \n##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic\n##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.\nplot_diffnet(net_test1, slices = c(1, 10, 15))\nplot_adopters(net_test1)\nplot_diffnet2(net_test1)\nset.seed(4436)\nnet_test2 <- rdiffnet(\n  n = 1000,\n  t = 20,\n  seed.nodes = \"random\",\n  seed.p.adopt = 0.001,\n  seed.graph = \"small-world\",\n  rgraph.args = list(p = 0.1),\n  threshold.dist = function (x) runif(1, 0.1, 0.7)\n)\n\nsummary(net_test2)## Diffusion network summary statistics\n## Name     : A diffusion network\n## Behavior : Random contagion\n## -----------------------------------------------------------------------------\n##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  \n## -------- ---------- ---------------- ------------- --------- ---------------- \n##        1          1         1 (0.00)             -      0.00 -0.00 (0.00)     \n##        2          4         5 (0.00)          0.00      0.00  0.10 (0.01) *** \n##        3          3         8 (0.01)          0.00      0.00  0.14 (0.01) *** \n##        4          5        13 (0.01)          0.01      0.00  0.17 (0.01) *** \n##        5          2        15 (0.01)          0.00      0.00  0.12 (0.01) *** \n##        6          2        17 (0.02)          0.00      0.00  0.15 (0.01) *** \n##        7          8        25 (0.02)          0.01      0.00  0.15 (0.01) *** \n##        8         11        36 (0.04)          0.01      0.00  0.18 (0.01) *** \n##        9         23        59 (0.06)          0.02      0.00  0.15 (0.01) *** \n##       10         32        91 (0.09)          0.03      0.00  0.19 (0.01) *** \n##       11         44       135 (0.14)          0.05      0.00  0.18 (0.01) *** \n##       12         56       191 (0.19)          0.06      0.00  0.15 (0.01) *** \n##       13         74       265 (0.26)          0.09      0.00  0.15 (0.01) *** \n##       14         95       360 (0.36)          0.13      0.00  0.15 (0.01) *** \n##       15        101       461 (0.46)          0.16      0.00  0.15 (0.01) *** \n##       16         82       543 (0.54)          0.15      0.00  0.13 (0.01) *** \n##       17         92       635 (0.64)          0.20      0.00  0.12 (0.01) *** \n##       18         86       721 (0.72)          0.24      0.00  0.13 (0.01) *** \n##       19         69       790 (0.79)          0.25      0.00  0.14 (0.01) *** \n##       20         45       835 (0.83)          0.21      0.00  0.14 (0.01) *** \n## -----------------------------------------------------------------------------\n##  Left censoring  : 0.00 (1)\n##  Right centoring : 0.16 (165)\n##  # of nodes      : 1000\n## \n##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic\n##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.\nplot_adopters(net_test2)\nplot_diffnet2(net_test2)\nset.seed(4436)\nnet_test2 <- rdiffnet(\n  n = 1000,\n  t = 20,\n  seed.nodes = \"random\",\n  seed.p.adopt = 0.001,\n  seed.graph = \"scale-free\",\n  rgraph.args = list(m = 4),\n  threshold.dist = function (x) runif(1, 0.1, 0.5)\n)\n\nsummary(net_test2)## Diffusion network summary statistics\n## Name     : A diffusion network\n## Behavior : Random contagion\n## -----------------------------------------------------------------------------\n##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  \n## -------- ---------- ---------------- ------------- --------- ---------------- \n##        1          1         1 (0.00)             -      0.00 -0.00 (0.00)     \n##        2          1         2 (0.00)          0.00      0.00  0.00 (0.00) *** \n##        3          2         4 (0.00)          0.00      0.00  0.01 (0.00) *** \n##        4          3         7 (0.01)          0.00      0.00  0.02 (0.00) *** \n##        5          3        10 (0.01)          0.00      0.00  0.01 (0.00) *** \n##        6          5        15 (0.01)          0.01      0.00  0.02 (0.00) *** \n##        7          5        20 (0.02)          0.01      0.00  0.01 (0.00) *** \n##        8          9        29 (0.03)          0.01      0.00  0.01 (0.00) *** \n##        9         13        42 (0.04)          0.01      0.00  0.02 (0.00) *** \n##       10         17        59 (0.06)          0.02      0.00  0.01 (0.00) *** \n##       11         71       130 (0.13)          0.08      0.00  0.01 (0.00) *** \n##       12        189       319 (0.32)          0.22      0.00  0.01 (0.00) *** \n##       13        385       704 (0.70)          0.57      0.00  0.01 (0.00) *** \n##       14        273       977 (0.98)          0.92      0.00  0.00 (0.00)     \n##       15         23      1000 (1.00)          1.00      0.00               -  \n##       16          0      1000 (1.00)          0.00      0.00               -  \n##       17          0      1000 (1.00)          0.00      0.00               -  \n##       18          0      1000 (1.00)          0.00      0.00               -  \n##       19          0      1000 (1.00)          0.00      0.00               -  \n##       20          0      1000 (1.00)          0.00      0.00               -  \n## -----------------------------------------------------------------------------\n##  Left censoring  : 0.00 (1)\n##  Right centoring : 0.00 (0)\n##  # of nodes      : 1000\n## \n##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic\n##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.\nplot_adopters(net_test2)\nplot_diffnet2(net_test2)"},{"path":"NetworkDiffusion.html","id":"DiffuseEmpiricalNetworks","chapter":"Section 11 Network Diffusion","heading":"11.2.2 Empirical Networks","text":"rdiffnet function described can also applied empirical networks. way example, let’s take look Iberian Roman Roads data set ’ve used several places document. define sites nodes connect edges documented road . draw additional edges nearest neighbors remaining unconnected nodes create single fully connected network. Download network data follow along download basemap .First, let’s map network labeling nodes number:order use network model diffusion process, simply supply seed.graph within rdiffnet function. following chunk code, supply network shown seed model 20 time steps initial “adopters” case defined nodes 72 77 far eastern portion study area. define threshold.dist vector values 0.25 indicating node adopt quarter connections already adopted. , set rewire = FALSE edges remain across time steps. Let’s take look network adopter plot:plot shows, network doesn’t reach saturation adoption 20 time steps give upward trajectory slope beginning end. Let’s now consider time adoption individual nodes. , can look object appended output rdiffnet function called toa “time adoption” indicates time step node adopted.Let’s now plot map network color coding nodes variable:map illustrates, nodes closest initial adopters earliest adopters. area southern portion study area shows dense collection nodes colored gray indicating adopt 20 time steps assessed.Let’s now create another adopter plot map color coded time adoption. next example, leave everything alone time set initial adopters nodes 6 7 northwestern portion study area:Using starting point, get fairly typical S-shaped curve full saturation adoption within 20 time steps. shows, specific location within network innovation/meme/disease/contagion originates can big impact rate completeness spread, even considering network.","code":"\nlibrary(igraph)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggrepel)\n\n# Read in required data\nload(\"data/road_networks.RData\")\nload(\"data/road_base.Rdata\")\n\nnodes <- nodes[match(V(road_net3)$name, nodes$Id), ]\n \n# Convert name, lat, and long data into sf coordinates\nlocations_sf <-\n  st_as_sf(nodes, coords = c(\"long\", \"lat\"), crs = 4326)\ncoord1 <- do.call(rbind, st_geometry(locations_sf)) %>%\n  tibble::as_tibble() %>%\n  setNames(c(\"long\", \"lat\"))\n\n# Create data.frame of long and lat as xy coordinates\nxy <- as.data.frame(coord1)\ncolnames(xy) <- c(\"x\", \"y\")\n\n# Extract edge list from network object for road_net\nedgelist1 <- get.edgelist(road_net3)\n\n# Create data frame of beginning and ending points of edges\nedges1 <- as.data.frame(matrix(NA, nrow(edgelist1), 4))\ncolnames(edges1) <- c(\"X1\", \"Y1\", \"X2\", \"Y2\")\nfor (i in seq_len(nrow(edgelist1))) {\n  edges1[i,] <- c(nodes[which(nodes$Id == edgelist1[i, 1]), 3],\n                  nodes[which(nodes$Id == edgelist1[i, 1]), 2],\n                  nodes[which(nodes$Id == edgelist1[i, 2]), 3],\n                  nodes[which(nodes$Id == edgelist1[i, 2]), 2])\n}\n# Plot ggmap object with network on top\nggmap(my_map) +\n  geom_segment(data = edges1,\n               aes(\n                 x = X1,\n                 y = Y1,\n                 xend = X2,\n                 yend = Y2\n               ),\n               size = 1) +\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.8,\n    col = \"black\",\n    fill = \"white\",\n    shape = 21,\n    size = 3,\n  ) +\n  geom_text_repel(aes(x = x, y = y, label = row.names(xy)),\n                  data = xy,\n                  size = 3) +\n  theme_void()\nset.seed(4435436)\ndiffnet_road <- rdiffnet(\n  seed.graph = as.matrix(road_net3),\n  t = 20,\n  seed.nodes = c(72, 77),\n  threshold.dist = rep(0.25, 122),\n  rewire = FALSE\n)\n\nsummary(diffnet_road)## Diffusion network summary statistics\n## Name     : A diffusion network\n## Behavior : Random contagion\n## -----------------------------------------------------------------------------\n##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  \n## -------- ---------- ---------------- ------------- --------- ---------------- \n##        1          2         2 (0.02)             -      0.02  0.04 (0.01) *** \n##        2          6         8 (0.07)          0.05      0.02  0.49 (0.02) *** \n##        3          1         9 (0.07)          0.01      0.02  0.49 (0.02) *** \n##        4          3        12 (0.10)          0.03      0.02  0.51 (0.02) *** \n##        5          3        15 (0.12)          0.03      0.02  0.52 (0.02) *** \n##        6          3        18 (0.15)          0.03      0.02  0.53 (0.02) *** \n##        7          3        21 (0.17)          0.03      0.02  0.52 (0.02) *** \n##        8          7        28 (0.23)          0.07      0.02  0.53 (0.02) *** \n##        9          8        36 (0.30)          0.09      0.02  0.56 (0.02) *** \n##       10          8        44 (0.36)          0.09      0.02  0.60 (0.02) *** \n##       11          7        51 (0.42)          0.09      0.02  0.58 (0.02) *** \n##       12          9        60 (0.49)          0.13      0.02  0.59 (0.02) *** \n##       13          9        69 (0.57)          0.15      0.02  0.63 (0.02) *** \n##       14          7        76 (0.62)          0.13      0.02  0.68 (0.02) *** \n##       15          6        82 (0.67)          0.13      0.02  0.69 (0.02) *** \n##       16          4        86 (0.70)          0.10      0.02  0.66 (0.02) *** \n##       17          1        87 (0.71)          0.03      0.02  0.66 (0.02) *** \n##       18          2        89 (0.73)          0.06      0.02  0.63 (0.02) *** \n##       19          3        92 (0.75)          0.09      0.02  0.60 (0.02) *** \n##       20          5        97 (0.80)          0.17      0.02  0.54 (0.02) *** \n## -----------------------------------------------------------------------------\n##  Left censoring  : 0.02 (2)\n##  Right centoring : 0.20 (25)\n##  # of nodes      : 122\n## \n##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic\n##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.\nplot_adopters(diffnet_road)\ndiffnet_road$toa##   n0  n73  n27  n77  n59   n1  n20  n70   n2  n64  n57  n46  n88   n3  n28   n4 \n##   14   15   13   14   15   15   15   14    8    8   13    7    7    8    9   18 \n##  n16  n33  n52  n29   n5  n85  n15   n6  n86   n7  n83  n30   n8  n81  n60   n9 \n##   19   18   17   19   NA   NA   NA    6    5   NA   NA   NA   12   11   13   11 \n##  n74  n75  n76  n78  n10  n42  n35  n38  n31  n11  n24  n12  n79  n13  n48  n23 \n##   11   12   12   10   11   12   12   10   12    6    5    4    3   NA   20   15 \n##  n36  n47  n14  n17  n55  n69  n39  n19  n53  n54  n18  n72  n21  n40  n67  n22 \n##   20   NA    9   10   NA   20   19   20   15   13   NA   NA   NA   20   NA   13 \n##  n84  n25  n49  n26  n80  n66  n32  n34  n44  n71  n37  n56  n41  n50  n43  n45 \n##   14   13   14   NA   12   NA   NA    1    2    2   16    9    1    2    4    9 \n##  n82  n61  n87  n51  n62  n63  n58  n65  n68  n89  n90  n91  n92  n93  n94  n95 \n##    8   10   10    8    9   NA   13   11    9   11   NA   NA    2    4   10    9 \n##  n96  n97  n98  n99 n100 n101 n102 n103 n104 n105 n106 n107 n108 n109 n110 n111 \n##   14   NA   NA   11   NA    6   NA   NA    8   16   NA   16    5    9    2    7 \n## n112 n113 n114 n115 n116 n117 n118 n119 n120 n121 \n##   10   10   13   12   12   16   13    8    2   14\nlibrary(ggmap)\nlibrary(ggrepel)\n\nggmap(my_map) +\n  # geom_segment plots lines by the beginning and ending\n  # coordinates like the edges object we created above\n  geom_segment(\n    data = edges1,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  # plot site node locations\n  geom_point(\n    data = xy,\n    aes(x, y, color = diffnet_road$toa),\n    alpha = 0.8,\n    shape = 16,\n    size = 3,\n  ) +\n  scale_color_viridis_c(option = \"plasma\") +\n  geom_text_repel(aes(x = x, y = y, label = row.names(xy)),\n                  data = xy,\n                  size = 3) +\n  theme_void()\nset.seed(44336)\ndiffnet_road <- rdiffnet(\n  seed.graph = as.matrix(road_net3),\n  t = 20,\n  seed.nodes = c(6, 7),\n  threshold.dist = rep(0.25, 122),\n  rewire = FALSE\n)\n\nplot_adopters(diffnet_road)\nggmap(my_map) +\n  # geom_segment plots lines by the beginning and ending\n  # coordinates like the edges object we created above\n  geom_segment(\n    data = edges1,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"black\",\n    size = 1\n  ) +\n  # plot site node locations\n  geom_point(\n    data = xy,\n    aes(x, y, color = diffnet_road$toa),\n    alpha = 0.8,\n    shape = 16,\n    size = 3,\n  ) +\n  scale_color_viridis_c(option = \"plasma\") +\n  geom_text_repel(aes(x = x, y = y, label = row.names(xy)),\n                  data = xy,\n                  size = 3) +\n  theme_void()"},{"path":"NetworkDiffusion.html","id":"EvaluatingDiffusion","chapter":"Section 11 Network Diffusion","heading":"11.3 Evaluating Diffusion Models","text":"Frequently, evaluating diffusion processes empirical networks, goal compare formal model simulation diffusion process empirical information regarding nodes, edges, network level metrics. provide example can look like, use Chaco World data specifically minimum distance network created Spatial Networks section defined edges among Chacoan architectural complexes (ca. .D. 1050-1150) within 36 kilometers (represents one day walk foot). period question peak distribution Chacoan complexes across region. added one additional attribute data set beginning ending date Chacoan complex. use information evaluate diffusion models . Download data follow along.Let’s start loading data mapping :Next, create diffusion network object using rdiffnet function. plot use maximum distance network matrix (36 kilometers) called d36 seed.graph set initial nodes include architectural complexes within Chaco Canyon, core Chaco World location earliest formal Great Houses. set threshold distance nodes adopt least one neighbor adopted set rewire = FALSE. run model 20 time steps.Let’s run function take look adopter plot:shows, parameters provided lead relatively quick adoptions followed leveling . Notably, nodes adopt disconnected components within network.Now let’s take look map color coded time adoption:map clearly shows spatial pattern sites south Chaco Canyon early adopters sites north relatively late adopters.order evaluate next want assess time adoption nodes relation attribute data. one approach can take use classify function built netdiffuseR place nodes set categories based time adoption. categories : Early Adopters, Early Majority, Late Majority, Laggards Non-Adopters.Next, order investigate different adopters related node attributes create data frame containing toa_class values well beginning dates site create box plot beginning date toa_class.box plot illustrates, sites “Early Adopter” “Early Majority” category include vast majority sites earlier starting dates though median across groups. may suggest network distance Chaco Canyon (originated “contagion” earliest Great Houses found) may factor establishment Chacoan complexes outside Chaco. Course, wanted take need assess variable roles spatial distance, network distance, perhaps even consider material cultural similarity data. point, however, brief example least points interesting pattern worth investigation. , example demonstrates one simple approach used compare diffusion models archaeological data.scratched surface network methods can used study diffusion . many advanced models may relevant archaeological analysis including many interesting Epidemiological Models likely work well archaeological context considerations sorts contagions (social biological). hope brief examples promote exploration approaches.","code":"\nlibrary(igraph)\nlibrary(ggmap)\nlibrary(sf)\nlibrary(dplyr)\n\nload(file = \"data/Chaco_net.Rdata\")\n\nchaco_map <- ggmap(base, darken = 0.15) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"white\",\n    size = 0.10,\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y),\n    alpha = 0.65,\n    size = 1,\n    col = \"red\",\n    show.legend = FALSE\n  ) +\n  theme_void()\nchaco_map\nchaco <- which(attr$CSN_macro_group == \"Chaco Canyon\")\n\nset.seed(443)\ndiffnet_chaco <- rdiffnet(\n  seed.graph = as.matrix(d36),\n  t = 20,\n  seed.nodes = chaco,\n  threshold.dist = function(i) 1L,\n  rewire = FALSE,\n  exposure.args = list(normalized = FALSE)\n)\n\nsummary(diffnet_chaco)## Diffusion network summary statistics\n## Name     : A diffusion network\n## Behavior : Random contagion\n## -----------------------------------------------------------------------------\n##  Period   Adopters   Cum Adopt. (%)   Hazard Rate   Density   Moran's I (sd)  \n## -------- ---------- ---------------- ------------- --------- ---------------- \n##        1         10        10 (0.04)             -      0.08  0.08 (0.01) *** \n##        2         40        50 (0.22)          0.19      0.08  0.42 (0.01) *** \n##        3         23        73 (0.33)          0.13      0.08  0.46 (0.01) *** \n##        4         29       102 (0.46)          0.19      0.08  0.56 (0.01) *** \n##        5         13       115 (0.52)          0.11      0.08  0.59 (0.01) *** \n##        6         13       128 (0.57)          0.12      0.08  0.62 (0.01) *** \n##        7         20       148 (0.66)          0.21      0.08  0.62 (0.01) *** \n##        8         25       173 (0.78)          0.33      0.08  0.64 (0.01) *** \n##        9         12       185 (0.83)          0.24      0.08  0.64 (0.01) *** \n##       10          5       190 (0.85)          0.13      0.08  0.64 (0.01) *** \n##       11          6       196 (0.88)          0.18      0.08  0.66 (0.01) *** \n##       12          3       199 (0.89)          0.11      0.08  0.73 (0.01) *** \n##       13          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       14          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       15          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       16          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       17          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       18          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       19          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n##       20          0       199 (0.89)          0.00      0.08  0.73 (0.01) *** \n## -----------------------------------------------------------------------------\n##  Left censoring  : 0.04 (10)\n##  Right centoring : 0.11 (24)\n##  # of nodes      : 223\n## \n##  Moran's I was computed on contemporaneous autocorrelation using 1/geodesic\n##  values. Significane levels  *** <= .01, ** <= .05, * <= .1.\nplot_adopters(diffnet_chaco)\nchaco_map2 <- ggmap(base, darken = 0.15) +\n  geom_segment(\n    data = edges,\n    aes(\n      x = X1,\n      y = Y1,\n      xend = X2,\n      yend = Y2\n    ),\n    col = \"white\",\n    size = 0.10,\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = xy,\n    aes(x, y, color = diffnet_chaco$toa),\n    alpha = 0.65,\n    size = 2,\n  ) +\n  scale_color_viridis_c(option = \"plasma\") +\n  theme_void()\n\nchaco_map2\ntoa_class <-\n  factor(\n    classify(diffnet_chaco)$toa,\n    levels = c(\n      \"Early Adopters\",\n      \"Early Majority\",\n      \"Late Majority\",\n      \"Laggards\",\n      \"Non-Adopters\"\n    )\n  )\n\ntable(toa_class)## toa_class\n## Early Adopters Early Majority  Late Majority       Laggards   Non-Adopters \n##             50             65             33             51             24\ndf <- data.frame(BeginDate = attr$Begin, Category = toa_class)\n\nlibrary(ggplot2)\n\nggplot(data = df) +\n  geom_boxplot(aes(y = BeginDate, fill = Category)) +\n  theme_bw()"},{"path":"ComparingNetworks.html","id":"ComparingNetworks","chapter":"Section 12 Comparing Networks","heading":"Section 12 Comparing Networks","text":"can systematically quantitatively compare network configurations node/edge structural positions? Can compare networks even represent different kinds phenomena vastly different numbers nodes edges? best metrics use comparisons (.e., graph level vs. node/edge level metrics)? Can capture global network properties local structures comparisons? common questions world network research recent years. surprising one exciting aspects networks general realization many networked systems share common properties dynamics despite representing wholly different kinds relations social biological systems. Identifying specifying relative similarity distance among different networks, thus, likely get us quite far.increased interest developing models directly comparing networks recent years (see Tantardini et al. 2019). work quite variable can generally grouped two sets approaches:Known Node Correspondence - Methods focused comparing network configurations share common set nodes (least sub-set nodes common).Unknown Node Correspondence - Methods focused comparing networks represented different sets nodes, can differ dramatically size, content, nature ties.lots methods approaches importantly, considerable methodological work focused methods identify work best characterizing comparing important dimensions network variability different contexts (e.g., Milenković Pržulj 2008; Milenković et al. 2010; Pržulj 2007; Tantardini et al. 2019; Trpevski et al. 2016; Yaveroğlu et al. 2014). section, briefly explore “known node correspondence (KNC)” “unknown node correspondence (UNC)” methods (borrowing useful terminology Tantardini et al. 2019) potential utility approaches archaeological network research.\nMany methods outlined section fairly\ncomputationally intensive involve iterative calculations scale\nrapidly complexity size networks involved. Although\nimplementations many methods R, analyses\nefficient readily available Python \nlanguages. fear! R-Studio built-ability run\nPython scripts use Python libraries show works \nexamples . Using package called reticulate \nrelatively easy move back forth R Python.\n","code":""},{"path":"ComparingNetworks.html","id":"KnownNode","chapter":"Section 12 Comparing Networks","heading":"12.1 Known Node Correspondence Methods","text":"section, outline potential analytical approaches can take networks share nodes substantial sub-set nodes common. Approaches vein frequently used comparing different layers multi-layer networks different temporal slices dynamic networks. kinds data common archaeology methods likely much offer.","code":""},{"path":"ComparingNetworks.html","id":"CompareAdjacencyMatrices","chapter":"Section 12 Comparing Networks","heading":"12.1.1 Direct Comparison of Adjacency Matrices","text":"simplest approach comparing networks common set nodes simply directly evaluate differences underlying adjacency matrices. example, can simply take absolute difference one matrix normalize based distance metric. Importantly simple approach works simple binary networks, directed networks, well weighted networks.example use three time slices ceramic similarity network Southwest Social Networks Project San Pedro region dating AD1250-1300, AD1300-1350, AD1350-1400 respectively. network object named based first year 50 year interval represents. network slices nodes common nodes present interval identical. Thus, first create function called network_subset_common requires two network objects name attribute outputs list two networks include nodes two overlap. Let’s start importing data finding common networks every combination three time slices. output objects named net followed year indicating first 50 year interval included, _, year indicating second 50 year interval. make lists consecutive intervals non-consecutive intervals. Download data follow along:order make comparisons, next extract adjacency matrices network list objects interest. Let’s start comparing AD1250-1300 AD1300-1350. First extract matrices:Next, find absolute value difference two adjacency matrices:Now can simply identify number proportion edges differ two adjacency matrices. metric can formally defined :\\[S = 1- \\frac{\\Sigma | ^1_{ij} - ^2_{ij}|}{n(n-1)}\\]\\(^1_{ij}\\) \\(^2_{ij}\\) adjacency matrices identical sets nodes.\\(n\\) number nodesLet’s take look using matrices created :number let’s us know proportion ties common two networks 0.82.can roll whole process function ease use. function use expects two adjacency matrices node set.results show, comparison AD1250-1300 AD1300-1350 showed overlap, followed AD1300-1350 AD1350-1400 interval overlap 0.63 finally non-sequential comparison AD1250-1300 AD1350-1400 overlap 0.47.procedure also works weighted networks, directed networks, form one-mode network. next chunk code create two random weighted networks, convert adjacency matrices compare using function:basic adjacency matrix comparison approach can help us get sense similar different networks account direction difference provide means interpreting difference relation network structure. see, examples extend basic approach several ways allow us consider features network data.","code":"\nlibrary(statnet)\n\nload(\"data/SanPedro_nets.Rdata\")\n\nnetwork_subset_common <-\n  function(net1, net2, namevar = \"vertex.names\") {\n    net1_names <-\n      network::get.vertex.attribute(net1, attrname = namevar)\n    net2_names <-\n      network::get.vertex.attribute(net2, attrname = namevar)\n    common_names <- net1_names[which(net1_names %in% net2_names)]\n    out1 <- net1 %s% which(net1 %v% namevar %in% common_names)\n    out2 <- net2 %s% which(net2 %v% namevar %in% common_names)\n    return(list(out1, out2))\n  }\n\nnet1250_1300 <-\n  network_subset_common(AD1250net, AD1300net, namevar = \"vertex.names\")\nnet1300_1350 <-\n  network_subset_common(AD1300net, AD1350net, namevar = \"vertex.names\")\nnet1250_1350 <-\n  network_subset_common(AD1250net, AD1350net, namevar = \"vertex.names\")\nnet1 <- as.matrix(net1250_1300[[1]])\nnet2 <- as.matrix(net1250_1300[[2]])\nnet_diff <- abs(net1-net2)\n\n# Let's look at the first 4 rows and columns\nnet_diff[1:4, 1:4]##               Artifact Hill Ash Terrace Bayless Ruin Big Bell\n## Artifact Hill             0           1            0        0\n## Ash Terrace               1           0            0        0\n## Bayless Ruin              0           0            0        0\n## Big Bell                  0           0            0        0\n1 - (sum(net_diff) / (nrow(net_diff) * (nrow(net_diff) - 1)))## [1] 0.8205128\nadjacency_compare <- function(net1, net2) {\n  net_diff <- abs(net1 - net2)\n  out <-\n    1 - (sum(net_diff) / (nrow(net_diff) * (nrow(net_diff) - 1)))\n  return(out)\n}\n\n# Run function for comparing AD1300-1350 to AD1350-1400\nadjacency_compare(as.matrix(net1300_1350[[1]]),\n                  as.matrix(net1300_1350[[2]]))## [1] 0.625731\n# Run function for comparing AD1250-1300 and AD1350-1400\nadjacency_compare(as.matrix(net1250_1350[[1]]),\n                  as.matrix(net1250_1350[[2]]))## [1] 0.474359\nlibrary(igraph)\nset.seed(3464)\nrnet1 <- erdos.renyi.game(n = 40, p.or.m = runif(1))\nE(rnet1)$weight <- sample(1:5, ecount(rnet1), replace = TRUE)\n\nrnet2 <- erdos.renyi.game(n = 40, p.or.m = runif(1))\nE(rnet2)$weight <- sample(1:5, ecount(rnet2), replace = TRUE)\n\npar(mfrow=c(1,2))\nplot(rnet1)\nplot(rnet2)\npar(mfrow=c(1,1))\n\nra1 <- as_adjacency_matrix(rnet1, sparse = FALSE)\nra2 <- as_adjacency_matrix(rnet2, sparse = FALSE)\n\nadjacency_compare(ra1, ra2)## [1] 0.5051282"},{"path":"ComparingNetworks.html","id":"QAP","chapter":"Section 12 Comparing Networks","heading":"12.1.2 Quadratic Assignment Procedure","text":"quadratic assignment procedure (QAP) method evaluating network correlations network metrics among two networks node-set using Monte Carlo simulation methods. R, QAP function test available statnet package function called qaptest.Using lists network objects node-set defined last example, can make assessments similarity using gcor graph correlation function sna package. function gives number -1 1 indicates degree direction similarity edges two networks. two networks present absent edges common, get value 1 absence presence reversed (active edges net1 inactive net2 inactive edges net1 active net2) get value -1.results show, AD1250-1300 AD1300-1350 reasonably similar graph correlation 0.63 AD1300-1350 AD1350-1400 less similar correlation 0.39. compare non-sequential intervals AD1250-1300 AD1350-1400 see even lower similarity 0.21. Notably values positive. question remains, however, might interpret values. example, two nearly complete nearly empty networks potentially get high graph correlation chance. QAP test designed deal specifically issue.QAP test creates large number random versions two imported network objects (randomly switching node label assignments keeping network structure) calculates graph correlation (graph level function) random versions networks every simulation (number simulations set 1000 default). logic behind randomly shuffling network labels generated new networks frequently produced graph correlation values high higher observed, suggest correlation observed networks easily generated chance given network size density. , hand, random network label shufflings produced correlations high higher observed correlation, used reject null hypothesis relationship graphs random.Let’s give shot three comparisons discuss results:value ’re interested top p-value simulated probability obtaining correlation high higher observed randomly shuffled versions network. first two comparisons temporally sequenced periods show simulated p-values near 0 suggesting low probability obtaining correlations high observed shuffled networks. comparison non-consecutive AD1250-1300 AD1350-1400 intervals, however, get considerably higher probability p = 0.093. results indicate 93 1000 random network label shuffles correlation value high higher observed recorded. light probably put much weight behind correlation periods. function documentation suggests, QAP results interpreted indicative underlying structural differences networks, instead simply differences particular node labeling schema controlling structural differences (labels shuffled actual network structures).Finally, can plot visualization QAP test provides density plot correlation values produced random replication along dotted line representing observed value:QAP potentially useful identifying whether given similarity graph level metric two graphs statistically significant, also problems method results can also vary relation size topological nature networks question (see Anderson et al. 1999).","code":"\ngcor(net1250_1300)[[2]]## [1] 0.6266283\ngcor(net1300_1350)[[2]]## [1] 0.3873585\ngcor(net1250_1350)[[2]]## [1] 0.2070197\nset.seed(43673)\n\nqap1250_1300 <- qaptest(net1250_1300, gcor, g1 = 1, g2 = 2)\nqap1250_1300## \n## QAP Test Results\n## \n## Estimated p-values:\n##  p(f(perm) >= f(d)): 0 \n##  p(f(perm) <= f(d)): 1\nqap1300_1350 <- qaptest(net1300_1350, gcor, g1 = 1, g2 = 2)\nqap1300_1350## \n## QAP Test Results\n## \n## Estimated p-values:\n##  p(f(perm) >= f(d)): 0.001 \n##  p(f(perm) <= f(d)): 1\nqap1250_1350 <- qaptest(net1250_1350, gcor, g1 = 1, g2 = 2)\nqap1250_1350## \n## QAP Test Results\n## \n## Estimated p-values:\n##  p(f(perm) >= f(d)): 0.093 \n##  p(f(perm) <= f(d)): 0.967\nplot(qap1250_1300, xlim = c(-1, 1))\nplot(qap1300_1350, xlim = c(-1, 1))\nplot(qap1250_1350, xlim = c(-1, 1))"},{"path":"ComparingNetworks.html","id":"DeltaCon","chapter":"Section 12 Comparing Networks","heading":"12.1.3 DeltaCon","text":"Another method comparing networks common node-set recently gained popularity DeltaCon approach (Koutra et al. 2016). method similar direct comparison adjacency matrices except based commonality paths networks rather just specific edges. underlying assumption simply matching first degree connections doesn’t capture true similarities differences networks capturing paths various lengths likely provide better assessment structural similarities differences among networks. Much like adjacency matrix methods DeltaCon ranges 0 1 provides indication strength association two networks.analytical details justification DeltaCon beyond scope guide direct original paper method defined details. Luckily, GitHub user Baoxu “Dash” Shi already created R function calculate DeltaCon available . ported function script simplified somewhat repository use simplified version . Note function relies three packages must installed use function: Matrix, SparseM, pracma.function expects two numeric edge lists representing networks node set also must indicate number nodes (unconnected nodes/isolates can also considered). Let’s give try San Pedro network data imported . Click download modified version script used . input expected two matrix objects form adjaency matrix set nodes:get value 0.86 just little higher adjacency matrix comparison. Now let’s try interval comparisons:Interestingly, compare results simple adjacency matrix comparison see pretty big differences. adjacency matrix comparison non-consecutive intervals least similar three comparisons overlap proportion 0.47. DeltaCon comparison actually higher AD1300-1350 AD1350-1400 comparison. suggests , although may first order differences nodes non-sequential networks, perhaps slightly greater similarities longer paths two. example illustrates making multiple comparisons different approaches can sometimes reveal unexpected insights.","code":"\nsource(\"scripts/delta_con.R\")\n\nel1 <- as.matrix(net1250_1300[[1]])\nel2 <- as.matrix(net1250_1300[[2]])\n\ndelta_con(el1, el2)## [1] 0.8639706\nel1 <- as.matrix(net1300_1350[[1]])\nel2 <- as.matrix(net1300_1350[[2]])\n\ndelta_con(el1, el2)## [1] 0.6645235\nel1 <- as.matrix(net1250_1350[[1]])\nel2 <- as.matrix(net1250_1350[[2]])\n\ndelta_con(el1, el2)## [1] 0.6992425"},{"path":"ComparingNetworks.html","id":"UnknownNode","chapter":"Section 12 Comparing Networks","heading":"12.2 Unknown Node Correspondence","text":"Although methods comparing networks common node-set useful, perhaps common use case network comparison considers networks nodes even size. Indeed, network analysts frequently interested characterizing similarity differences among networks entirely different sources (example, comparing road networks internet). variety methods designed use case highlight useful drawing methodological comparison methods presented Tantardini et al. 2019. Many methods outlined Tantardini colleagues available R even available Python anyone considering seriously investigating approaches archaeological data probably want use Python (show can use Python within R-Studio ).","code":""},{"path":"ComparingNetworks.html","id":"ComparingStatistics","chapter":"Section 12 Comparing Networks","heading":"12.2.1 Comparing Network Global and Local Statistics","text":"Perhaps simplest common means comparing networks simply compare different network metrics properties networks (standardized network size type). example, calculate density two networks compare values get sense relate (least terms one feature). Alternatively, calculate node edge based metrics like centrality compare resulting distributions. already shown several examples type comparison Exploratory Network Analysis section document Roman Roads Case Study. example, happened using three networks node-set certainly required.chunk code reproduce net_stats function calculating range network metrics Exploratory\nNetwork Analysis section calculate stats San Pedro time-slice networks.Since San Pedro networks network format objects use intergraph package convert igraph objects function expects.Data like can useful making general comparisons networks. example, can see major differences density among time periods. ratio open closed triads differs dramatically time.Another simple approach frequently used comparing networks compare distributions node edge level statistics. example, can compare degree distributions among networks using simple histogram visuals:quick glance three plots shows degree distributions differ magnitude direction skew among three intervals. take examining features distributions detail may provide additional information differences network structures potential generative processes.Simple comparisons like shown often good first step, can difficult know make differences metrics distributions. next several examples, present approaches designed provide information help put single metric/feature comparisons context.","code":"\nlibrary(igraph)\n\nnet_stats <- function(net) {\n  out <- matrix(NA, 10, 2)\n  out[, 1] <- c(\"Nodes\", \"Edges\", \"Isolates\", \"Density\", \"Average Degree\",\n               \"Average Shortest Path\", \"Diamater\",\n               \"Clustering Coefficient\", \"Closed Triad Count\",\n               \"Open Triad Count\")\n  # number of nodes\n  out[1, 2] <- vcount(net)\n  # number of edges\n  out[2, 2] <- ecount(net)\n  # number of isolates\n  out[3, 2] <- sum(igraph::degree(net) == 0)\n  # network density rounding to the third digit\n  out[4, 2] <- round(edge_density(net), 3)\n  # mean degree rounding to the third digit\n  out[5, 2] <- round(mean(igraph::degree(net)), 3)\n  # mean shortest path length rounding to the third digit\n  out[6, 2] <- round(igraph::mean_distance(net), 3)\n  # network diameter\n  out[7, 2] <- igraph::diameter(net)\n  # average global transitivity rounding to the third digit\n  out[8, 2] <- round(igraph::transitivity(net, type = \"average\"), 3)\n  # closed triads in triad_census\n  out[9, 2] <- igraph::triad_census(net)[16]\n  # open triads in triad_census\n  out[10, 2] <- igraph::triad_census(net)[11]\nreturn(out)\n}\nlibrary(intergraph)\n\nns1 <- net_stats(asIgraph(AD1250net))\nns2 <- net_stats(asIgraph(AD1300net))\nns3 <- net_stats(asIgraph(AD1350net))\n\nns_res <- cbind(ns1, ns2[, 2], ns3[, 2])\ncolnames(ns_res) <- c(\"Measure\", \"AD1250-1300\", \"AD1300-1350\",\n                      \"AD1350-1400\")\n\nknitr::kable(ns_res, format = \"html\")\nhist(\n  sna::degree(AD1250net, rescale = TRUE),\n  main = \"AD1250-1300\",\n  xlab = \"Degree\"\n)\nhist(\n  sna::degree(AD1300net, rescale = TRUE),\n  main = \"AD1300-1350\",\n  xlab = \"Degree\"\n)\nhist(\n  sna::degree(AD1350net, rescale = TRUE),\n  main = \"AD1350-1400\",\n  xlab = \"Degree\"\n)"},{"path":"ComparingNetworks.html","id":"NetworkKernel","chapter":"Section 12 Comparing Networks","heading":"12.2.2 Graph Kernel Methods","text":"network (graph) kernel function measures similarity pair networks based comparisons vectors representing specific features networks. practice represents inner product two vectors representing relevant feature (single dimension) networks. explain works let’s consider hypothetical example want compare set books various topics determine similar book books. Say books digital text files previously read . might begin? One relatively simple approach (simple computer least) tabulate words book compare frequency distributions book others. -called “bag words” approach similarities books defined structure content simply overlap word frequency. Two books fishing likely words common book fishing another nuclear physics. can extend general line thinking networks create “bag graphs” representation underlying network provide vectors comparison (see Silva et al. 2018).Let’s start relatively simple example. Let’s say interested defining kernel comparing two networks based “graphlet” representation. graphlet simply set possible configurations set nodes can take given \\(k\\) number nodes. example, 3 nodes following graphlets possible configurations:two graphs, compare number times configurations appears. Let’s make couple small random graphs try :Now can tabulate number graphets configuration 0 3 denoted graph vector:\\[\\begin{aligned}\nf_{G1} =& (0, 4, 8, 8) \\\\\nf_{G2} =& (0, 3, 6, 1)\n\\end{aligned}\\]Now need account size network number graphlets can divide graphlet counts total number graphlets network:\\[\\begin{aligned}\nf_{G1} =& (0, 4, 8, 8) / 20 = (0, 0.2, 0.4, 0.4) \\\\\nf_{G2} =& (0, 3, 6, 1) / 10 = (0, 0.3, 0.6, 0.1)\n\\end{aligned}\\]Now create can create kernel describing relationship two graphs calculating inner product transpose vector first graph vector second graph:\\[K(G1,G2) = F_{G1}^T \\cdot F_{G2} = 0.34\\]case returned value 0.34 graphlet kernel \\(k=3\\).many kinds kernels can calculated networks. example, can calculate shortest path kernel determines many shortest paths length 1 diameter network (standardized total number shortest paths possible) networks. , create random walk kernel generating number random walks networks simultaneously quantifying number matching walks. many different types kernels can calculated networks details described elsewhere (see Ghosh et al. 2018).\npackage graphkernels provides set 14 graph\nkernel calculation methods can calculated R Python.\npackage works using igraph network objects expects\nlist networks grouped single object. use R\nimplementation example .\nchunk code , convert San Pedro network objects igraph network format calculate graphlet kernel \\(k=3\\), random walk kernel, finally shortest path kernel. results provided symmetric matrix can evaluate comparisons networks looking row column corresponding item number list provided function. values terms whatever measure provide (e.g., number length random walks, proportional overlap graphlets, etc.) general, larger numbers indicate greater similarity networks given feature.Let’s give try:results show, rank-order kernel values different metrics , despite using networks. illustrates, single graph kernel doesn’t typically paint whole picture graphs can similar features others. many graph kernel methods available likely profitable archaeological network analysts explore methods greater detail.","code":"\nset.seed(4354)\ng1 <- erdos.renyi.game(6, 0.6)\ng2 <- erdos.renyi.game(5, 0.4)\n\nplot(g1)\nplot(g2)\nfg1 <- c(0, 4, 8, 8)\nfg1 <- fg1 / sum(fg1)\n\nfg2 <- c(0, 3, 6, 1)\nfg2 <- fg2 / sum(fg2)\n\nt(fg1) %*% fg2##      [,1]\n## [1,] 0.34\nlibrary(graphkernels)\nlibrary(intergraph)\ng <- list(asIgraph(AD1250net), asIgraph(AD1300net), asIgraph(AD1350net))\n\nk_graphlet <- CalculateGraphletKernel(g, par = 3)\n\nk_rw <- CalculateGeometricRandomWalkKernel(g, par = 0.00001)\n\nk_sp <- CalculateShortestPathKernel(g)\n\nout <- matrix(NA, nrow = 3, ncol = 3)\n\nout[1, 1] <- k_graphlet[1, 2]\nout[2, 1] <- k_graphlet[2, 3]\nout[3, 1] <- k_graphlet[1, 3]\n\nout[1, 2] <- k_rw[1, 2]\nout[2, 2] <- k_rw[2, 3]\nout[3, 2] <- k_rw[1, 3]\n\nout[1, 3] <- k_sp[1, 2]\nout[2, 3] <- k_sp[2, 3]\nout[3, 3] <- k_sp[1, 3]\n\nrow.names(out) <-\n  c(\"AD1200-1250, 1300-1350\",\n    \"AD1300-1350, 1350-1400\",\n    \"AD1250-1300, 1350-1400\")\ncolnames(out) <- c(\"graphlets\", \"random walks\", \"shortest paths\")\n\nknitr::kable(out, \"html\")"},{"path":"ComparingNetworks.html","id":"SpectralMethods","chapter":"Section 12 Comparing Networks","heading":"12.2.3 Spectral Methods","text":"network spectrum complex set functions based eigenvalues network describe structural properties network \\(n\\) fewer dimensions \\(n\\) number nodes network. Many approaches network comparison rely network spectra. short can think spectrum set values describe relationships network based linear transformations underlying adjacency matrix can compared different networks. full explanation eigenvectors eigenvalues beyond scope document (check good video explanation) short, eigenvectors (\\(\\overrightarrow v\\)) eigenvalues (\\(\\lambda\\)) adjacency matrix (\\(\\)) satisfy following equation:\\[\\begin{aligned}\n\\overrightarrow v = &  \\lambda \\overrightarrow v \\\\\n\\overrightarrow v - \\lambda \\overrightarrow v =  &  0\n\\end{aligned}\\], adjacency matrix multiplied eigenvector equal eigenvalue multiplied eigenvector. two dimensions, can visualize might work imagining stretch shear image particular direction evaluate outcome specific vectors along image. Mona Lisa example apply shearing transformation famous painting, points along red axis longer along directional vector transformation. Points along blue axis, however, still exactly transformation. Thus, blue vector eigenvector. case re-scaled image points along blue vector place images. Thus, eigenvalue 1. sheared pictures see also scaled picture factor 2 eigenvalue blue vector 2 meaning particular pixel point (0,1) first image point (0,2) sheared scaled image.want extend three dimensional space imagine rotating cube direction around random axis. think every point within cube coordinates 3D space, points remain along vector rotation fall along axis rotation. eigenvector transformation. expand shrink shape making rotation, scaling factor represent eigenvalue.apply approach larger n-dimensional space like adjacency matrix representing \\(n\\) nodes becomes bit harder visualize underlying principle . set eigenvalues (length \\(n\\) \\(n\\) x \\(n\\) adjacency matrix) ordered largest smallest spectrum matrix. hand two graphs, can simply find Euclidean distance :\\[d(G_1,G_2) = \\sqrt{\\Sigma_i(s_i^{(1)}-s_i^{(2)})^2} \\]\\(s_i^{(1)}\\) spectrum graph 1 (\\(G_1\\)) ordered largest smallest\\(s_i^{(2)}\\) spectrum graph 2 (\\(G_2\\)) ordered longest smallest.one spectrum vector longer vector can padded zeros maintaining ordering.Spectral comparisons useful comparing graphs different sizes issues including fact different graphs can spectra small changes graph structure can sometimes result large changes spectra. Despite potential problems methods still common, especially comparisons large graphs can calculated efficiently.take one step , many graph-based spectral comparison methods based adjacency matrix directly, instead derivations matrix highlight special features. example, many methods based called Laplacian matrix. Laplacian matrix degree matrix graph minus adjacency matrix graph. degree matrix defined \\(n\\) x \\(n\\) matrix entries outside diagonal 0 values along diagonal represent degree network node. methods described can used find eigenvector eigenvalues Laplacian matrix simply replacing matrix adjacency matrix (\\(\\)) equation .existing packages allow assessments spectral-based graph comparisons. found many useful efficient limited Python rather R. Thus, take opportunity explore Python scripts can used within R-Studio using R objects using package called reticulate.\nR package reticulate designed help move\nobjects functions back forth R Python environments\ncomputer. order use reticulate need \ninstall R package also install instance Python >= 3.8\ncomputer. easiest way install Python machine \ndon’t already use \nreticulate::install_miniconda() right R console. Check \ndetails.\nLet’s first initialize reticulate package:point install Python already done using reticulate::install_miniconda() command. Python installed need install Python package called NetLSD (Network Laplacian Spectral Descriptors). easiest way click “Terminal” panel R-Studio instance type following command directly terminal (need instance R-Studio):goes well, install NetLSD Python package instance Python associated R-Studio installation call Python commands either directly terminal using special functions built reticulate package. package calculates spectral distance networks using version Laplacian matrix described define eigenvalues graph.First, let’s create network objects R can use Python environment. case need adjacency matrices NetLSD package:\nR Markdown document R-Studio can create block \nspecify Python code simply changing initial r\ninside {r} {python}.\nNow ’ve created objects R, can run functions Python. following chunk code actually Python rather R although looks relatively similar. first lines consist import commands tell Python initialize required packages use (much like library() function R).Next, create Python objects R objects. object R global environment can called within Python R-Studio using prefix r. name object. code , define Python object called graph1 based R object called g1 using r.g1 command.next line codes represent functions within Python package installed. First call function called heat within netlsd package adding netlst.heat() providing object function calculated parentheses. Next calculate Laplacian spectral distance two graphs using function numpy package (imported shortened name np) typing np.linalg.norm. Just like R, can assign result object type name object report output screen.results show Laplacian spectral distance three temporal networks. Smaller numbers indicate less distance numbers bounded upper end. results show distance AD1300-1350 AD1350-1400 smallest (meaning graphs similar measure) comparison non-consecutive intervals greatest.advantage spectral method comparison summary overall structural properties network rather particular feature saw graph kernel methods.Importantly, metric also used compare graphs differ dramatically size scale well. next chunk code import networkx package nx create random graph 1000 nodes using Barabasi-Albert algorithm. compare original 13 node network AD1250-1300 show can compare networks dramatically different sizes. Note eigenvalues first 13 San Pedro network defined 0.certainly exhausted possibilities spectral graph comparison . particular, currently unclear network summaries work networks features like common archaeological networks (example, similarity networks high degrees closure). spectral methods perform differently networks different structural tendencies, evaluation archaeological networks mind useful.","code":"\nlibrary(reticulate)## Warning: package 'reticulate' was built under R version 4.2.3pip install netlsd\ng1 <- as.matrix(AD1250net)\ng2 <- as.matrix(AD1300net)\ng3 <- as.matrix(AD1350net)## [1] TRUE## [1] TRUEimport netlsd\nimport numpy as np\n\ngraph1 = r.g1\ngraph2 = r.g2\ngraph3 = r.g3\n\ndesc1 = netlsd.heat(graph1)\ndesc2 = netlsd.heat(graph2)\ndesc3 = netlsd.heat(graph3)\n\ndistance1_2 = np.linalg.norm(desc1 - desc2) \ndistance1_2## 0.9955321810540249distance2_3 = np.linalg.norm(desc2 - desc3) \ndistance2_3## 0.2568554438667868distance1_3 = np.linalg.norm(desc1 - desc3) \ndistance1_3## 1.1791128279165486import networkx\nimport netlsd\n\n# create a random graph with 1000 nodes\ng4 = networkx.barabasi_albert_graph(1000, m = 20, seed = 13) \ndesc4 = netlsd.heat(g4)\n\ndistance_new = np.linalg.norm(desc1 - desc4) \ndistance_new## 1.6539873180732085"},{"path":"ComparingNetworks.html","id":"PortraitDivergence","chapter":"Section 12 Comparing Networks","heading":"12.2.4 Portrait Divergence","text":"Another recently developed method attempts provide overall metric network relationships referred portrait divergence approach (Bagrow et al. 2018). approach defines divergence among two networks non-overlapping nodes based distribution shortest path lengths network. Specifically, method creates network “portrait” matrix \\(B_{lk}\\) \\(l\\) integer vector \\(0\\) network diameter \\(d\\) \\(k\\) vector \\(0\\) \\(N-1\\) \\(N\\) number nodes \\(k\\) shortest path distance \\(l\\). metric can also used weighted directed networks. Using matrix \\(B_{lk}\\) portrait divergence defined :\\[P(k,l) = P(k|l)P(l) = \\frac {1}{N}B_{lk} \\frac {1}{\\Sigma_c n^2_c}\\Sigma_k k'B_{lk'}\\]\\(P(k,l)\\) probability choosing two nodes random distance \\(l\\) one two nodes selected \\(k\\) nodes distance \\(l\\). \\(Q(k,l)\\) represents probability network two.\\(N\\) number nodes network.\\(n_c\\) number nodes connected component \\(c\\).Portrait convergence calculated using Jensen-Shannon divergence :\\[D(G_1,G_2) = \\frac {1}{2}KL(P||M) + \\frac{1}{2}KL(Q||M)\\]\\(M = (P+Q)/2\\) mixture distribution \\(P\\) \\(Q\\)\\(KL(\\cdot||\\cdot)\\) Kullback-Liebler divergence.’s lot math, know essentially metric creates matrix characterizes shortest path lengths relation total diameter graph compares based resulting probability distributions paths various length using assessments mutual information. Kullback-Liebler divergence measure information lost using one probability distribution estimate another. measure symmetric \\(KL(P||M)\\) \\(KL(M||P)\\).run R, ’re going actually use Python package/script initialize using reticulate command source_python() works essentially like source() R scripts. Python script modified version script placed GitHub Bagrow (can download modified version ).next chunk code show another way can run Python code R-Studio. example first initialize portrait_divergence function create 3 edge list objects. run portrait_divergence function using py$ prefix. Much like used r. prefix call global R objects Python can use py$ call Python objects R. Using py$portrait_divergence() function supplying two edge lists R objects can run function.Portrait divergence ranges 0 1 lower values indicate closer relationship terms shortest path portrait structure 1 represents overlap probability distributions networks., can also used networks different sizes origins. next example use Roman Road networks used Section 3 compare San Pedro ceramic network road network. Roman Road network different properties San Pedro network much larger well.compare two networks see relatively high portrait divergence value might expect given drastically different nature two networks.Portrait divergence can also calculated weighted networks (based three column weighted network edge list) using portrait_divergence function. example add random weights two networks used last example see effects results. Note weighting schema can also different scales procedure still work. example weights AD1250-1300 ceramic similarity network range 1-3 whereas values range 1-100 road network.shows, get somewhat lower value considering random weightings. likely informative evaluate sets networks defined using different weighting schemes track different approaches assigning defining weight lead different network portraits.","code":"\nlibrary(reticulate)\nsource_python(\"scripts/portrait_divergence.py\")\n\ng1 <- as_edgelist(asIgraph(AD1250net))\ng2 <- as_edgelist(asIgraph(AD1300net))\ng3 <- as_edgelist(asIgraph(AD1350net))\n\npy$portrait_divergence(g1, g2)## [1] 0.5958473\npy$portrait_divergence(g2, g3)## [1] 0.3720442\npy$portrait_divergence(g1, g3)## [1] 0.7556229\nload(\"data/road_networks.RData\")\n\npy$portrait_divergence(g1, as_edgelist(road_net, names = FALSE))## This graph was created by an old(er) igraph version.\n##   Call upgrade_graph() on it to use with the current igraph version\n##   For now we convert it on the fly...## [1] 0.8242969\nset.seed(46232)\ng1w <- cbind(g1, sample(1:3, nrow(g1), replace = TRUE))\nrnet <- as_edgelist(road_net, names = FALSE)\nrnetw <- cbind(rnet, sample(1:100, nrow(rnet), replace = TRUE))\n\npy$portrait_divergence(g1w, rnetw)## [1] 0.7798428"},{"path":"ComparingNetworks.html","id":"GraphletMethods","chapter":"Section 12 Comparing Networks","heading":"12.2.5 Graphlet-based Methods","text":"Another set methods proven quite useful referred graphlet-based measures. different specific models general methods grouped define similarity terms distribution non-isomorphic sub-graphs larger networks (typically ranging 3 5 nodes). Experimental research shown graphlet approaches good job recovering information structure networks, individual positions nodes edges, overall network topology well generative processes. Indeed, comparison many network comparison methods, Tantardini et al. (2019) found graphlet-based methods generally performed best common circumstances (although methods yet extended weighted/valued networks).basic premise set number nodes limited numbers unique graph motifs possible tallying distribution comparing networks, can get idea similar networks terms local global structural properties. image shows possible undirected graphlet configurations 2, 3, 4, 5 nodes. colored shading figure shows nodes structurally equivalent positions within graphlet (nodes color given graphlet structural position graphlet). graphlets numbered (starting 0) typically recent publications (\\(G_0\\) \\(G_{29}\\)) nodes unique “orbits” labeled \\(O_0\\) \\(O_{72}\\). orbit case refers unique structural position within unique graphlet.graphlet automorphisms figure comes Melckenbeeck et al. 2019 BMC Bioinformatics originally published CC--4.0 licence reused altered colors.\nImportantly, quantification graphlets graphlet-based\nmethods discussed graphlet kernel described \nexactly methods outlined section count\ngraphlets size \\(k\\) \nunconnected nodes. example, graphlet-based methods \\(k=3\\) graphlets considered \nthree nodes least one connection (unlike graphlet kernel\nmethods also considered empty triad triad one\nunconnected node).\nLet’s start using learning use orca package R calculate orbits given \\(k\\) network objects. way example, use Roman Roads network data first network Cibola ceramic similarity network second (click links download follow along). use orca package, need convert igraph network objects edge list column defined integer data. using apply function get.edgelist function nested within . making conversion use orca::count4 orca::count5 functions define counts orbits \\(k=4\\) \\(k=5\\) node configurations respectively. view first rows . output data frames row node columns represent counts orbits configuration using numbering scheme shown figure .","code":"\nlibrary(orca)## Warning: package 'orca' was built under R version 4.2.3\n# Read in data\nload(\"data/road_networks.RData\")\ncibola <-\n  read.csv(file = \"data/Cibola_adj.csv\",\n           header = TRUE,\n           row.names = 1)\ncibola_net <- igraph::graph_from_adjacency_matrix(as.matrix(cibola),\n                                                mode = \"undirected\")## Warning: The `adjmatrix` argument of `graph_from_adjacency_matrix()` must be symmetric\n## with mode = \"undirected\" as of igraph 1.6.0.\n## ℹ Use mode = \"max\" to achieve the original behavior.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.\n# Calculate orbits for k = 4 and 5 for the Roman road network\nroad_net_int <-\n  t(apply(igraph::get.edgelist(road_net, names = F), 1, as.integer))## Warning: `get.edgelist()` was deprecated in igraph 2.0.0.\n## ℹ Please use `as_edgelist()` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.## This graph was created by an old(er) igraph version.\n##   Call upgrade_graph() on it to use with the current igraph version\n##   For now we convert it on the fly...\nroad_orb4 <- orca::count4(road_net_int)\nroad_orb5 <- orca::count5(road_net_int)\n\nhead(road_orb4)##      O0 O1 O2 O3 O4 O5 O6 O7 O8 O9 O10 O11 O12 O13 O14\n## [1,]  4  6  6  0 10 18  1  4  0  1   0   0   0   0   0\n## [2,]  3  5  2  1  6  8  3  0  0  0   0   1   1   0   0\n## [3,]  3  9  3  0 11 18  8  1  0  2   0   0   0   0   0\n## [4,]  2  4  1  0  9  4  3  0  0  0   0   0   0   0   0\n## [5,]  2  4  1  0  7  4  3  0  0  0   0   0   0   0   0\n## [6,]  3  2  1  2  5  2  0  0  0  0   2   0   0   1   0\nhead(road_orb5)##      O0 O1 O2 O3 O4 O5 O6 O7 O8 O9 O10 O11 O12 O13 O14 O15 O16 O17 O18 O19 O20\n## [1,]  4  6  6  0 10 18  1  4  0  1   0   0   0   0   0   9  24  10   5   6   3\n## [2,]  3  5  2  1  6  8  3  0  0  0   0   1   1   0   0   8   6   4   1   8   6\n## [3,]  3  9  3  0 11 18  8  1  0  2   0   0   0   0   0   6  16  23   0  22  16\n## [4,]  2  4  1  0  9  4  3  0  0  0   0   0   0   0   0  13   7   2   6  10   3\n## [5,]  2  4  1  0  7  4  3  0  0  0   0   0   0   0   0  13   7   3   1  10   3\n## [6,]  3  2  1  2  5  2  0  0  0  0   2   0   0   1   0   9   3   0   4   0   0\n##      O21 O22 O23 O24 O25 O26 O27 O28 O29 O30 O31 O32 O33 O34 O35 O36 O37 O38\n## [1,]  18   0   1   0   0   0   2   3   0   0   0   0   0   3   0   0   0   0\n## [2,]   0   1   0   0   0   0   0   0   0   3   0   0   0   2   0   0   0   0\n## [3,]   9   3   0   1   0   0   4   4   0   0   2   0   0   3   0   0   0   0\n## [4,]   0   1   0   0   0   0   2   0   0   0   0   0   0   1   0   0   0   0\n## [5,]   0   1   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n## [6,]   0   0   0   0   0   0   0   0   5   0   0   0   0   1   0   0   0   0\n##      O39 O40 O41 O42 O43 O44 O45 O46 O47 O48 O49 O50 O51 O52 O53 O54 O55 O56\n## [1,]   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n## [2,]   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0\n## [3,]   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n## [4,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [5,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [6,]   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0\n##      O57 O58 O59 O60 O61 O62 O63 O64 O65 O66 O67 O68 O69 O70 O71 O72\n## [1,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [2,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [3,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [4,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [5,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [6,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n# Calculate orbits for k = 4 and 5 for the Cibola network\ncibola_net_int <-\n  t(apply(igraph::get.edgelist(cibola_net, names = F), 1, as.integer))\n\ncibola_orb4 <- orca::count4(cibola_net_int)\ncibola_orb5 <- orca::count5(cibola_net_int)\n\nhead(cibola_orb4)##      O0 O1 O2 O3  O4 O5 O6 O7 O8 O9 O10 O11 O12 O13 O14\n## [1,] 11 17  7 48 105 11  0  0  2 11  75  13  40  37 115\n## [2,]  8 38  0 28 120  0 23  0  0 54  58   0 104   0  56\n## [3,]  1 13  0  0  28  0 17  0  0 61   0   0   0   0   0\n## [4,] 11 34  9 46  84 76 41  0  9 46 124  19  61  43 103\n## [5,] 13 18 13 65  65 60 15  3  1 32 124  24  15  86 173\n## [6,] 11 24  7 48 106 40 16  0  5 17  94  12  48  39 114\nhead(cibola_orb5)##      O0 O1 O2 O3  O4 O5 O6 O7 O8 O9 O10 O11 O12 O13 O14 O15 O16 O17 O18 O19 O20\n## [1,] 11 17  7 48 105 11  0  0  2 11  75  13  40  37 115 496  69   0 122   0   0\n## [2,]  8 38  0 28 120  0 23  0  0 54  58   0 104   0  56 365   0   0 125 179   0\n## [3,]  1 13  0  0  28  0 17  0  0 61   0   0   0   0   0  73   0   0  24 115   0\n## [4,] 11 34  9 46  84 76 41  0  9 46 124  19  61  43 103  36 334  42  45 214 108\n## [5,] 13 18 13 65  65 60 15  3  1 32 124  24  15  86 173 158 185   1  48  61  63\n## [6,] 11 24  7 48 106 40 16  0  5 17  94  12  48  39 114 311 201  24  97  96  33\n##      O21 O22 O23 O24 O25 O26 O27 O28 O29 O30 O31 O32 O33 O34 O35 O36 O37 O38\n## [1,]   0   0   0  66   0  14 261   6 372   1   0   0   0   0   0  14   0   0\n## [2,]   0   3   0 164  15   0 233   0 262   0  22  18   0   0  11   0   0   0\n## [3,]   0   4   0 125   0   0  42   0   0   0  45   0   0   0   2   0   0   0\n## [4,]   0  20   0  58  32  20 156 153 360 115 105  92   0   0  12   1  59   0\n## [5,]  28   4   0  60  11  47 111 155 449  74  31  81   2   2   5   0   8   2\n## [6,]   0   3   0  82  16  10 317  54 369  58  14  47   0   0   4  17  15   0\n##      O39 O40 O41 O42 O43 O44 O45 O46 O47 O48 O49 O50 O51 O52 O53 O54 O55 O56\n## [1,]   0   0  26   0  31   1  30 261   9  28   0   0   2  10   4   0   0   2\n## [2,]  29  83   0   0  16   0  65 235   0   0   0   0   0   2   0  30   0  30\n## [3,]  85   0   0   0   0   0  46   0   0   0   0   0   0   0   0   0   0 152\n## [4,]  23 119  15   0 187   3 159  39  26 319   0   0  11   0  13  16   0  55\n## [5,]  38  28  30  12 193   2  86  50   9 344   0   0   1   4   3   0  14  47\n## [6,]  11  41   6   0  46   0  63 203   8 156   0   0  11   0  13  12   0  11\n##      O57 O58 O59 O60 O61 O62 O63 O64 O65 O66 O67 O68 O69 O70 O71 O72\n## [1,] 117  10  37  33   6   1   0   5  16 150  58   9   0  50  84 171\n## [2,]  69   0 104   0   0   0   0   0 129 105   0   0   0 173   0  70\n## [3,]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n## [4,] 221  14  55  50   9   2  12   6  25 115  80  38   2  90  79 143\n## [5,] 355  10  33  40  21   0   0   4   1  76 132   2   4  12 242 276\n## [6,] 154  10  39  49   5   2   2   8   8 141  56  20   4  64  87 168"},{"path":"ComparingNetworks.html","id":"relative-graphlet-frequency-distribution","chapter":"Section 12 Comparing Networks","heading":"Relative Graphlet Frequency Distribution","text":"orbits enumerated pair networks, many options comparing networks. simplest method simply calculate absolute difference frequency graphlets normalized total number graphlets network. called Relative Graphlet Frequency Distribution (RGFD). can , however, take one intermediate step. orca::count4 orca::count5 functions calculate orbit counts, graphlet counts. made simple function assigns graphlet counts using schema shown figure .place can compare two networks using rescaled version relative graph frequency distribution defined :\\[d(G_1,G_2) = \\Sigma_{=1} | F_i(G_1) - F_i(G_2)|\\]\\(F_i(G_1)\\) count graphlet \\(\\) network 1 divided total number graphlets network 1\\(F_i(G_2)\\) count graphlet \\(\\) network 2 divided total number graphlets network 2We can easily calculate measure dividing column sums graphlet counts network total number graphlets network. Next find sum absolute differences results. Note version using 15 \\(k=4\\) graphlets also use 73 \\(k=5\\) graphlets number (though larger numbers computationally difficult calculate don’t typically provide better results). measure comparisons two vectors proportions sum 1, possible values range 0 two graphlet distributions identical 2 two graphlet distributions inverse one another. rolled function ease use. function expects matrices graphlet counts:example produced distance 1.0959 suggesting networks share half graphlet distributions common.Importantly, also possible run function defined orbit counts directly instead just graphlet counts either \\(k=4\\) \\(k=5\\). Note run function \\(k=4\\) example results identical graphlet counts means guaranteed.results suggest somewhat greater distance distribution orbits \\(k=5\\) \\(k=4\\).","code":"\norbit_to_graphlet <- function(x) {\n  out <- matrix(NA, nrow(x), 9)\n  out[, 1] <- x[, 1]\n  out[, 2] <- rowSums(x[, 2:3])\n  out[, 3] <- x[, 4]\n  out[, 4] <- rowSums(x[, 5:6])\n  out[, 5] <- rowSums(x[, 7:8])\n  out[, 6] <- x[, 9]\n  out[, 7] <- rowSums(x[, 10:12])\n  out[, 8] <- rowSums(x[, 13:14])\n  out[, 9] <- x[, 15]\n  colnames(out) <- c(\"G0\", \"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"G8\")\n  return(out)\n}\n\nroad_graphlet <- orbit_to_graphlet(road_orb4)\nhead(road_graphlet)##      G0 G1 G2 G3 G4 G5 G6 G7 G8\n## [1,]  4 12  0 28  5  0  1  0  0\n## [2,]  3  7  1 14  3  0  1  1  0\n## [3,]  3 12  0 29  9  0  2  0  0\n## [4,]  2  5  0 13  3  0  0  0  0\n## [5,]  2  5  0 11  3  0  0  0  0\n## [6,]  3  3  2  7  0  0  2  1  0\ncibola_graphlet <- orbit_to_graphlet(cibola_orb4)\nhead(cibola_graphlet)##      G0 G1 G2  G3 G4 G5  G6  G7  G8\n## [1,] 11 24 48 116  0  2  99  77 115\n## [2,]  8 38 28 120 23  0 112 104  56\n## [3,]  1 13  0  28 17  0  61   0   0\n## [4,] 11 43 46 160 41  9 189 104 103\n## [5,] 13 31 65 125 18  1 180 101 173\n## [6,] 11 31 48 146 16  5 123  87 114\nrgfd <- function(graphlet1, graphlet2) {\n  graphlet1_sum <- colSums(graphlet1) / sum(graphlet1)\n  graphlet2_sum <- colSums(graphlet2) / sum(graphlet2)\n  return(sum(abs(graphlet1_sum - graphlet2_sum)))\n}\n\n\nrgfd(road_graphlet, cibola_graphlet)## [1] 1.09591\nrgfd(road_orb4, cibola_orb4)## [1] 1.09591\nrgfd(road_orb5, cibola_orb5)## [1] 1.273612"},{"path":"ComparingNetworks.html","id":"graphlet-orbit-distribution-agreement","chapter":"Section 12 Comparing Networks","heading":"Graphlet (Orbit) Distribution Agreement","text":"Another graphlet-based method comparing networks based something called graphlet distribution agreement. measure actually works orbits underlying graphlets may also sometimes see referred orbit distribution agreement measure. measure based distribution degree 73 possible orbits graphlet \\(k=5\\) case. calculated follows possible orbit \\(j\\) (indexed 0 72 figure ):\\[NG^j(k) = \\frac{d G^j(k)/k}{T_{G^}} \\]\n\\(d G^j(k) / k\\) number nodes network \\(G\\) touching \\(k\\) times orbit \\(j\\) divided \\(k\\)\\(T_{G^}\\) normalizing factor sum values numerator values \\(j\\)set values place orbit 0 72 2 networks can calculate agreement value \\(j\\) two networks using following equation:\\[^j(G_1,G_2) = 1 - \\sqrt{\\frac{1}{2} \\Sigma (N^j_{G_1}(k) - N^j_{G_2}(k))^2}\\]final value agreement geometric arithmetic mean 73 values \\(^j(G_1,G_2)\\). value range 0 1 larger numbers indicating greater agreement distribution orbits.\nLuckily us, someone already gone trouble coding\nmethod R. GitHub User QiliShi created \npackage called NetworkSim calculates metric\ndescribed . package CRAN archive, however, \nneeds installed directly GitHub using \ndevtools::install_github function. already\ninstalled package, run next line code.\nspecific function within NetworkSim package called netODA orbit distribution agreement. expects either networks igraph format integer edge list objects run. Let’s give try using Roman Road Cibola ceramic similarity data imported using arithmetic means:Now let’s compare three versions Roman Road network (see section Exploratory Analysis details) using arithmetic mean.might expect, different versions Roman Road network quite similar graphlet degree distribution values closer 1. Now let’s try geometric mean. also include comparison Cibola ceramic network first Roman Road network:Notice geometric mean (\\(i_{th}\\) root product set \\(\\) numbers) quite similar Roman Road comparisons NA comparisons Roman Road Cibola ceramic network. geometric means undefined value set numbers considered 0 negative. case, indicates least one Agreement value one orbit configuration 0 comparison. aware cases exist may even fairly common comparing different networks.","code":"\ndevtools::install_github(\"QiliShi/NetworkSim\")\nlibrary(NetworkSim)\n\nnetODA(road_net, cibola_net, mean = \"arithmetic\")## [1] 0.3420875\nnetODA(road_net, road_net2, mean = \"arithmetic\")## This graph was created by an old(er) igraph version.\n##   Call upgrade_graph() on it to use with the current igraph version\n##   For now we convert it on the fly...## [1] 0.9307024\nnetODA(road_net, road_net3, mean = \"arithmetic\")## This graph was created by an old(er) igraph version.\n##   Call upgrade_graph() on it to use with the current igraph version\n##   For now we convert it on the fly...## [1] 0.8732273\nnetODA(road_net2, road_net3, mean = \"arithmetic\")## [1] 0.8688872\nnetODA(road_net, road_net2, mean = \"geometric\")## [1] 0.9262988\nnetODA(road_net, road_net3, mean = \"geometric\")## [1] 0.8269154\nnetODA(road_net2, road_net3, mean = \"geometric\")## [1] 0.8243554\nnetODA(road_net, cibola_net, mean = \"geometric\")## [1] NaN"},{"path":"ComparingNetworks.html","id":"graphlet-correlation-distance","chapter":"Section 12 Comparing Networks","heading":"Graphlet Correlation Distance","text":"One final graphlet-based measure shown considerable promise Graphlet Correlation Distance (GCD). measure compares correlation matrix based orbit counts one network correlation matrix based orbit counts second network. Exploration focused measure shown orbits defined actually redundant, meaning counts orbit perfectly correlated orbit (Yaveroglu et al. 2015). Thus, measures calculated redundant orbits discarded avoid double counting particular structural positions. case orbits \\(k=4\\) redundant orbits indexed {3, 12, 13, 14} figure . remaining 11 orbits redundant orbits removed used calculated measure called GCD-11 based remaining 11 non-redundant orbits. Work Tantardini others (2019) suggest measure performs better recognizing different network generative models either GCD-15 measure (includes redundant orbits \\(k=4\\)) GCD-73 GCD-56 represent full non-redundant orbit counts \\(k=5\\) case. example thus work GCD-11 measure.GCD-11 measure calculated :first defining \\(k=4\\) orbit counts node two networks removing four columns associated redundant orbitscalculating 11 x 11 correlation matrix using rank order Spearman’s \\(\\rho\\) measure correlation data frame orbit counts node networksfinally, GCD-11 defined Euclidean distance upper triangle (excluding diagonal) correlation matrices.measure, based Euclidean distance 0 two networks identical upper bound.unaware existing R package calculates GCD-11 derivation Graphlet Correlation Distance, relatively easy create function obtain measure. can download GCD-11 script follow along code . netGCD() function requires orca package expects two igraph network objects input.\nNote indexes used remove columns orbit count\ndata frame different numbers indexes listed \ntext {3, 12, 13, 14} vs. {4, 13, 14, 15}. R \ndefault starts indexes 1 many programming languages \ngraphlet framework starts index 0.\nNow let’s give try using Roman Road Cibola ceramic networks:GCD-11 values higher comparing networks generated different processes , illustrate last example, 0 compare network . upper bound distance comparing sets networks together comparing results can get better sense networks compare structural properties.mentioned briefly , GCD-11 particularly well suited identifying networks generated similar processes. Thus, expect network generated particular way, create random networks generated process (competing generative processes) compare results aid interpretation. example, next chunk code create random small world network 1000 nodes another network generated using Erdos Renyi process compare Roman Road network.shows, considerably smaller distance random small world network Roman Road network Erdos-Renyi network Roman Road network. Indeed, comparisons Erdos-Renyi model Roman Roads produces similar high distance comparison random small world Erdos-Renyi networks. , course, proof Roman Network network small world structure comparison part analytical path evaluate possibility.","code":"\nrequire(orca)\n\n### GCD-11 function\n\nnetGCD <- function(net1, net2) {\n  # Convert igraph objects into integer edge lists\n  net1a <- t(apply(igraph::get.edgelist(net1, names = F), 1, as.integer))\n  net2a <- t(apply(igraph::get.edgelist(net2, names = F), 1, as.integer))\n  \n  # Calculate orbit counts for 4 nodes and exclude redundant indexes\n  orb1 <- orca::count4(net1a)[, -c(4, 13, 14, 15)]\n  orb2 <- orca::count4(net2a)[, -c(4, 13, 14, 15)]\n  \n  # Create correlation matrix using Spearman's rho for both orbit counts\n  orbcor1 <- cor(orb1, method = \"spearman\")\n  orbcor2 <- cor(orb2, method = \"spearman\")\n  \n  # Convert to vector of upper triangle\n  orbcor1 <- orbcor1[upper.tri(orbcor1)]\n  orbcor2 <- orbcor2[upper.tri(orbcor2)]\n  \n  # Calculate Euclidean distance between results for each network\n  out <- as.matrix(dist(t(cbind(orbcor1, orbcor2))))[2]\n  \n  return(out)\n}\nnetGCD(road_net, cibola_net)## [1] 3.126976\nnetGCD(road_net, road_net2)## [1] 1.05689\nnetGCD(road_net, road_net3)## [1] 0.658248\nnetGCD(road_net2, road_net3)## [1] 0.9222939\nnetGCD(road_net, road_net) # comparing identical networks## [1] 0\nset.seed(3256)\nsw1 <- sample_smallworld(dim = 1, size = 1000, nei = 2, p = 0.1)\ner1 <- erdos.renyi.game(n = 1000, p = 0.1)\n\nnetGCD(road_net, sw1)## [1] 1.528994\nnetGCD(road_net, er1)## [1] 4.746963\nnetGCD(sw1, er1)## [1] 5.077361"},{"path":"ComparingNetworks.html","id":"Alignment","chapter":"Section 12 Comparing Networks","heading":"12.2.6 Alignment-based Methods","text":"number additional methods Unknown Node Correspondence approaches network comparison haven’t covered . Many simply slight alterations approaches already outlined one set methods known alignment-based methods somewhat different. approaches come computational biology attempt create mappings ordered pairs nodes two networks similar positions networks various functions assess quality matching. approaches alignment-based methods simply rely network information biological information (information based functions particular genes proteins) thus can’t generalized areas. alignment based approaches rely solely topology attempt align networks based graphlet degree distributions (similar GCD discussed ). experimented method (GRAAL GRAph ALigner) found computationally intensive tends produce less useful results methods outlined. doesn’t mean approaches aren’t useful archaeological cases leave experimentation others.","code":""},{"path":"TableOfContents.html","id":"TableOfContents","chapter":"Table of Contents Quick Reference","heading":"Table of Contents Quick Reference","text":"purpose section provide quick index topics covered document can easily identify work specific things. Use cross-reference links find looking .","code":""},{"path":"TableOfContents.html","id":"welcome","chapter":"Table of Contents Quick Reference","heading":"Welcome","text":"WelcomeHow Use Online Companion?ReproducibilityComputational Archaeology Discord CommunityNew R R Studio?Contribute ProjectHelp Build CommunityAcknowledgements","code":""},{"path":"TableOfContents.html","id":"part-ii-getting-started","chapter":"Table of Contents Quick Reference","heading":"PART II: GETTING STARTED","text":"","code":""},{"path":"TableOfContents.html","id":"section-1-getting-started-with-r","chapter":"Table of Contents Quick Reference","heading":"Section 1: Getting Started with R","text":"Getting Started RDownload Install R\nWindows\nMacOC\nLinux\nWindowsMacOCLinuxDownload Install R-StudioRun R-StudioR R-Studio Basics\nOrganization R-Studio\nMathematical Operations\nCreating Variables/Objects\nLogical Operators\nVectors\nUsing Basic R Functions\nTabular Data\nData Types R\nObject Types R\nVectors\nMatrices\nData Frames\nLists\n\nOrganization R-StudioMathematical OperationsCreating Variables/ObjectsLogical OperatorsVectorsUsing Basic R FunctionsTabular DataData Types RObject Types R\nVectors\nMatrices\nData Frames\nLists\nVectorsMatricesData FramesListsThe Workspace Tab\nSetting Working Directory\nWorking first R script\nSetting Working DirectoryWorking first R scriptInstalling Using PackagesWorking External FilesPlotting DataWarnings Messages RMore Advanced R Features\nConditional Statements\nLoops\nCustom Functions\nConditional StatementsLoopsCustom FunctionsTest Skills","code":""},{"path":"TableOfContents.html","id":"part-ii-work-while-you-read","chapter":"Table of Contents Quick Reference","heading":"PART II: WORK WHILE YOU READ","text":"","code":""},{"path":"TableOfContents.html","id":"section-2-data-and-workspace-setup","chapter":"Table of Contents Quick Reference","heading":"Section 2: Data and Workspace Setup","text":"Data Workspace SetupData Sets\nJust Give Everything\nRoman Road Networks\nSouthwest Social Networks Project Ceramic Similarity Networks\nCibola Region Technological Similarity Networks\nHimalayan Visibility Networks\nArchaeological Publication Networks\nIron Age Sites Southern Spain\nJust Give EverythingRoman Road NetworksSouthwest Social Networks Project Ceramic Similarity NetworksCibola Region Technological Similarity NetworksHimalayan Visibility NetworksArchaeological Publication NetworksIron Age Sites Southern SpainImporting Data RRequired/Suggested R Packages\nJust Install Everything\nJust Install EverythingR EnvironmentSuggested Workspace Setup","code":""},{"path":"TableOfContents.html","id":"section-3-network-data-in-r","chapter":"Table of Contents Quick Reference","heading":"Section 3: Network Data in R","text":"Network Data RNetwork Data Formats\nEdge list\nAdjacency list\nAdjacency matrix\nIncidence matrix\nNode edge attribute data\nEdge listAdjacency listAdjacency matrixIncidence matrixNode edge attribute dataNetwork Types\nSimple networks\nDirected networks\nSigned, Categorized, Weighted Networks\nTwo-mode networks\nSimilarity networks\nBrainerd-Robinson similarity\nMorisita’s Index\n\\(\\chi^{2}\\) Distance\nJaccard Similarity\nCreating network objects similarity matrices\n\nEgo networks\nMultilayer networks\nSimple networksDirected networksSigned, Categorized, Weighted NetworksTwo-mode networksSimilarity networks\nBrainerd-Robinson similarity\nMorisita’s Index\n\\(\\chi^{2}\\) Distance\nJaccard Similarity\nCreating network objects similarity matrices\nBrainerd-Robinson similarityMorisita’s Index\\(\\chi^{2}\\) DistanceJaccard SimilarityCreating network objects similarity matricesEgo networksMultilayer networksConverting among network object types","code":""},{"path":"TableOfContents.html","id":"section-4-exploratory-network-analysis","chapter":"Table of Contents Quick Reference","heading":"Section 4: Exploratory Network Analysis","text":"Exploratory Network AnalysisExample Network ObjectsCalculating Network Metrics RNetwork Centrality\nDegree Centrality\nBetweenness Centrality\nEigenvector Centraoity\nPage Rank\nCloseness Centrality\nHubs Authorities\nDegree CentralityBetweenness CentralityEigenvector CentraoityPage RankCloseness CentralityHubs AuthoritiesTriads Clustering\nTriads\nTriad Census\nTransitivity\nTriadsTriad CensusTransitivityWalks, Paths, Distance\nDistance\nShortest Paths\nNetwork Diameter\nDistanceShortest PathsNetwork DiameterComponents Bridges\nIdentifying Components\nCutpoints\nBridges\nIdentifying ComponentsCutpointsBridgesCliques Communities\nCliques\nK-Cores\nCluster Detection Agloritms\nGirvan-Newman Clustering\nWalktrap Algorithm\nLouvain Modularity\nCalculating Modularity Partitions\nFinding Edges Communities\n\nCliquesK-CoresCluster Detection Agloritms\nGirvan-Newman Clustering\nWalktrap Algorithm\nLouvain Modularity\nCalculating Modularity Partitions\nFinding Edges Communities\nGirvan-Newman ClusteringWalktrap AlgorithmLouvain ModularityCalculating Modularity PartitionsFinding Edges CommunitiesCase Study: Roman Roads Iberian Peninsula","code":""},{"path":"TableOfContents.html","id":"section-5-quantifying-uncertainty","chapter":"Table of Contents Quick Reference","heading":"Section 5: Quantifying Uncertainty","text":"Quantifying UncertaintyR Scripts Conducting Uncertainty AnalysisA General Approach UncertaintyNodes Missing RandomEdges Missing RandomAssessing Individual Nodes/Edges Missing RandomNodes/Edges Missing Due Biased SamplingResampling Incidence MatricesEdge Probability Modeling\nEdge Probability Similarity Networks\nEdge Probability Similarity NetworksUncertainty Due Small Variable Sample Sizes","code":""},{"path":"TableOfContents.html","id":"section-6-network-visualization","chapter":"Table of Contents Quick Reference","heading":"Section 6: Network Visualization","text":"Network VisualizationData R SetupVisualizing Networks R\nnetwork package\nigraph package\nggraph package\nnetwork packageigraph packageggraph packageNetwork Visualization Options\nGraph Layouts\nManual Layouts\nGeographic Layouts\nShape-based Algorithmic Layouts\n\nNode Edge Options\nNodes\nEdges\nLabels\n\nKind Color Blind\nCommunities Groups\nGraph Layouts\nManual Layouts\nGeographic Layouts\nShape-based Algorithmic Layouts\nManual LayoutsGeographic LayoutsShape-based Algorithmic LayoutsNode Edge Options\nNodes\nEdges\nLabels\nNodesEdgesLabelsBe Kind Color BlindCommunities GroupsReplicating Book Figures\nFigure 6.1 - Manual Layout\nFigure 6.2 - Examples Common Network Plot Formats\nFigure 6.3 - Examples Rare Network Plot Formats\nFigure 6.4 - Simple Network Clusters\nFigure 6.5 - Interactive Layout\nFigure 6.6 - Absolute Geographic Layout\nFigure 6.7 - Distorted Geographic Layout\nFigure 6.8 - Graph Layout Algorithms\nFigure 6.9 - Heirarchical Graph Layouts\nFigure 6.10 - Kind Color Blind\nFigure 6.11 - Node Symbol Color Schemes\nFigure 6.12 - Image Node, Example 1\nFigure 6.13 - Image Node, Example 2\nFigure 6.14 - Edge Thickness Color\nFigure 6.15 - Edge Direction\nFigure 6.16 - Edge Binarization\nFigure 6.17 - Edge Bundling\nFigure 6.18 - Group---box Layout\nFigure 6.19 - Weighted Adjacency Matrix\nFigure 6.20 - Nodetrix Diagram Interactive Plot\nFigure 6.21 - Temporal Change, Filmstrip Approach\nFigure 6.22 - Temporal Change, Similtaneous Display\nFigure 6.23 - Timelines Time Prisms\nFigure 6.24 - Animation\nFigure 6.25 - Interactive Networks\nFigure 6.26 - Case Study, SWSN Example 1\nFigure 6.27 - Case Study, SWSN Example 2\nFigure 6.1 - Manual LayoutFigure 6.2 - Examples Common Network Plot FormatsFigure 6.3 - Examples Rare Network Plot FormatsFigure 6.4 - Simple Network ClustersFigure 6.5 - Interactive LayoutFigure 6.6 - Absolute Geographic LayoutFigure 6.7 - Distorted Geographic LayoutFigure 6.8 - Graph Layout AlgorithmsFigure 6.9 - Heirarchical Graph LayoutsFigure 6.10 - Kind Color BlindFigure 6.11 - Node Symbol Color SchemesFigure 6.12 - Image Node, Example 1Figure 6.13 - Image Node, Example 2Figure 6.14 - Edge Thickness ColorFigure 6.15 - Edge DirectionFigure 6.16 - Edge BinarizationFigure 6.17 - Edge BundlingFigure 6.18 - Group---box LayoutFigure 6.19 - Weighted Adjacency MatrixFigure 6.20 - Nodetrix Diagram Interactive PlotFigure 6.21 - Temporal Change, Filmstrip ApproachFigure 6.22 - Temporal Change, Similtaneous DisplayFigure 6.23 - Timelines Time PrismsFigure 6.24 - AnimationFigure 6.25 - Interactive NetworksFigure 6.26 - Case Study, SWSN Example 1Figure 6.27 - Case Study, SWSN Example 2","code":""},{"path":"TableOfContents.html","id":"section-7-spatial-networks","chapter":"Table of Contents Quick Reference","heading":"Section 7: Spatial Networks","text":"Spatial NetworksWorking Geographic Data RExample DataPlanar Networks Trees\nEvaluating Planarity\nDefining Trees\nEvaluating PlanarityDefining TreesSpatial Network Models\nRelative Neighborhood Networks\nGabrial Graphs\nBeta Skeletons\nMinimum Spanning Trees\nDelaunay Triangulation\nK-Nearest Neighbors\nMax Distance Networks\nRelative Neighborhood NetworksGabrial GraphsBeta SkeletonsMinimum Spanning TreesDelaunay TriangulationK-Nearest NeighborsMax Distance NetworksCase Studies: Spatial Networks Networks Space\nProximity Iron Age Sites Southern Spain\nNetworks Space U.S. Southwest\nProximity Iron Age Sites Southern SpainNetworks Space U.S. Southwest","code":""},{"path":"TableOfContents.html","id":"part-iii-going-beyond-the-book","chapter":"Table of Contents Quick Reference","heading":"PART III: GOING BEYOND THE BOOK","text":"","code":""},{"path":"TableOfContents.html","id":"section-8-exponential-random-graph-models","chapter":"Table of Contents Quick Reference","heading":"Section 8: Exponential Random Graph Models","text":"Exponential Random Graph ModelsERGMs RCranborne Chase Visibility Network Example\nAssessments Network Properties\nFitting Models ergm\nBuilding Model Based Theory\nAssessing Goodness--Fit\nAsessing Models MCMC Diagnostics\nAssessments Network PropertiesFitting Models ergmBuilding Model Based TheoryAssessing Goodness--FitAsessing Models MCMC DiagnosticsSimulating Networks ERGMsAdditinoal Info ERGM Terms\nAvoiding Model Degeneracy\nAvoiding Model Degeneracy","code":""},{"path":"TableOfContents.html","id":"section-9-spatial-interaction-models","chapter":"Table of Contents Quick Reference","heading":"Section 9: Spatial Interaction Models","text":"Spatial Interaction ModelsSimple Gravity Models\nParameterizing Gravity Model\nParameterizing Gravity ModelThe Rihll Wilson “Retail” Model\nParameterizing Retail Model\nParameterizing Retail ModelTruncated Power FunctionsOther Spatial Interaction Models","code":""},{"path":"TableOfContents.html","id":"section-10-affiliation-data-and-co-association","chapter":"Table of Contents Quick Reference","heading":"Section 10: Affiliation Data and Co-Association","text":"Affiliation Data Co-AssociationAnalyzing Two-Mode Networks\nUsing Traditional Network Metrics\nUsing Two-Mode Specific Network Metrics\nProjecting Two-Mode Networks Analysis\nUsing Traditional Network MetricsUsing Two-Mode Specific Network MetricsProjecting Two-Mode Networks AnalysisCorrespondence Analysis\nNetwork Visuals Using Correspondence Analysis\nNetwork Visuals Using Correspondence AnalysisMeasuring Co-Association\nAlternative Methods Visualizing Co-associations\nAlternative Methods Visualizing Co-associations","code":""},{"path":"TableOfContents.html","id":"section-11-network-diffusion","chapter":"Table of Contents Quick Reference","heading":"Section 11: Network Diffusion","text":"Network DiffusionDiffusion ProcessesSimulating Network Diffusion R\nSimulated Networks\nEmpirical Networks\nSimulated NetworksEmpirical NetworksEvaluating Diffusion Models","code":""},{"path":"TableOfContents.html","id":"section-12-comparing-networks","chapter":"Table of Contents Quick Reference","heading":"Section 12: Comparing Networks","text":"Comparing NetworksKnown Node Correspondence\nDirect Comparison Adjacency Matrices\nQuadratic Assignment Procedure\nDeltaCon\nDirect Comparison Adjacency MatricesQuadratic Assignment ProcedureDeltaConUnknown Node Correspondence\nComparing Network Global Local Statistics\nGraph Kernel Methods\nSpectral Methods\nPortrait Divergence\nGraphlet-based Methods\nAlignment-based Methods\nComparing Network Global Local StatisticsGraph Kernel MethodsSpectral MethodsPortrait DivergenceGraphlet-based MethodsAlignment-based Methods","code":""},{"path":"TableOfContents.html","id":"additional-information-and-materials","chapter":"Table of Contents Quick Reference","heading":"ADDITIONAL INFORMATION AND MATERIALS","text":"References R PackagesArchNetSci GitHub Repository","code":""},{"path":"references-and-r-packages.html","id":"references-and-r-packages","chapter":"References and R Packages","heading":"References and R Packages","text":"","code":""}]
